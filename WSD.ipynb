{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "import pandas as pd\n",
    "import copy\n",
    "\n",
    "from collections import Counter, defaultdict\n",
    "import xml.etree.ElementTree as ET\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# World Sense Disambiguation (WSD)\n",
    "\n",
    "Ce notebook permet d'effectuer une comparaison des performances de deux algorithmes, un d'apprentissage supervisé et un d'apprentissage semi-supervisé, pour la tâche de Word Sense Disambiguation (WSD). \n",
    "\n",
    "Les deux méthodes sont les suivants :\n",
    "- pour la classification supervisée, utilisation d'un MLP\n",
    "- pour la classification semi-supervisée, utilisation d'un algorithme de constrained K-Means\n",
    "\n",
    "Plusieurs tests sont effectués en considérant plusieurs mots à désambiguiser pour lesquels les performances de ces deux méthodes sont évaluées. L'objectif final est de comparer ces performances pour déterminer à partir de combien de données annotées la première méthode est préférable à la deuxième et vice versa.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Extraction des données\n",
    "\n",
    "La classe Extractor permet d'accéder aux données et de les stocker dans des dictionnaires puis des embeddings. Elle permet de figer les données sur lesquelles les tests de classification seront ensuite faits. Elle comporte les méthodes suivantes :\n",
    "\n",
    "- `extract_examples()` : pour extraire les données d'entraînement et de test provenant de fichiers XML FSE\n",
    "\n",
    "- `extract_embeddings()` : pour extraire les embeddings à partir d'un fichier créé en amont, qui ne regroupe que les embeddings nécéssaires à notre jeu de données. Cette méthode est surtout utile pour drastiquement réduire le temps de chargement des embeddings\n",
    "\n",
    "- `look_up()` : pour effectuer l'étape de look-up avant la classifcation\n",
    "\n",
    "- `select_examples()` : pour sélectionner des données représentatives lorsqu'on ne considère pas toutes les données annotées. Pour qu'un ensemble de données soit représentatif, il faut que chaque étiquette présente dans les données totales soit présente au moins une fois dans le set d'entraînement sélectionné\n",
    "\n",
    "- `define_instance()` : pour choisir les données qui seront classifiées, c'est-à-dire quelle proportion des données seront utilisées (80%, 50%, 25%...)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Extractor :\n",
    "    \n",
    "    def __init__(self, data_path, gold_path, embeddings_path, context_size):\n",
    "        '''\n",
    "        A partir des données, extrait les examples qui seront utilisés lors de l'apprentissage.\n",
    "\n",
    "        INPUT\n",
    "        data_path (str) : chemin pour accéder aux données d'entraînement, au format XML\n",
    "        gold_path (str) : chemin pour accéder aux numéros de sens correspondant aux données\n",
    "                          d'entraînement\n",
    "        embeddings_path (str) : chemin pour accéder aux embeddings, déjà extraits et \n",
    "                                présélectionnés pour ces données\n",
    "        context_size (int) : taille de la fenêtre du contexte du mot à désambiguiser\n",
    "\n",
    "        ARGUMENTS DE CLASSE\n",
    "        self.w2examples (dict) : associe chaque lemme à une liste d'examples correspondant à son \n",
    "                                 utilisation dans une phrase du corpus. \n",
    "                                 examples (list) : liste de tous les couples \n",
    "                                  ([mots du contexte], numéro de sens) pour un lemme donné\n",
    "        self.w2senses (dict) : associe chaque lemme à son ensemble de sens possible\n",
    "        self.w2emb (dict) : associe chaque mot à son embedding\n",
    "        self.selected_examples (liste) : liste d'examples qui contient au moins un example de \n",
    "                                         chaque sens du lemme choisi\n",
    "        self.selected_examples_embs (liste) : même liste d'examples, mais avec les contextes \n",
    "                                              sous forme d'embedding\n",
    "        self.X_train (set) : corpus d'apprentissage\n",
    "        self.X_test (set) : numéros des sens correspondant au corpus d'apprentissage\n",
    "        self.y_train (set) : corpus de test\n",
    "        self.y_test (set) : numéros des sens correspondant au corpus d'apprentissage\n",
    "        self.annotated_examples (list) : liste des données considérées comme annotées \n",
    "        self.unannotated_examples (list) : liste des données considérées comme non annotées \n",
    "        '''\n",
    "        \n",
    "        #récupération des données XML d'apprentissage fournies en argument\n",
    "        tree = ET.parse(data_path)\n",
    "        data_file = tree.getroot()\n",
    "\n",
    "        #récupération des données txt correspondant aux gold class\n",
    "        gold_file = open(gold_path, \"r\",encoding=\"utf-8\")\n",
    "        \n",
    "        # self.w2examples (dict) : associe chaque lemme à une liste d'examples correspondant à son \n",
    "        #                          utilisation dans une phrase du corpus.\n",
    "        # clé (str) : lemme du mot à désambiguiser\n",
    "        # valeur (list) : liste de tous les couples ([mots du contexte], numéro de sens) pour ce \n",
    "        #                 lemme\n",
    "        #\n",
    "        # self.w2senses (dict) : associe chaque lemme à son ensemble de sens possible\n",
    "        # clé (str) : lemme du mot à désambiguiser\n",
    "        # valeur (set) : ensemble des sens possible pour ce lemme\n",
    "        self.w2examples, self.w2senses = self.extract_examples_and_senses(data_file, gold_file, context_size)\n",
    "\n",
    "        # self.w2emb (dict) : associe chaque mot à l'embedding représentant son contexte sommé\n",
    "        # clé (str) : mot à désambiguiser\n",
    "        # valeur (list) : embedding\n",
    "        self.w2emb = self.extract_embeddings(embeddings_path)\n",
    "\n",
    "        # liste d'examples qui contient au moins un example de chaque sens du lemme choisi\n",
    "        # cette liste sera définie lorsque l'instance du mot à désambiguiser sera choisi\n",
    "        self.selected_examples = []\n",
    "        # même liste d'examples, mais avec les contextes sous forme d'embedding\n",
    "        # cette liste sera définie lorsque l'instance du mot à désambiguiser sera choisi\n",
    "        self.selected_examples_embs = []\n",
    "\n",
    "        # les corpus seront définis lorsque l'instance du mot à désambiguiser sera choisi\n",
    "        self.X_train = set()\n",
    "        self.X_test = set()\n",
    "        self.y_train = set()\n",
    "        self.y_test = set()\n",
    "\n",
    "        # liste des données considérées comme annotées \n",
    "        self.annotated_examples = []\n",
    "        # liste des données considérées comme non annotées \n",
    "        self.unannotated_examples = []\n",
    "    \n",
    "    def extract_examples_and_senses(self, data_file, gold_file, context_size):\n",
    "        '''\n",
    "        Extrait les données à partir des fichiers de corpus d'apprentissage et de gold classes.\n",
    "\n",
    "        INPUT\n",
    "        data_file (Element): représentation des phrases du corpus d'apprentissage\n",
    "        gold_file (TextIOWrapper): fichier contenant les numéros de sens (gold class) pour chaque\n",
    "                                   mot à désambiguiser\n",
    "        '''\n",
    "    \n",
    "        # clé (str) : lemme du mot à désambiguiser\n",
    "        # valeur (list) : liste de tous les couples ([mots du contexte], numéro de sens) pour ce \n",
    "        #                 lemme\n",
    "        w2examples = {}\n",
    "        # clé (str) : lemme du mot à désambiguiser\n",
    "        # valeur (set) : ensemble des sens possible pour ce lemme\n",
    "        w2senses = defaultdict(set)\n",
    "\n",
    "        # lecture du fichier gold\n",
    "        gold_file = gold_file.readlines()\n",
    "        \n",
    "        # index de parcours dans le fichier gold\n",
    "        i_gold = 0\n",
    "\n",
    "        # pour chaque phrase du corpus\n",
    "        for text_id in data_file:\n",
    "            for sentence in text_id:\n",
    "\n",
    "                # recherche de(s) l'indice(s) de(s) l'instance(s) pour savoir où se trouve la fenêtre\n",
    "                i_instances = []\n",
    "                for j in range(len(sentence)):\n",
    "                    if sentence[j].tag == \"instance\":\n",
    "                        i_instances.append(j)\n",
    "                \n",
    "                # tant qu'il y a des instances à repérer dans la phrase\n",
    "                while len(i_instances) > 0:\n",
    "\n",
    "                    # enregistrement du lemme de l'instance\n",
    "                    instance = sentence[i_instances[0]].attrib[\"lemma\"].lower()\n",
    "                    \n",
    "                    # si l'instance n'a pas encore de contexte\n",
    "                    if instance not in w2examples : \n",
    "                        # le crée\n",
    "                        w2examples[instance] = []\n",
    "\n",
    "                    context = []\n",
    "                    # pour chaque mot de la fenêtre\n",
    "                    for k in range(-context_size, context_size + 1):\n",
    "                        # si le mot est l'instance, enregistrement de son lemme\n",
    "                        if k == 0:\n",
    "                            context.append(instance)\n",
    "                        # sinon enregistrement du mot du contexte\n",
    "                        elif len(sentence) > i_instances[0] + k and i_instances[0] + k >= 0:\n",
    "                            context.append(sentence[i_instances[0] + k].text.lower())\n",
    "                    \n",
    "                    # récupération des différents sens possibles dans le fichier gold \n",
    "                    gold_class = gold_file[i_gold].split(\"__\")[1].split(\"_\")[1]\n",
    "\n",
    "                    # le fichiers gold et data ayant les données dans le même ordre, les instances\n",
    "                    # et les sens peuvent être enregistrés en même temps dans leur dictionnaire\n",
    "                    # respectif\n",
    "                    w2senses[instance].add(gold_class)\n",
    "                    w2examples[instance].append((context, gold_class))\n",
    "                    \n",
    "                    # l'instance lue est enlevée de la to-do list et l'index de parcours du fichier \n",
    "                    # gold est incrémenté pour passer à l'instance suivante\n",
    "                    i_instances.pop(0)\n",
    "                    i_gold += 1\n",
    "\n",
    "        return w2examples, w2senses\n",
    "    \n",
    "    def extract_embeddings(self,path_embeddings) :\n",
    "        '''\n",
    "        Récupère les embeddings dans le fichier généré et associe à chaque mot son\n",
    "        embedding.\n",
    "\n",
    "        INPUT\n",
    "        path_embeddings (str) : chemin pour accéder aux embeddings, déjà extraits et \n",
    "                                présélectionnés pour ces données\n",
    "\n",
    "        OUTPUT\n",
    "        w2emb (dict) : associe chaque mot à son embedding\n",
    "        '''\n",
    "\n",
    "        # lecture du fichier\n",
    "        file_embeddings = open(path_embeddings , \"r\", encoding=\"UTF-8\")\n",
    "\n",
    "        # clé (str) : mot à désambiguiser\n",
    "        # valeur (list) : embedding du mot\n",
    "        w2emb = {}\n",
    "\n",
    "        # pour chaque mot du fichier\n",
    "        for line in file_embeddings.readlines():\n",
    "\n",
    "            # séparation du mot et de l'embedding\n",
    "            splitted_line = line.split(\" \")\n",
    "            word = splitted_line[0]\n",
    "            embedding = list(map(float,splitted_line[1:]))\n",
    "            # insertion du mot et de son embedding dans le dictionnaire\n",
    "            w2emb[word] = embedding\n",
    "\n",
    "        return w2emb\n",
    "\n",
    "    def look_up(self, context) :\n",
    "        '''\n",
    "        Remplace dans les mots du vecteur de contexte par leur embedding et en fait la\n",
    "        somme.\n",
    "\n",
    "        INPUT\n",
    "        context (list) : liste de taille (size_window*2)+1\n",
    "\n",
    "        OUTPUT\n",
    "        context_emb (list) : liste de taille size_embedding (300 ici)\n",
    "        '''\n",
    "\n",
    "        # taille d'un embedding : 300\n",
    "        emb_size = len(list(self.w2emb.values())[0]) \n",
    "        # initialisation du contexte sous forme d'embedding\n",
    "        context_emb = np.zeros(emb_size)\n",
    "\n",
    "        # pour chaque mot du contexte\n",
    "        for word in context :\n",
    "            # s'il est présent dans le dictionnaire d'embeddings\n",
    "            if word in self.w2emb :\n",
    "                # il est ajouté à l'embedding représentant le contexte\n",
    "                context_emb = np.add(context_emb, np.array(self.w2emb[word])) \n",
    "\n",
    "        return context_emb\n",
    "    \n",
    "    def select_examples(self, examples, senses, sample_size):\n",
    "        '''\n",
    "        Choisit des examples représentatifs du corpus selon un nombre imposé de \n",
    "        données à choisir.\n",
    "\n",
    "        INPUT\n",
    "        examples (list) : liste d'examples pour le mot à désambiguiser\n",
    "        n_senses (int) : nombre de sens associés à ce mot\n",
    "        sample_size (float) : quantité des données considérés\n",
    "\n",
    "        OUTPUT\n",
    "        selected_examples (list) : liste d'examples qui contient au moins un example \n",
    "                                   de chaque sens\n",
    "        '''\n",
    "\n",
    "        selected_examples = []\n",
    "        \n",
    "        # pour chaque sens, on ajoute un example associé à ce sens, au hasard\n",
    "        for sense in senses :\n",
    "            selected_examples.append(random.choice(list(filter((lambda example:example[1]==sense),\n",
    "                                                               examples))))\n",
    "        \n",
    "        # ajoute le nombre de données manquantes (non-présentes dans la liste) selectionnées au hasard\n",
    "        random.shuffle(examples)\n",
    "        for example in examples:\n",
    "            if example not in selected_examples and len(selected_examples) < sample_size*len(examples):\n",
    "                selected_examples.append(example)\n",
    "\n",
    "        return selected_examples\n",
    "    \n",
    "    def select_train_test(self, x, y, senses, data_size, train_size = 0.8):\n",
    "        '''\n",
    "        Sépare en un train set et test set les examples représentatifs du corpus en mettant \n",
    "        au moins une étiquette de chaque sens dans le train set (et le test set si possible)\n",
    "\n",
    "        INPUT\n",
    "        x (list) : liste d'examples pour le mot à désambiguiser\n",
    "        y (list) : liste d'étiquette pour chaque example de x\n",
    "        senses (list) : numéros des sens associés à ce mot\n",
    "        train_size (float) : quantité des données d'entraînement considérés\n",
    "        '''\n",
    "\n",
    "        # SELECTION DES DONNEES REPRESENTATIVES DU TRAIN\n",
    "\n",
    "        # sélection au hasard d'un contexte et de son étiquette pour chaque sens\n",
    "        selected_train = [random.choice(list(filter((lambda example: example[1] == sense),\n",
    "                                                    zip(x,y)))) for sense in senses]\n",
    "            \n",
    "        # SELECTION DES DONNEES REPRESENTATIVES DU TEST\n",
    "\n",
    "        # fait de même pour le corpus de test, lorsque possible, en ne considérant pas\n",
    "        # ceux déjà sélectionnés pour le train\n",
    "        selected_test = []\n",
    "        for sense in senses:\n",
    "            added = False\n",
    "            for example in zip(x,y):\n",
    "                for train_ex in selected_train:\n",
    "                    # vérifie que l'example n'a pas déjà été sélectionné dans le train et\n",
    "                    # le test pour ne pas faire de doublon\n",
    "                    if example[1] == sense and example[1] == train_ex[1] and not(np.array_equal(example[0], train_ex[0])):\n",
    "                        selected_test.append(example)\n",
    "                        added = True\n",
    "                        break\n",
    "                if added == True:\n",
    "                    break\n",
    "\n",
    "        # SELECTION DES DONNEES RESTANTES DU TRAIN ET DU TEST\n",
    "\n",
    "        # effectue un split sur le reste d'examples disponibles\n",
    "        remaining_X = []\n",
    "        remaining_y = []\n",
    "        selected_train_copy = copy.deepcopy(selected_train)\n",
    "        selected_train_copy.extend(selected_test)\n",
    "        for contexte, sens in zip(x,y):\n",
    "            to_add = True\n",
    "            for ex in selected_train_copy:\n",
    "                # vérifie que l'example n'a pas déjà été sélectionné dans le train et le\n",
    "                # test pour ne pas faire de doublon\n",
    "                if np.array_equal(contexte, ex[0]) and sens == ex[1]:\n",
    "                    to_add = False\n",
    "                    break\n",
    "            if to_add:\n",
    "                remaining_X.append(contexte)\n",
    "                remaining_y.append(sens)\n",
    "\n",
    "        try:\n",
    "            self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(remaining_X, remaining_y,train_size = train_size)\n",
    "    \n",
    "            # ajout des données représentatives dans les sets correspondant\n",
    "            selected_X_train, selected_y_train = zip(*selected_train)\n",
    "            selected_X_test, selected_y_test = zip(*selected_test)\n",
    "            \n",
    "            self.X_train.extend(selected_X_train)\n",
    "            self.X_test.extend(selected_X_test)\n",
    "            self.y_train.extend(selected_y_train)\n",
    "            self.y_test.extend(selected_y_test)\n",
    "\n",
    "        except ValueError as ve:\n",
    "            print(f\"La taille des données ({data_size}) est trop faible. L'opération train_test_split() est impossible.\")                                                                     \n",
    "\n",
    "            \n",
    "        \n",
    "        \n",
    "\n",
    "            \n",
    "    def define_instance(self, instance, data_size, display=True):\n",
    "        '''\n",
    "        Permet de définir l'instance du mot à désambiguiser et les examples à utiliser. \n",
    "        Fixe les derniers arguments de classe selon l'instance choisie.\n",
    "        Contraint le choix de classification selon le nombre de données considéré.\n",
    "\n",
    "        INPUT\n",
    "        instance (str) : mot à désambiguiser\n",
    "        data_size (float): quantité de données à considérer\n",
    "        affichage (bool, optional): affiche une trace des options choisies\n",
    "        '''\n",
    "        ###################################################\n",
    "        # Etape 1: faire le set de données annotées\n",
    "        # choisit des examples d'entraînement représentatifs du corpus selon le nombre\n",
    "        # imposé de données\n",
    "        self.annotated_examples = self.select_examples(self.w2examples[instance],\n",
    "                                                       self.w2senses[instance],\n",
    "                                                       data_size)\n",
    "        # liste de tous les contextes sous forme d'embedding\n",
    "        X_annotated = [self.look_up(context) for context, gold in self.annotated_examples]\n",
    "        # liste de tous les numéros de sens\n",
    "        y_annotated = [gold for context, gold in self.annotated_examples]\n",
    "        # le set des données annotées est une liste des examples représentatifs sous forme d'embeddings\n",
    "        self.selected_examples_embs = list(zip(X_annotated,y_annotated))\n",
    "\n",
    "        ###################################################\n",
    "        # Etape 2: faire le set de données non-annotées\n",
    "        # garde en mémoire les examples considérés comme non-annotés\n",
    "        self.unannotated_examples = [example for example in self.w2examples[instance] \n",
    "                                     if example not in self.annotated_examples]        \n",
    "        # liste de tous les contextes sous forme d'embedding\n",
    "        X_unannotated = [self.look_up(context) for context,gold in self.unannotated_examples]\n",
    "        # liste de tous les numéros de sens\n",
    "        y_unannotated = [gold for context,gold in self.unannotated_examples]\n",
    "        # le set des données non-annotées est une liste des examples sous forme d'embeddings\n",
    "        self.unannotated_set = list(zip(X_unannotated,y_unannotated))\n",
    "\n",
    "        ###################################################\n",
    "        # Etape 3: faire le set de données à classifier par MLPClassifier_WSD\n",
    "        # création des corpus d'entrainement et de test\n",
    "        self.select_train_test(X_annotated, y_annotated, self.w2senses[instance],data_size)\n",
    "        \n",
    "        ###################################################\n",
    "        # Etape 4: affichage des informations relatives à l'instance choisie pour MLPClassifier_WSD\n",
    "        if display :\n",
    "            self.classifier_display_at_instance_time(instance, data_size)\n",
    "            \n",
    "    \n",
    "    # Affichage des informations relatives à l'instance choisie pour MLPClassifier_WSD\n",
    "    def classifier_display_at_instance_time(self, instance, data_size):\n",
    "        print(\"--> Instance :\", instance)\n",
    "        print(f'{data_size*100}% des données annotées considérées')\n",
    "        print(\"Nombre de données d'entraînement : \", len(self.X_train))\n",
    "        print(\"Etiquettes possibles pour cette instance : \", self.w2senses[instance])\n",
    "        print(\"Etiquettes présentes dans les données d'entraînement :\", Counter(self.y_train))\n",
    "        most_frequent_sense = max(self.y_train,key=self.y_train.count)\n",
    "        occurrence_of_most_frequent_sense = self.y_train.count(most_frequent_sense)/len(self.y_train)\n",
    "        print(f\"Les occurrences du sens {most_frequent_sense} sont les plus fréquentes, avec une proportion de {round(occurrence_of_most_frequent_sense*100,2)} %\")\n",
    "    \n",
    "    # Affichage des informations relatives à l'instance choisie pour K_Means\n",
    "    def kmeans_display_at_instance_time(self, instance, num_correct, num_examples, size):\n",
    "        y = [gold for tensor,gold in self.selected_examples_embs] + [gold for tensor,gold in self.unannotated_set] \n",
    "        print(\"--> Instance :\",instance)\n",
    "        print(f\"Proportion de données annotées considérées sur le corpus: {size*100} %\")\n",
    "        print(f\"Répartition des sens: {Counter(y)}\")\n",
    "        most_frequent_sense = max(y,key=y.count)\n",
    "        occurrence_of_most_frequent_sense = y.count(most_frequent_sense)/len(y)\n",
    "        print(f\"Le sens le plus fréquent pour '{instance}' est le sens {most_frequent_sense} avec une proportion de {round(occurrence_of_most_frequent_sense*100,2)} %\")\n",
    "        #print(f\"Pour '{instance}', l'accuracy est de {round(num_correct/num_examples,2)} %\")\n",
    "        print()\n",
    "\n",
    "    def get_sets(self):\n",
    "        return self.X_train, self.X_test, self.y_train, self.y_test\n",
    "    \n",
    "    def get_annotated_and_unannotated_sets(self):\n",
    "        \n",
    "        return self.selected_examples_embs, self.unannotated_set\n",
    "        \n",
    "    def get_annotated_examples(self):\n",
    "        return self.annotated_examples\n",
    "    \n",
    "    def get_unannotated_examples(self):\n",
    "        return self.unannotated_examples\n",
    "    \n",
    "    def get_embs(self):\n",
    "        return self.selected_examples_embs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chemin du corpus annoté\n",
    "data_path = \"../donnees/FSE-1.1-191210/FSE-1.1.data.xml\"\n",
    "# chemin pour récupérer les gold class du corpus annoté\n",
    "gold_path = \"../donnees/FSE-1.1-191210/FSE-1.1.gold.key.txt\"\n",
    "# choix de la fenêtre du contexte\n",
    "context_size = 4\n",
    "# chemin pour récupérer les embeddings afin de faire l'opération look-up\n",
    "# Les embeddings sont extraits de fasttext\n",
    "embeddings_path = \"embeddings.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'set' object has no attribute 'extend'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# exemple d'utilisation d'Extractor avec le verbe \"aboutir\" et 100% des données utilisées\u001b[39;00m\n\u001b[0;32m      2\u001b[0m ext \u001b[39m=\u001b[39m Extractor(data_path, gold_path, embeddings_path, context_size)\n\u001b[1;32m----> 3\u001b[0m ext\u001b[39m.\u001b[39;49mdefine_instance(\u001b[39m\"\u001b[39;49m\u001b[39maboutir\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m0.1\u001b[39;49m, display\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[0;32m      4\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mexemple d\u001b[39m\u001b[39m'\u001b[39m\u001b[39mexample avec contexte et gold class :\u001b[39m\u001b[39m\"\u001b[39m,ext\u001b[39m.\u001b[39mget_annotated_examples()[\u001b[39m0\u001b[39m])\n\u001b[0;32m      5\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mau format embedding : \u001b[39m\u001b[39m\"\u001b[39m,ext\u001b[39m.\u001b[39mget_embs()[\u001b[39m0\u001b[39m])\n",
      "Cell \u001b[1;32mIn[11], line 343\u001b[0m, in \u001b[0;36mExtractor.define_instance\u001b[1;34m(self, instance, data_size, display)\u001b[0m\n\u001b[0;32m    338\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39munannotated_set \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(\u001b[39mzip\u001b[39m(X_unannotated,y_unannotated))\n\u001b[0;32m    340\u001b[0m \u001b[39m###################################################\u001b[39;00m\n\u001b[0;32m    341\u001b[0m \u001b[39m# Etape 3: faire le set de données à classifier par MLPClassifier_WSD\u001b[39;00m\n\u001b[0;32m    342\u001b[0m \u001b[39m# création des corpus d'entrainement et de test\u001b[39;00m\n\u001b[1;32m--> 343\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mselect_train_test(X_annotated, y_annotated, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mw2senses[instance])\n\u001b[0;32m    345\u001b[0m \u001b[39m###################################################\u001b[39;00m\n\u001b[0;32m    346\u001b[0m \u001b[39m# Etape 4: affichage des informations relatives à l'instance choisie pour MLPClassifier_WSD\u001b[39;00m\n\u001b[0;32m    347\u001b[0m \u001b[39mif\u001b[39;00m display :\n",
      "Cell \u001b[1;32mIn[11], line 297\u001b[0m, in \u001b[0;36mExtractor.select_train_test\u001b[1;34m(self, x, y, senses, train_size)\u001b[0m\n\u001b[0;32m    294\u001b[0m selected_X_train, selected_y_train \u001b[39m=\u001b[39m \u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39mselected_train)\n\u001b[0;32m    295\u001b[0m selected_X_test, selected_y_test \u001b[39m=\u001b[39m \u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39mselected_test)\n\u001b[1;32m--> 297\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mX_train\u001b[39m.\u001b[39;49mextend(selected_X_train)\n\u001b[0;32m    298\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mX_test\u001b[39m.\u001b[39mextend(selected_X_test)\n\u001b[0;32m    299\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39my_train\u001b[39m.\u001b[39mextend(selected_y_train)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'set' object has no attribute 'extend'"
     ]
    }
   ],
   "source": [
    "# exemple d'utilisation d'Extractor avec le verbe \"aboutir\" et 100% des données utilisées\n",
    "ext = Extractor(data_path, gold_path, embeddings_path, context_size)\n",
    "ext.define_instance(\"aboutir\", 0.1, display=True)\n",
    "print(\"\\nexemple d'example avec contexte et gold class :\",ext.get_annotated_examples()[0])\n",
    "print(\"\\nau format embedding : \",ext.get_embs()[0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Classification supervisée\n",
    "\n",
    "L'utilisation d'un Classifieur MLP permet de prédire le sens des verbes de façon supervisée. Il s'agit de la première méthode proposée pour la tâche de WSD.\n",
    "\n",
    "Les données utilisées sont les données annotées extraites du fichier FSE grâce à l'Extractor pour un lemme donné. Un MLPClassifier_WSD doit donc être créé pour chaque verbe dont on veut la prédiction.\n",
    "\n",
    "MLPClassifier_WSD comporte les méthodes suivantes :\n",
    "- `classify()` : pour prédire le sens du lemme associé au classifieur et calculer l'accuracy de cette prédiction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPClassifier_WSD :\n",
    "    \n",
    "    def __init__(self, X_train, X_test, y_train, y_test) :\n",
    "        '''\n",
    "        A partir des données, prédit le sens d'un lemme et évalue la prédiction\n",
    "\n",
    "        ARGUMENTS DE CLASSE\n",
    "        self.X_train (list) : liste des contextes d'entraînement\n",
    "        self.y_train (list) : liste des gold class d'entraînement\n",
    "        self.X_test (list) : liste des contextes de test\n",
    "        self.y_test (list) : liste des gold class de test\n",
    "        '''\n",
    "        # ensembles d'entraînement et de test provenant de l'Extractor pour un lemme donné\n",
    "        self.X_train = X_train\n",
    "        self.X_test = X_test\n",
    "        self.y_train = y_train\n",
    "        self.y_test = y_test \n",
    "\n",
    "        # prédiction du modèle\n",
    "        self.y_pred = []\n",
    "        # accuracy de la prédiction\n",
    "        self.accuracy = 0\n",
    "        \n",
    "    def classify(self, affichage=False) :\n",
    "        ''' \n",
    "        Permet de prédire le sens du verbe.\n",
    "\n",
    "        INPUT\n",
    "        affichage (bool, optional) : affiche une trace des options choisies\n",
    "        '''\n",
    "\n",
    "        clf = MLPClassifier(random_state=1, hidden_layer_sizes=(100,)) \n",
    "        # entraînement\n",
    "        clf.fit(self.X_train, self.y_train)\n",
    "        # prédiction\n",
    "        self.y_pred = clf.predict(self.X_test)\n",
    "\n",
    "        # calcul de l'accuracy\n",
    "        self.accuracy = accuracy_score(self.y_pred, self.y_test)\n",
    "        \n",
    "        # si une trace est souhaitée\n",
    "        if affichage :\n",
    "            print(\"prediction :\", self.y_pred)\n",
    "            print(\"gold :\", self.y_test)\n",
    "            print(\"accuracy score : \", self.accuracy,\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction : ['4' '4' '4' '4' '4' '4' '4' '3' '3' '2' '4']\n",
      "gold : ['4', '4', '4', '4', '4', '4', '3', '4', '3', '2', '4']\n",
      "accuracy score :  0.8181818181818182 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# exemple d'utilisation de MLPClassifieur_WSD avec le verbe \"demeurer\" et 100% des données utilisées\n",
    "ext = Extractor(data_path, gold_path, embeddings_path, context_size)\n",
    "ext.define_instance(\"demeurer\", 1, display=False)\n",
    "X_train, X_test, y_train, y_test = ext.get_sets()\n",
    "\n",
    "Clf = MLPClassifier_WSD(X_train, X_test, y_train, y_test)\n",
    "Clf.classify(affichage=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour pouvoir comparer les performances de ce Classifieur MLP avec celles de l'apprentissage semi-supervisé, nous devons créer un classifieur par verbe à désambiguiser et choisir un pas de descente pour la quantité de données annotées considérées.\n",
    "\n",
    "Pour chaque classifieur et chaque quantitée de données considérées, on effectue *n_repeat* classifications pour obtenir une accuracy moyenne représentative du classifieur. \n",
    "\n",
    "Par conséquent, pour :\n",
    "- n_repeat = 5\n",
    "- step = 0.25\n",
    "\n",
    "nous obtiendrons pour chaque classifieur une liste d'accuracies correspondant à :\n",
    "- la moyenne des accuracies de 5 prédictions \n",
    "- pour 100%, 75%, 50% et 25% des données."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mean_accuracy(instance, data_size, n_repeat, affichage=True):\n",
    "    '''\n",
    "    Retourne une moyenne d'accuracies pour un nombre de classifications donné.\n",
    "\n",
    "    INPUT\n",
    "    n_repeat (int): nombre de classifications à effectuer\n",
    "    affichage (bool, optional): affiche une trace des options choisies\n",
    "\n",
    "    OUTPUT\n",
    "    mean (float): moyenne des accuracies calculées\n",
    "    '''\n",
    "\n",
    "    # liste de l'accuracy à chaque répétition\n",
    "    accuracies = []\n",
    "        \n",
    "    for _ in range(n_repeat) :\n",
    "            \n",
    "        # pour chaque itération, un nouveau classifieur est créé, qui s'appuie toujours sur \n",
    "        # la même quantité de données mais avec un autre tirage des données\n",
    "        # par exemple, pour 75% des données, des accuracies différentes seront obtenues en\n",
    "        # fonction des tirages de ces données\n",
    "        ext.define_instance(instance, data_size, False)\n",
    "        X_train, X_test, y_train, y_test = ext.get_sets()\n",
    "        Clf = MLPClassifier_WSD(X_train, X_test, y_train, y_test)\n",
    "        Clf.classify()\n",
    "            \n",
    "        accuracies.append(Clf.accuracy)\n",
    "        mean = sum(accuracies)/len(accuracies)\n",
    "            \n",
    "    # si la trace est souhaitée\n",
    "    if affichage :\n",
    "        print(f'{data_size*100}% des données annotées considérées')\n",
    "        print(\"instance :\", instance)\n",
    "        print(\"accuracies :\", accuracies)\n",
    "        print(\"accuracy moyenne :\", mean, \"\\n\")\n",
    "\n",
    "    return mean\n",
    "\n",
    "def get_accuracies(instances, step, n_repeat, affichage=True):\n",
    "    '''\n",
    "    - Permet d'obtenir une accuracy moyenne par lemme pour une certaine quantité \n",
    "      de données considérée.\n",
    "    - Produit un fichier csv.\n",
    "\n",
    "    INPUT\n",
    "    instances (list): liste des mots à désambiguiser\n",
    "    step (float): pas de descente dans la quantité de données à considérer\n",
    "    n_repeat (int): nombre de classifications tests à effectuer\n",
    "\n",
    "    OUTPUT\n",
    "    instance2acc (dict) : associe à chaque instance sa liste d'accuracies moyennes\n",
    "    '''\n",
    "\n",
    "    # clé : mot à désambiguiser\n",
    "    # valeur : liste des accuracies moyennes à chaque pas de descente\n",
    "    instance2acc = {instance : [] for instance in instances}\n",
    "    moyennes = []\n",
    "    data_sizes =[]\n",
    "            \n",
    "    # pour chaque quantité de données observée\n",
    "    for i in range(round(1.0/step)): \n",
    "                \n",
    "        # calcul de la taille des données avec le pas de descente (100%, 75%, 50%, 25%)\n",
    "        data_size = 1.0 - (step*float(i))\n",
    "        data_sizes.append(data_size)\n",
    "        \n",
    "        # pour chaque mot à désambiguiser\n",
    "        for instance in instances :\n",
    "            # calcul de son accuracy moyenne\n",
    "            instance2acc[instance].append(get_mean_accuracy(instance, data_size, n_repeat, affichage))\n",
    "\n",
    "        # on boucle sur les valeurs obtenues pour obtenir leur moyenne\n",
    "        moyennes.append(sum([accuracies[i] for accuracies in instance2acc.values()])/len(instance2acc))\n",
    "  \n",
    "    # ajout d'une clé moyennes pour avoir les moyennes de toutes les accuracy moyennes pour chaque instance\n",
    "    # pour chaque pas\n",
    "    instance2acc[\"moyennes\"] = moyennes\n",
    "            \n",
    "    # ajout d'une clé pour stocker les tailles des données à chaque pas\n",
    "    instance2acc[\"data_sizes\"] = data_sizes \n",
    "\n",
    "    # export en csv des résultats\n",
    "    df = pd.DataFrame(instance2acc)\n",
    "    df.set_index(\"data_sizes\")\n",
    "    df.to_csv(f\"accuracies_par_lemme_{n_repeat}_repet.csv\")\n",
    "    \n",
    "    return instance2acc     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pas de descente dans la quantité de données considérées\n",
    "step = 0.25\n",
    "# nombre de classifications pour un classifieur pour obtenir une accuracy moyenne\n",
    "n_repeat = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# récupération de tous les verbes du corpus à désambiguiser\\ninstances = list(ext.w2examples.keys())\\n# calcul des accuracies\\nget_accuracies(instances, step, n_repeat)'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''# récupération de tous les verbes du corpus à désambiguiser\n",
    "instances = list(ext.w2examples.keys())\n",
    "# calcul des accuracies\n",
    "get_accuracies(instances, step, n_repeat)'''"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification semi-supervisée"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import pandas as pd\n",
    "import random\n",
    "from collections import Counter\n",
    "\n",
    "class K_Means():\n",
    "    ''' \n",
    "    classifieur K-means pour un mot particulier\n",
    "    '''\n",
    "\n",
    "    def __init__(self, annotated_examples, not_annotated_examples):\n",
    "        '''\n",
    "        Instancie les différentes variables utiles pour l'algorithme du K-means\n",
    "\n",
    "        examples : liste d'examples dont le mot à désambiguiser est le même pour \n",
    "                   chaque example\n",
    "        example : couple d'un mot avec son contexte de fenêtre 4 (sous forme \n",
    "                  d'embedding) et du numéro de sens attendu du mot à désambiguiser \n",
    "                  (gold class sous forme d'integer)\n",
    "                    si example = ([1.9, 2.3, 0.6], 1),\n",
    "                    - le contexte avec le mot à désambiguiser et son lemme est \n",
    "                      l'embedding [1.9, 2.3, 0.6]\n",
    "                    - le numéro de sens est 1\n",
    "        '''\n",
    "\n",
    "        # transforme l'ensemble des examples en une liste pour pouvoir garder le \n",
    "        # même indice pour chaque example par la suite\n",
    "        self.annotated_examples = annotated_examples\n",
    "\n",
    "        # on a le gold, mais on ne l'utilisera que pour calculer l'accuracy\n",
    "        # pour le training, nous ferons comme si nous n'avions pas la gold class\n",
    "        self.not_annotated_examples = not_annotated_examples\n",
    "\n",
    "        # transforme les embeddings en tensors\n",
    "        # ce sont les exemples qui devront être classifiés\n",
    "        self.tensors_examples = [example[0] for example in self.not_annotated_examples]\n",
    "\n",
    "        # détermine le nombre de sens possibles k (donc le nombre de clusters) \n",
    "        # à l'aide des données annotées, qui représentent tous les sens possibles\n",
    "        self.k = len(set([example[1] for example in self.annotated_examples]))\n",
    "        \n",
    "        # initialisation des centroïdes : pour chaque sens, le centroïde \n",
    "        # correspond à la moyenne des embeddings des exemples annotés\n",
    "        # Ainsi, chaque centroïde représente un sens\n",
    "        self.tensors_centroids, self.cluster2sense = self.make_centroids()\n",
    "\n",
    "        #initialisation d'un dataframe à partir de self.tensors_centroids\n",
    "        # rows: cluster number (k), columns: dimension number (len(tensors_examples[0]))\n",
    "        self.new_centroids = pd.DataFrame(self.tensors_centroids).astype(\"float\")\n",
    "        #print(self.new_centroids.head())\n",
    "        # initialisation de clusters : tous les examples sont associés au cluster 0\n",
    "        self.clusters = np.zeros(len(not_annotated_examples))\n",
    "        #random number between 0 and k-1 for each example\n",
    "        #self.clusters = np.asarray([random.randint(0,self.k-1) for i in range(len(not_annotated_examples))])\n",
    "\n",
    "\n",
    "    def make_centroids(self):\n",
    "        cluster2sense = []\n",
    "        tensors_centroids = []\n",
    "        senses = set([example[1] for example in self.annotated_examples])\n",
    "        for sense in senses: \n",
    "            # on récupère les examples du sens\n",
    "            examples_sense = [example[0] for example in self.annotated_examples if example[1] == sense]\n",
    "            # on calcule le centroid du sens\n",
    "            centroid = torch.mean(torch.stack(examples_sense), dim=0)\n",
    "            # on ajoute le centroid à la liste des centroids\n",
    "            tensors_centroids.append(centroid)\n",
    "            # on ajoute le sens à la liste des sens\n",
    "            #L'index du sens correspond au numéro du cluster\n",
    "            cluster2sense.append(sense)\n",
    "\n",
    "        return tensors_centroids, cluster2sense\n",
    "    \n",
    "\n",
    "    def update_new_centroids_dataframe(self):\n",
    "        # étape 1: on regroupe tous les tenseurs des exemples ayant le même cluster dans self.clusters et on fait la moyenne\n",
    "        tmp_new_centroids = pd.DataFrame(self.tensors_examples).groupby(by = self.clusters).mean() #shape : [k, len(tensors_examples[0])]\n",
    "        # étape 2: on détermine quels sont les clusters qui ont été assignés à au moins un exemple dans self.clusters\n",
    "        clus, counts = np.unique(self.clusters, return_counts=True)\n",
    "        #print(dict(zip(clus, counts)))\n",
    "        # étape 3: pour chaque cluster qui n'a pas d'exemple assigné, on insère un row vide dans tmp_new_centroids à l'index correspondant\n",
    "        row_to_insert = [[np.nan] * self.new_centroids.shape[1]]\n",
    "        for i in range(self.k): \n",
    "            if i not in clus:\n",
    "                tmp_new_centroids = pd.concat([tmp_new_centroids.iloc[:i], pd.DataFrame(row_to_insert, columns=tmp_new_centroids.columns), tmp_new_centroids.iloc[i:]]).reset_index(drop=True)\n",
    "        # étape 4: on remplace dans self.new_centroids les rows non vides de tmp_new_centroids \n",
    "        self.new_centroids.update(tmp_new_centroids)\n",
    "\n",
    "\n",
    "    def learn_clusters(self):\n",
    "        '''\n",
    "        Algorithme de K-Means\n",
    "        Retourne les coordonnées de chaque centroide ainsi que le cluster auquel \n",
    "        appartient chaque example\n",
    "        '''\n",
    "\n",
    "        # différence initialisée à Vrai\n",
    "        diff = True\n",
    "        \n",
    "        # tant qu'il y a une différence entre l'ancienne liste et la nouvelle \n",
    "        # liste de centroides\n",
    "        #while diff:\n",
    "        for i in range(10):\n",
    "\n",
    "            # CALCUL DES DISTANCES ENTRE CHAQUE EXAMPLE ET CHAQUE CENTROIDE\n",
    "         \n",
    "            # pour chaque couple (indice, coordonnées) dans les examples\n",
    "            for i, tensor_example in enumerate(self.tensors_examples):\n",
    "                # initialisation de la distance minimum à l'infini\n",
    "                min_dist = float('inf')\n",
    "                # pour chaque couple (indice, coordonnées) dans les centroides\n",
    "                for j, tensor_centroid in enumerate(self.tensors_centroids):\n",
    "                    # calcul de la distance entre cet example et ce centroide\n",
    "                    d = (tensor_centroid - tensor_example).pow(2).sum(axis=0).sqrt()\n",
    "                    # si une distance plus faible est trouvée\n",
    "                    if min_dist > d:\n",
    "                        # la distance ainsi que le centroide sont stockés\n",
    "                        min_dist = d\n",
    "                        self.clusters[i] = j\n",
    "            \n",
    "\n",
    "            #mise à jour des centroïdes: \n",
    "            self.update_new_centroids_dataframe()\n",
    "            \n",
    "            tensors_new_centroids = []\n",
    "            \n",
    "            #pour chaque cluster (donc chaque ligne de new_centroids)\n",
    "            for i in range(len(self.new_centroids.index)):\n",
    "                centroid = []\n",
    "                #pour chaque dimension du vecteur moyen assigné au cluster\n",
    "                for j in range(len(self.new_centroids.columns)):\n",
    "                    # recréee le vecteur\n",
    "                    centroid.append(int(self.new_centroids.iat[i,j]))\n",
    "                #et rassemble les nouveaux tenseurs des centroides dans une liste\n",
    "                tensors_new_centroids.append(torch.tensor(centroid))\n",
    "\n",
    "            # MISE A JOUR DES CENTROIDES\n",
    "            count_diff = 0\n",
    "            # pour chaque centroide\n",
    "            for i in range(len(self.tensors_centroids)):\n",
    "                # si l'ancien centroide et le nouveau ne sont pas les mêmes\n",
    "                if not(torch.equal(self.tensors_centroids[i], tensors_new_centroids[i])):\n",
    "                    count_diff += 1\n",
    "                    # met à jour le centroide\n",
    "                    self.tensors_centroids = tensors_new_centroids\n",
    "            # s'il n'y a eu aucune différence entre les anciens et les nouveaux centroides, \n",
    "            # la boucle while se termine\n",
    "            if count_diff == 0:\n",
    "                diff = False\n",
    "            \n",
    "            \n",
    "\n",
    "    def accuracy(self): \n",
    "        correct = 0\n",
    "        for i in range(len(self.not_annotated_examples)):\n",
    "            sens_attendu = self.not_annotated_examples[i][1]\n",
    "            sens_assigne = self.cluster2sense[int(self.clusters[i])]\n",
    "            if sens_attendu == sens_assigne:\n",
    "                correct += 1\n",
    "        return correct, len(self.not_annotated_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mean_accuracy(instance, data_size, n_repeat, affichage=True):\n",
    "    '''\n",
    "    Retourne une moyenne d'accuracies pour un nombre de classifications donné.\n",
    "\n",
    "    INPUT\n",
    "    n_repeat (int): nombre de classifications à effectuer\n",
    "    affichage (bool, optional): affiche une trace des options choisies\n",
    "\n",
    "    OUTPUT\n",
    "    mean (float): moyenne des accuracies calculées\n",
    "    '''\n",
    "\n",
    "    # liste de l'accuracy à chaque répétition\n",
    "\n",
    "\n",
    "    accuracies = []\n",
    "    accuracy_instances = []\n",
    "    list_num_correct = []\n",
    "    list_num_examples = []\n",
    "        \n",
    "    for _ in range(n_repeat) :\n",
    "            \n",
    "        # pour chaque itération, un nouveau classifieur est créé, qui s'appuie toujours sur \n",
    "        # la même quantité de données mais avec un autre tirage des données\n",
    "        # par exemple, pour 75% des données, des accuracies différentes seront obtenues en\n",
    "        # fonction des tirages de ces données\n",
    "        ext.define_instance(instance, data_size, False)\n",
    "        \n",
    "        annotated_set, unannotated_set = ext.get_annotated_and_unannotated_sets()\n",
    "        annotated_set = [(torch.from_numpy(embedding),sense) for embedding,sense in annotated_set]\n",
    "        unannotated_set = [(torch.from_numpy(embedding),gold) for embedding,gold in unannotated_set]\n",
    "        k_Means = K_Means(annotated_set, unannotated_set)\n",
    "        k_Means.learn_clusters()\n",
    "        \n",
    "        correct, num_examples = k_Means.accuracy()\n",
    "        \n",
    "        if _ == n_repeat-1:\n",
    "            ext.kmeans_display_at_instance_time(instance, correct, num_examples, data_size)\n",
    "        accuracies.append(correct/num_examples)\n",
    "        mean = sum(accuracies)/len(accuracies)\n",
    "        \n",
    "        list_num_correct.append(correct)\n",
    "        list_num_examples.append(num_examples)\n",
    "        accuracy_instances.append(correct/num_examples)\n",
    "\n",
    "        # si la trace est souhaitée\n",
    "        if affichage and _ == n_repeat-1:\n",
    "            print(\"Accuracies :\", accuracies)\n",
    "            print(f\"Accuracy moyenne sur {n_repeat} répétitions:\", mean)\n",
    "            print()\n",
    "    accuracy_kmeans = sum(accuracy_instances)/len(accuracy_instances)\n",
    "    print(f\"Macro-average : {round(accuracy_kmeans,2)}\")\n",
    "    micro_average = sum(list_num_correct)/sum(list_num_examples)\n",
    "    print(f\"Micro-average : {round(micro_average,2)}\")\n",
    "    print(\"\\n--------------------------------------------------\\n\")\n",
    "    return mean\n",
    "\n",
    "def get_accuracies(instances, step, n_repeat, display=True):\n",
    "    '''\n",
    "    - Permet d'obtenir une accuracy moyenne par lemme pour une certaine quantité \n",
    "      de données considérée.\n",
    "    - Produit un fichier csv.\n",
    "\n",
    "    INPUT\n",
    "    instances (list): liste des mots à désambiguiser\n",
    "    step (float): pas de descente dans la quantité de données à considérer\n",
    "    n_repeat (int): nombre de classifications tests à effectuer\n",
    "\n",
    "    OUTPUT\n",
    "    instance2acc (dict) : associe à chaque instance sa liste d'accuracies moyennes\n",
    "    '''\n",
    "\n",
    "    # clé : mot à désambiguiser\n",
    "    # valeur : liste des accuracies moyennes à chaque pas de descente\n",
    "    instance2acc = {instance : [] for instance in instances}\n",
    "    moyennes = []\n",
    "    data_sizes =[]\n",
    "    \n",
    "\n",
    "    # pour chaque quantité de données observée\n",
    "    for i in range(round(1.0/step)): \n",
    "                \n",
    "        # calcul de la taille des données avec le pas de descente (100%, 75%, 50%, 25%)\n",
    "        data_size = 0.9 - (step*float(i))\n",
    "        data_sizes.append(data_size)\n",
    "        \n",
    "        # pour chaque mot à désambiguiser\n",
    "        for instance in instances :\n",
    "            # calcul de son accuracy moyenne\n",
    "            mean = get_mean_accuracy(instance, data_size, n_repeat, display)\n",
    "            instance2acc[instance].append(mean)\n",
    "        # on boucle sur les valeurs obtenues pour obtenir leur moyenne\n",
    "        moyennes.append(sum([accuracies[i] for accuracies in instance2acc.values()])/len(instance2acc))\n",
    "  \n",
    "    # ajout d'une clé moyennes pour avoir les moyennes de toutes les accuracy moyennes pour chaque instance\n",
    "    # pour chaque pas\n",
    "    instance2acc[\"moyennes\"] = moyennes\n",
    "            \n",
    "    # ajout d'une clé pour stocker les tailles des données à chaque pas\n",
    "    instance2acc[\"data_sizes\"] = data_sizes \n",
    "\n",
    "    # export en csv des résultats\n",
    "    df = pd.DataFrame(instance2acc)\n",
    "    df.set_index(\"data_sizes\")\n",
    "    df.to_csv(f\"kmeans_accuracies_par_lemme_{n_repeat}_repet.csv\")\n",
    "    \n",
    "    return instance2acc  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pas de descente dans la quantité de données considérées\n",
    "step = 0.15\n",
    "# nombre de classifications pour un classifieur pour obtenir une accuracy moyenne\n",
    "n_repeat = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--> Instance : aboutir\n",
      "Proportion de données annotées considérées sur le corpus: 90.0 %\n",
      "Répartition des sens: Counter({'3': 41, '4': 7, '1': 1, '2': 1})\n",
      "Le sens le plus fréquent pour 'aboutir' est le sens 3 avec une proportion de 82.0 %\n",
      "\n",
      "Accuracies : [0.8, 0.2, 0.8, 0.4, 0.6]\n",
      "Accuracy moyenne sur 5 répétitions: 0.56\n",
      "\n",
      "Macro-average : 0.56\n",
      "Micro-average : 0.56\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "--> Instance : investir\n",
      "Proportion de données annotées considérées sur le corpus: 90.0 %\n",
      "Répartition des sens: Counter({'4': 34, '3': 11, '1': 4, '2': 1})\n",
      "Le sens le plus fréquent pour 'investir' est le sens 4 avec une proportion de 68.0 %\n",
      "\n",
      "Accuracies : [0.4, 0.0, 0.2, 0.2, 0.0]\n",
      "Accuracy moyenne sur 5 répétitions: 0.16\n",
      "\n",
      "Macro-average : 0.16\n",
      "Micro-average : 0.16\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "--> Instance : traduire\n",
      "Proportion de données annotées considérées sur le corpus: 90.0 %\n",
      "Répartition des sens: Counter({'1': 26, '5': 15, '4': 9})\n",
      "Le sens le plus fréquent pour 'traduire' est le sens 1 avec une proportion de 52.0 %\n",
      "\n",
      "Accuracies : [0.8, 0.6, 0.2, 0.4, 0.6]\n",
      "Accuracy moyenne sur 5 répétitions: 0.52\n",
      "\n",
      "Macro-average : 0.52\n",
      "Micro-average : 0.52\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "--> Instance : aboutir\n",
      "Proportion de données annotées considérées sur le corpus: 75.0 %\n",
      "Répartition des sens: Counter({'3': 41, '4': 7, '1': 1, '2': 1})\n",
      "Le sens le plus fréquent pour 'aboutir' est le sens 3 avec une proportion de 82.0 %\n",
      "\n",
      "Accuracies : [0.4166666666666667, 0.16666666666666666, 0.25, 0.0, 0.3333333333333333]\n",
      "Accuracy moyenne sur 5 répétitions: 0.23333333333333334\n",
      "\n",
      "Macro-average : 0.23\n",
      "Micro-average : 0.23\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "--> Instance : investir\n",
      "Proportion de données annotées considérées sur le corpus: 75.0 %\n",
      "Répartition des sens: Counter({'4': 34, '3': 11, '1': 4, '2': 1})\n",
      "Le sens le plus fréquent pour 'investir' est le sens 4 avec une proportion de 68.0 %\n",
      "\n",
      "Accuracies : [0.0, 0.0, 0.25, 0.0, 0.16666666666666666]\n",
      "Accuracy moyenne sur 5 répétitions: 0.08333333333333333\n",
      "\n",
      "Macro-average : 0.08\n",
      "Micro-average : 0.08\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "--> Instance : traduire\n",
      "Proportion de données annotées considérées sur le corpus: 75.0 %\n",
      "Répartition des sens: Counter({'1': 26, '5': 15, '4': 9})\n",
      "Le sens le plus fréquent pour 'traduire' est le sens 1 avec une proportion de 52.0 %\n",
      "\n",
      "Accuracies : [0.5833333333333334, 0.08333333333333333, 0.4166666666666667, 0.5, 0.5833333333333334]\n",
      "Accuracy moyenne sur 5 répétitions: 0.4333333333333334\n",
      "\n",
      "Macro-average : 0.43\n",
      "Micro-average : 0.43\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "--> Instance : aboutir\n",
      "Proportion de données annotées considérées sur le corpus: 60.00000000000001 %\n",
      "Répartition des sens: Counter({'3': 41, '4': 7, '1': 1, '2': 1})\n",
      "Le sens le plus fréquent pour 'aboutir' est le sens 3 avec une proportion de 82.0 %\n",
      "\n",
      "Accuracies : [0.0, 0.21052631578947367, 0.5263157894736842, 0.21052631578947367, 0.05263157894736842]\n",
      "Accuracy moyenne sur 5 répétitions: 0.2\n",
      "\n",
      "Macro-average : 0.2\n",
      "Micro-average : 0.2\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "--> Instance : investir\n",
      "Proportion de données annotées considérées sur le corpus: 60.00000000000001 %\n",
      "Répartition des sens: Counter({'4': 34, '3': 11, '1': 4, '2': 1})\n",
      "Le sens le plus fréquent pour 'investir' est le sens 4 avec une proportion de 68.0 %\n",
      "\n",
      "Accuracies : [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Accuracy moyenne sur 5 répétitions: 0.0\n",
      "\n",
      "Macro-average : 0.0\n",
      "Micro-average : 0.0\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "--> Instance : traduire\n",
      "Proportion de données annotées considérées sur le corpus: 60.00000000000001 %\n",
      "Répartition des sens: Counter({'1': 26, '5': 15, '4': 9})\n",
      "Le sens le plus fréquent pour 'traduire' est le sens 1 avec une proportion de 52.0 %\n",
      "\n",
      "Accuracies : [0.5263157894736842, 0.631578947368421, 0.10526315789473684, 0.631578947368421, 0.631578947368421]\n",
      "Accuracy moyenne sur 5 répétitions: 0.5052631578947369\n",
      "\n",
      "Macro-average : 0.51\n",
      "Micro-average : 0.51\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "--> Instance : aboutir\n",
      "Proportion de données annotées considérées sur le corpus: 45.00000000000001 %\n",
      "Répartition des sens: Counter({'3': 41, '4': 7, '1': 1, '2': 1})\n",
      "Le sens le plus fréquent pour 'aboutir' est le sens 3 avec une proportion de 82.0 %\n",
      "\n",
      "Accuracies : [0.14814814814814814, 0.2962962962962963, 0.2222222222222222, 0.1111111111111111, 0.5555555555555556]\n",
      "Accuracy moyenne sur 5 répétitions: 0.26666666666666666\n",
      "\n",
      "Macro-average : 0.27\n",
      "Micro-average : 0.27\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "--> Instance : investir\n",
      "Proportion de données annotées considérées sur le corpus: 45.00000000000001 %\n",
      "Répartition des sens: Counter({'4': 34, '3': 11, '1': 4, '2': 1})\n",
      "Le sens le plus fréquent pour 'investir' est le sens 4 avec une proportion de 68.0 %\n",
      "\n",
      "Accuracies : [0.1111111111111111, 0.0, 0.1111111111111111, 0.0, 0.18518518518518517]\n",
      "Accuracy moyenne sur 5 répétitions: 0.08148148148148147\n",
      "\n",
      "Macro-average : 0.08\n",
      "Micro-average : 0.08\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "--> Instance : traduire\n",
      "Proportion de données annotées considérées sur le corpus: 45.00000000000001 %\n",
      "Répartition des sens: Counter({'1': 26, '5': 15, '4': 9})\n",
      "Le sens le plus fréquent pour 'traduire' est le sens 1 avec une proportion de 52.0 %\n",
      "\n",
      "Accuracies : [0.48148148148148145, 0.5555555555555556, 0.2222222222222222, 0.48148148148148145, 0.4074074074074074]\n",
      "Accuracy moyenne sur 5 répétitions: 0.4296296296296296\n",
      "\n",
      "Macro-average : 0.43\n",
      "Micro-average : 0.43\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "--> Instance : aboutir\n",
      "Proportion de données annotées considérées sur le corpus: 30.000000000000004 %\n",
      "Répartition des sens: Counter({'3': 41, '4': 7, '1': 1, '2': 1})\n",
      "Le sens le plus fréquent pour 'aboutir' est le sens 3 avec une proportion de 82.0 %\n",
      "\n",
      "Accuracies : [0.08823529411764706, 0.6176470588235294, 0.5294117647058824, 0.08823529411764706, 0.08823529411764706]\n",
      "Accuracy moyenne sur 5 répétitions: 0.2823529411764706\n",
      "\n",
      "Macro-average : 0.28\n",
      "Micro-average : 0.28\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "--> Instance : investir\n",
      "Proportion de données annotées considérées sur le corpus: 30.000000000000004 %\n",
      "Répartition des sens: Counter({'4': 34, '3': 11, '1': 4, '2': 1})\n",
      "Le sens le plus fréquent pour 'investir' est le sens 4 avec une proportion de 68.0 %\n",
      "\n",
      "Accuracies : [0.0, 0.0, 0.029411764705882353, 0.0, 0.0]\n",
      "Accuracy moyenne sur 5 répétitions: 0.0058823529411764705\n",
      "\n",
      "Macro-average : 0.01\n",
      "Micro-average : 0.01\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "--> Instance : traduire\n",
      "Proportion de données annotées considérées sur le corpus: 30.000000000000004 %\n",
      "Répartition des sens: Counter({'1': 26, '5': 15, '4': 9})\n",
      "Le sens le plus fréquent pour 'traduire' est le sens 1 avec une proportion de 52.0 %\n",
      "\n",
      "Accuracies : [0.47058823529411764, 0.5294117647058824, 0.5, 0.5588235294117647, 0.5]\n",
      "Accuracy moyenne sur 5 répétitions: 0.5117647058823529\n",
      "\n",
      "Macro-average : 0.51\n",
      "Micro-average : 0.51\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "--> Instance : aboutir\n",
      "Proportion de données annotées considérées sur le corpus: 15.000000000000002 %\n",
      "Répartition des sens: Counter({'3': 41, '4': 7, '1': 1, '2': 1})\n",
      "Le sens le plus fréquent pour 'aboutir' est le sens 3 avec une proportion de 82.0 %\n",
      "\n",
      "Accuracies : [0.047619047619047616, 0.07142857142857142, 0.047619047619047616, 0.11904761904761904, 0.07142857142857142]\n",
      "Accuracy moyenne sur 5 répétitions: 0.07142857142857142\n",
      "\n",
      "Macro-average : 0.07\n",
      "Micro-average : 0.07\n",
      "\n",
      "--------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "With n_samples=1, test_size=None and train_size=0.8, the resulting train set will be empty. Adjust any of the aforementioned parameters.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m instances \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(ext\u001b[39m.\u001b[39mw2examples\u001b[39m.\u001b[39mkeys())[:\u001b[39m3\u001b[39m]\n\u001b[0;32m      3\u001b[0m \u001b[39m# calcul des accuracies\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m get_accuracies(instances, step, n_repeat)\n",
      "Cell \u001b[1;32mIn[24], line 90\u001b[0m, in \u001b[0;36mget_accuracies\u001b[1;34m(instances, step, n_repeat, display)\u001b[0m\n\u001b[0;32m     87\u001b[0m \u001b[39m# pour chaque mot à désambiguiser\u001b[39;00m\n\u001b[0;32m     88\u001b[0m \u001b[39mfor\u001b[39;00m instance \u001b[39min\u001b[39;00m instances :\n\u001b[0;32m     89\u001b[0m     \u001b[39m# calcul de son accuracy moyenne\u001b[39;00m\n\u001b[1;32m---> 90\u001b[0m     mean \u001b[39m=\u001b[39m get_mean_accuracy(instance, data_size, n_repeat, display)\n\u001b[0;32m     91\u001b[0m     instance2acc[instance]\u001b[39m.\u001b[39mappend(mean)\n\u001b[0;32m     92\u001b[0m \u001b[39m# on boucle sur les valeurs obtenues pour obtenir leur moyenne\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[24], line 27\u001b[0m, in \u001b[0;36mget_mean_accuracy\u001b[1;34m(instance, data_size, n_repeat, affichage)\u001b[0m\n\u001b[0;32m     19\u001b[0m list_num_examples \u001b[39m=\u001b[39m []\n\u001b[0;32m     21\u001b[0m \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(n_repeat) :\n\u001b[0;32m     22\u001b[0m         \n\u001b[0;32m     23\u001b[0m     \u001b[39m# pour chaque itération, un nouveau classifieur est créé, qui s'appuie toujours sur \u001b[39;00m\n\u001b[0;32m     24\u001b[0m     \u001b[39m# la même quantité de données mais avec un autre tirage des données\u001b[39;00m\n\u001b[0;32m     25\u001b[0m     \u001b[39m# par exemple, pour 75% des données, des accuracies différentes seront obtenues en\u001b[39;00m\n\u001b[0;32m     26\u001b[0m     \u001b[39m# fonction des tirages de ces données\u001b[39;00m\n\u001b[1;32m---> 27\u001b[0m     ext\u001b[39m.\u001b[39;49mdefine_instance(instance, data_size, \u001b[39mFalse\u001b[39;49;00m)\n\u001b[0;32m     29\u001b[0m     annotated_set, unannotated_set \u001b[39m=\u001b[39m ext\u001b[39m.\u001b[39mget_annotated_and_unannotated_sets()\n\u001b[0;32m     30\u001b[0m     annotated_set \u001b[39m=\u001b[39m [(torch\u001b[39m.\u001b[39mfrom_numpy(embedding),sense) \u001b[39mfor\u001b[39;00m embedding,sense \u001b[39min\u001b[39;00m annotated_set]\n",
      "Cell \u001b[1;32mIn[15], line 342\u001b[0m, in \u001b[0;36mExtractor.define_instance\u001b[1;34m(self, instance, data_size, display)\u001b[0m\n\u001b[0;32m    337\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39munannotated_set \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(\u001b[39mzip\u001b[39m(X_unannotated,y_unannotated))\n\u001b[0;32m    339\u001b[0m \u001b[39m###################################################\u001b[39;00m\n\u001b[0;32m    340\u001b[0m \u001b[39m# Etape 3: faire le set de données à classifier par MLPClassifier_WSD\u001b[39;00m\n\u001b[0;32m    341\u001b[0m \u001b[39m# création des corpus d'entrainement et de test\u001b[39;00m\n\u001b[1;32m--> 342\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mselect_train_test(X_annotated, y_annotated, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mw2senses[instance])\n\u001b[0;32m    344\u001b[0m \u001b[39m###################################################\u001b[39;00m\n\u001b[0;32m    345\u001b[0m \u001b[39m# Etape 4: affichage des informations relatives à l'instance choisie pour MLPClassifier_WSD\u001b[39;00m\n\u001b[0;32m    346\u001b[0m \u001b[39mif\u001b[39;00m display :\n",
      "Cell \u001b[1;32mIn[15], line 289\u001b[0m, in \u001b[0;36mExtractor.select_train_test\u001b[1;34m(self, x, y, senses, train_size)\u001b[0m\n\u001b[0;32m    286\u001b[0m         remaining_X\u001b[39m.\u001b[39mappend(contexte)\n\u001b[0;32m    287\u001b[0m         remaining_y\u001b[39m.\u001b[39mappend(sens)\n\u001b[1;32m--> 289\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mX_train, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mX_test, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39my_train, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39my_test \u001b[39m=\u001b[39m train_test_split(remaining_X, remaining_y, \n\u001b[0;32m    290\u001b[0m                                                                         train_size \u001b[39m=\u001b[39;49m train_size)\n\u001b[0;32m    292\u001b[0m \u001b[39m# ajout des données représentatives dans les sets correspondant\u001b[39;00m\n\u001b[0;32m    293\u001b[0m selected_X_train, selected_y_train \u001b[39m=\u001b[39m \u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39mselected_train)\n",
      "File \u001b[1;32mc:\\Users\\Utilisateur\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:2562\u001b[0m, in \u001b[0;36mtrain_test_split\u001b[1;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[0;32m   2559\u001b[0m arrays \u001b[39m=\u001b[39m indexable(\u001b[39m*\u001b[39marrays)\n\u001b[0;32m   2561\u001b[0m n_samples \u001b[39m=\u001b[39m _num_samples(arrays[\u001b[39m0\u001b[39m])\n\u001b[1;32m-> 2562\u001b[0m n_train, n_test \u001b[39m=\u001b[39m _validate_shuffle_split(\n\u001b[0;32m   2563\u001b[0m     n_samples, test_size, train_size, default_test_size\u001b[39m=\u001b[39;49m\u001b[39m0.25\u001b[39;49m\n\u001b[0;32m   2564\u001b[0m )\n\u001b[0;32m   2566\u001b[0m \u001b[39mif\u001b[39;00m shuffle \u001b[39mis\u001b[39;00m \u001b[39mFalse\u001b[39;00m:\n\u001b[0;32m   2567\u001b[0m     \u001b[39mif\u001b[39;00m stratify \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Utilisateur\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:2236\u001b[0m, in \u001b[0;36m_validate_shuffle_split\u001b[1;34m(n_samples, test_size, train_size, default_test_size)\u001b[0m\n\u001b[0;32m   2233\u001b[0m n_train, n_test \u001b[39m=\u001b[39m \u001b[39mint\u001b[39m(n_train), \u001b[39mint\u001b[39m(n_test)\n\u001b[0;32m   2235\u001b[0m \u001b[39mif\u001b[39;00m n_train \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m-> 2236\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m   2237\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWith n_samples=\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m, test_size=\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m and train_size=\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m, the \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   2238\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mresulting train set will be empty. Adjust any of the \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   2239\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39maforementioned parameters.\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(n_samples, test_size, train_size)\n\u001b[0;32m   2240\u001b[0m     )\n\u001b[0;32m   2242\u001b[0m \u001b[39mreturn\u001b[39;00m n_train, n_test\n",
      "\u001b[1;31mValueError\u001b[0m: With n_samples=1, test_size=None and train_size=0.8, the resulting train set will be empty. Adjust any of the aforementioned parameters."
     ]
    }
   ],
   "source": [
    "# récupération de tous les verbes du corpus à désambiguiser\n",
    "instances = list(ext.w2examples.keys())[:3]\n",
    "# calcul des accuracies\n",
    "get_accuracies(instances, step, n_repeat)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
