{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "import pandas as pd\n",
    "from collections import Counter, defaultdict\n",
    "import xml.etree.ElementTree as ET\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WSD"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ce notebook permet d'effectuer des tests de comparaison des performances d'apprentissage supervisée et semi-supervisée pour la tâche de Word Sense Disambiguation. Nous développerons deux méthodes de classification : un MLP pour la classification supervisée et un constrained K-means pour la classification semi-supervisée. Nous effectuerons plusieurs tests en considérant plusieurs mots à désambiguiser pour lesquels nous évaluerons les performances de ces deux méthodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter, defaultdict\n",
    "import re\n",
    "import xml.etree.ElementTree as ET\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "import random\n",
    "import pandas as pd"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification supervisé"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On construit une classe Classifieur qui va nous permettre d'accéder aux différents classifieurs (un classifieur pour un mot ambigü).\n",
    "\n",
    "Cette classe possède les méthodes suivantes :  \n",
    "        1 : extract_examples() : pour extraire les données d'entraînement et de test   \n",
    "        2 : extract_embeddings() : pour extraire les embeddings à partir d'un fichier crée en amont, qui ne regroupe que les embeddings nécéssaires à notre jeu de données  \n",
    "        3 : look_up() : pour effectuer l'étape de look-up avant la classifcation en elle-même  \n",
    "        4 : select_examples() :  pour sélectionner des données représentatives lorsqu'on ne considère pas toutes les données annotées i.e. chaque étiquette présente dans les données est présente au moins une fois dans le set d'entraînement \n",
    "        5 : classify() : pour afficher et évaluer la classification  \n",
    "        6 : get_mean_accuracy() : qui renvoie une accuracy moyenne pour plusieurs tests de classification  \n",
    "        7 : test_classifications() : pour comparer différents classifieurs en prenant en considération de moins en moins de données annotées"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifieurs :\n",
    "    \n",
    "    def __init__(self,data_path,gold_path,embeddings_path,context_size):\n",
    "        \n",
    "        #récupération des données XML\n",
    "        tree = ET.parse(data_path)\n",
    "        data_file = tree.getroot()[0]\n",
    "\n",
    "        #récupération des données .txt\n",
    "        gold_file = open(gold_path, \"r\",encoding=\"utf-8\")\n",
    "        \n",
    "        self.w2examples, self.w2senses = self.extract_examples_and_senses(data_file,gold_file,context_size)\n",
    "        self.w2emb = self.extract_embeddings(embeddings_path)\n",
    "    \n",
    "    def extract_examples_and_senses(self,data_file, gold_file, context_size):\n",
    "        \"\"\"Extract the data from the files.\n",
    "\n",
    "        Args:\n",
    "            data_file (Element): Sentences\n",
    "            gold_file (TextIOWrapper): Golds keys\n",
    "\n",
    "        Returns:\n",
    "            dictionary: associates the list of context vectors corresponding to the instance\n",
    "            dictionary : associates to the word each senses\n",
    "        \"\"\"\n",
    "    \n",
    "        w2examples={}\n",
    "        w2senses = defaultdict(set)\n",
    "        \n",
    "        for (sentence,gold_line) in zip(data_file,gold_file.readlines()) :\n",
    "            \n",
    "            #pour chaque phrase, on initialise deux listes qui permettront de respecter les tailles des contextes (+10,-10)\n",
    "            context_before = []\n",
    "            context_after = []\n",
    "            context = []\n",
    "            \n",
    "            #on boucle sur les mots de la phrase pour construire les listes\n",
    "            #on cherche l'instance et on repart en arrière pour constuire le contexte avant\n",
    "            i_instance = 0\n",
    "            while sentence[i_instance].tag != \"instance\" : \n",
    "                i_instance+=1\n",
    "            \n",
    "            instance = sentence[i_instance].attrib[\"lemma\"].lower()\n",
    "            \n",
    "            if instance not in w2examples : \n",
    "                w2examples[instance] = []\n",
    "            \n",
    "            #on vérifie la longueur des phrases pour ne pas soulever d'erreur\n",
    "            \n",
    "            #context_before \n",
    "            \n",
    "            #si le contexte avant l'instance est supérieur ou égale à la taille du contexte choisie\n",
    "            #on ajoute à la liste chaque mot aux index from i-instance-1 to i_instance-5\n",
    "            if (len(sentence[:i_instance])>=context_size) :\n",
    "                    for i in range(1,context_size+1) :\n",
    "                        context_before.append(sentence[i_instance-i].text.lower())\n",
    "            \n",
    "            #sinon, on ajoute à la liste tous les mots et on ajoutera des balises pour compléter\n",
    "            else :\n",
    "                for i in range(1,len(sentence[:i_instance])+1) :\n",
    "                    context_before.append(sentence[i_instance-i].text.lower())\n",
    "\n",
    "            #context_after\n",
    "            \n",
    "            #si le contexte après l'instance est supérieur ou égale à la taille du contexte choisie\n",
    "            #on ajoute à la liste chaque mot aux index from i-instance+1 to i_instance+11\n",
    "            if(len(sentence[i_instance+1:])>= context_size) :\n",
    "                for i in range(i_instance+1,i_instance+(context_size+1)):\n",
    "                    context_after.append(sentence[i].text.lower())\n",
    "            \n",
    "            #sinon, on ajoute à la liste tous les mots et on ajoutera des balises pour compléter\n",
    "            else :\n",
    "                for i in range(i_instance+1,len(sentence)):\n",
    "                    context_after.append(sentence[i].text.lower())\n",
    "            \n",
    "            #une fois les listes constituées, on ajoute les balises de début et de fin de phrase si nécessaire\n",
    "            for i in range(context_size-len(context_before)) :\n",
    "                context_before.append(\"<d>\")\n",
    "                \n",
    "            for i in range(context_size-len(context_after)) :\n",
    "                context_after.append(\"<f>\")\n",
    "                \n",
    "            #le vecteur sera une concaténation des contextes d'avant et d'après\n",
    "            context = context_before\n",
    "            context.append(instance)\n",
    "            context.extend(context_after)\n",
    "                \n",
    "            #on récupère ensuite le nombre associé au sens pour constuire l'exemple + ajouter au dictionnaire w2sense\n",
    "            gold = int((re.findall(\"ws_[0-9]\",gold_line)[0]).replace(\"ws_\",\"\"))\n",
    "            \n",
    "            w2senses[instance].add(gold)\n",
    "            w2examples[instance].append((context,gold))\n",
    "            \n",
    "        return w2examples,w2senses\n",
    "    \n",
    "    def extract_embeddings(self,path_embeddings) :\n",
    "        '''\n",
    "        Récupère les embeddings dans le fichier générée.\n",
    "\n",
    "        Args:\n",
    "            path_embeddings (string)\n",
    "\n",
    "        Returns:\n",
    "            dictionnary: Associe à chaque mot son embedding\n",
    "        '''\n",
    "\n",
    "        f = open(path_embeddings , \"r\", encoding=\"UTF-8\")\n",
    "\n",
    "        #On récupère dans le fichier crée les embeddings pour créer un dictionnaire\n",
    "        w2emb = {}\n",
    "        for line in f.readlines():\n",
    "            splitted_line = line.split(\" \")\n",
    "            word = splitted_line[0]\n",
    "            embedding = list(map(float,splitted_line[1:]))\n",
    "            w2emb[word] = embedding\n",
    "        return w2emb\n",
    "\n",
    "    def look_up(self,context, w2emb) :\n",
    "        '''\n",
    "        Remplace dans le vecteur de contexte les mots par leur embedding.\n",
    "\n",
    "        Args:\n",
    "            context (list): liste de taille (size_window*2)+1\n",
    "            w2emb (dictionnary): Associe à chaque mot son embedding\n",
    "\n",
    "        Returns:\n",
    "            list : liste de taille size_embedding : BOW\n",
    "        '''\n",
    "\n",
    "        emb_size = len(list(w2emb.values())[0]) #on récupère la taille d'un embedding : 300\n",
    "        context_emb = np.zeros(emb_size)\n",
    "        for word in context :\n",
    "            if word in w2emb :\n",
    "                context_emb = np.add(context_emb, np.array(w2emb[word]))             \n",
    "        return context_emb\n",
    "    \n",
    "    def select_examples(self,examples,senses,size):\n",
    "        '''\n",
    "        Choisit des examples d'entraînement représentatifs du corpus.\n",
    "\n",
    "        Args:\n",
    "            examples (list)\n",
    "            n_senses (int): nombre de senses associés à l'instance\n",
    "            size (float): quantité des données d'entraînement considérés\n",
    "\n",
    "        Returns:\n",
    "            list: examples qui contiennent au moins un example de chaque sense\n",
    "        '''\n",
    "\n",
    "        selected_examples = []\n",
    "        \n",
    "        #Pour chaque sens, on ajoute un example associé à ce sens ,au hasard\n",
    "        for sense in senses :\n",
    "            selected_examples.append(random.choice(list(filter((lambda example:example[1]==sense),examples))))\n",
    "        \n",
    "        #On calcule ensuite le nombre d'examples qu'il reste à ajouter pour atteindre la quantité de données souhaitée\n",
    "        size_to_add = round(size*(len(examples)))-len(selected_examples)\n",
    "        \n",
    "        #On ajoute ce nombre de données (non-présentes déjà dans la liste) selectionnées au hasard\n",
    "        selected_examples.extend(random.choices(list(filter((lambda example : example not in selected_examples),examples)),k=size_to_add))\n",
    "        \n",
    "        return selected_examples\n",
    "    \n",
    "    def get_sets(self, instance,data_size):\n",
    "        selected_examples = self.select_examples(self.w2examples[instance],self.w2senses[instance],data_size)\n",
    "        X = [self.look_up(context,self.w2emb)for context,gold in selected_examples]\n",
    "        y = [gold for context,gold in selected_examples]\n",
    "            \n",
    "        X_train, X_test, y_train, y_test = train_test_split(X,y,train_size=0.8)\n",
    "        \n",
    "        self.X_train = X_train\n",
    "        self.X_test = X_test\n",
    "        self.y_train = y_train\n",
    "        self.y_test = y_test \n",
    "        return X_train, X_test, y_train, y_test\n",
    "    \n",
    "    def get_classifier(self,instance,data_size) :\n",
    "        \"\"\"_summary_\n",
    "\n",
    "        Args:\n",
    "            instance (_type_): _description_\n",
    "            data_size (_type_): _description_\n",
    "\n",
    "        Returns:\n",
    "            _type_: _description_\n",
    "        \"\"\"\n",
    "        clf = MLPClassifier(random_state=1,hidden_layer_sizes=(100,)) \n",
    "        self.clf = clf\n",
    "        X_train, X_test, y_train, y_test = self.get_sets(instance, data_size)\n",
    "        clf.fit(X_train, y_train)\n",
    "        return clf\n",
    "        \n",
    "\n",
    "    def classify(self,instance,data_size,affichage=True) :\n",
    "        \"\"\"Permet d'afficher les données de classification et de prédire.\n",
    "\n",
    "        Args:\n",
    "            instance (string): mot anbigü à désambiguïser\n",
    "            data_size (float): quantité de données à considérer\n",
    "            affichage (bool, optional): affichage ou non des données de classification. Defaults to True.\n",
    "\n",
    "        Returns:\n",
    "            _type_: _description_\n",
    "        \"\"\"\n",
    "        clf = self.get_classifier(instance,data_size)\n",
    "        y_pred = clf.predict(self.X_test)\n",
    "        \n",
    "        if affichage :\n",
    "            print(\"instance :\",instance)\n",
    "            print(f'{data_size*100}% des données annotées considérées')\n",
    "            print(\"nombre de données d'entraînement : \", len(self.X_train))\n",
    "            print(\"étiquettes possibles pour cette instance : \", self.w2senses[instance])\n",
    "            print(\"étiquettes présentes dans les données d'entraînement :\",Counter(self.y_train))\n",
    "            print(\"prédiction :\", y_pred)\n",
    "            print(\"gold :\",self.y_test)\n",
    "            print(\"accuracy score : \", accuracy_score(y_pred,self.y_test),\"\\n\")\n",
    "        \n",
    "        return y_pred\n",
    "    \n",
    "    def get_mean_accuracy(self,instance,data_size,n_repeat,affichage = False):\n",
    "        \"\"\"Permet d'effectuer différentes classifications et de rendre une moyenne d'accuracies.\n",
    "\n",
    "        Args:\n",
    "            instance (string): mot à désambiguiser\n",
    "            data_size (float): quantité de données à considérer\n",
    "            n_repeat (int): nombre de classifications tests à effectuer\n",
    "\n",
    "        Returns:\n",
    "            int: moyenne des accuracies obtenues\n",
    "        \"\"\"\n",
    "        accuracies = []\n",
    "        for i in range(n_repeat) :\n",
    "            y_pred = self.classify(instance,data_size,False)\n",
    "            accuracies.append(accuracy_score(y_pred,self.y_test))\n",
    "            \n",
    "        if affichage :\n",
    "            print(instance)\n",
    "            print(accuracies)\n",
    "        return sum(accuracies)/len(accuracies)\n",
    "\n",
    "    def test_classifications(self,instances,step,n_repeat,affichage=True):\n",
    "        \"\"\"Permet d'obtenir une accuracy moyenne pour une certaine quantité de données considérée.\n",
    "\n",
    "        Args:\n",
    "            instances (string): mot à désambiguiser\n",
    "            step (float): pas de descente dans la quantité de données à considérer\n",
    "            n_repeat (int): nombre de classifications tests à effectuer\n",
    "\n",
    "        Returns:\n",
    "            dictionnary: associe à chaque instance sa liste d'accuracies moyenne \n",
    "        \"\"\"\n",
    "        \n",
    "        instance2acc = {instance : [] for instance in instances}\n",
    "        data_sizes =[]\n",
    "        for i in range(round(1.0/step)):\n",
    "            \n",
    "            data_size = 1.0 - (step*float(i))\n",
    "            data_sizes.append(data_size)\n",
    "            \n",
    "            if affichage :\n",
    "                print(data_size)\n",
    "            for instance in instances :\n",
    "                \n",
    "                instance2acc[instance].append(self.get_mean_accuracy(instance,data_size,n_repeat,True))\n",
    "                print()\n",
    "        \n",
    "        if affichage :\n",
    "\n",
    "            tab = instance2acc\n",
    "            tab[\"data_sizes\"] = data_sizes \n",
    "            df = pd.DataFrame(tab)\n",
    "            df.set_index(\"data_sizes\")\n",
    "            print(f\"Accuracies moyennes obtenues avec {n_repeat} classifications\")\n",
    "            print(df)\n",
    "            \n",
    "        return instance2acc     \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour créer le Classifieur, il faut définir les chemins des données, le chemin du fichier stockant les embeddings et la taille du contexte."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "#A définir\n",
    "# chemin pour récupérer les données annotées\n",
    "data_path = \"../donnees/FSE-1.1-191210/FSE-1.1.data.xml\"\n",
    "# chemin pour récupérer les gold class\n",
    "gold_path = \"../donnees/FSE-1.1-191210/FSE-1.1.gold.key.txt\"\n",
    "# choix de la fenêtre du contexte\n",
    "context_size = 4\n",
    "# chemin pour pouvoir faire l'opération look-up. Les embeddings sont extraits de fasttext\n",
    "embeddings_path = \"embeddings.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "Clf = Classifieurs(data_path,gold_path,embeddings_path,context_size)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On effectue un premier test sur le premier mot ambigü des données d'entraînement : \"aboutir\". On choisit de considérer 100% des données."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "instance : aboutir\n",
      "100% des données annotées considérées\n",
      "nombre de données d'entraînement :  20\n",
      "étiquettes possibles pour cette instance :  {1, 2, 3, 4}\n",
      "étiquettes présentes dans les données d'entraînement : Counter({3: 19, 1: 1})\n",
      "prédiction : [3 3 3 3 3]\n",
      "gold : [3, 4, 3, 2, 3]\n",
      "accuracy score :  0.6 \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([3, 3, 3, 3, 3])"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Clf.classify(\"aboutir\",1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans un second temps, on effectue nos tests sur plusieurs classifieurs en choisissant un pas de descente dans la quantité des données annotées considérées. Pour chaque classifieur et chaque quantitée de données considérées, on effectue n_repeat classifications pour obtenir une accuracy moyenne représentative du classifieur. Par conséquent, pour n_repeat=5 et step=0.25, nous obtiendrons pour chaque classifieur une liste d'accuracies correspondante à la moyenne des accuracies de 5 prédictions pour 100%, 75%, 50% et 25% des données."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "#A définir\n",
    "#Nombre de classifieurs choisis au hasard à tester\n",
    "n_rand_instances = 3\n",
    "#Pas de descente dans la quantité de données considérées\n",
    "step = 0.25\n",
    "#Nombre de classifications pour un classifieur pour obtenir une accuracy moyenne\n",
    "n_repeat = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "agir\n",
      "[0.8, 0.6, 0.6, 0.2, 0.8, 0.6, 1.0, 0.8, 0.6, 0.8]\n",
      "\n",
      "prononcer\n",
      "[0.8, 0.2, 0.8, 1.0, 0.6, 1.0, 0.6, 0.4, 0.8, 0.8]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\anais\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\anais\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\anais\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "changer\n",
      "[0.8, 0.8, 0.8, 0.8, 0.8, 0.6, 0.8, 0.8, 0.0, 0.8]\n",
      "\n",
      "0.75\n",
      "agir\n",
      "[0.5, 0.5, 0.25, 0.25, 0.5, 0.5, 0.75, 0.75, 0.5, 0.75]\n",
      "\n",
      "prononcer\n",
      "[0.5, 0.5, 0.5, 0.75, 0.5, 0.75, 0.25, 0.75, 0.25, 0.25]\n",
      "\n",
      "changer\n",
      "[0.25, 0.5, 0.5, 0.5, 0.25, 0.25, 0.25, 0.5, 0.75, 0.5]\n",
      "\n",
      "0.5\n",
      "agir\n",
      "[0.6666666666666666, 0.6666666666666666, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.6666666666666666, 0.6666666666666666, 0.6666666666666666, 0.3333333333333333]\n",
      "\n",
      "prononcer\n",
      "[0.3333333333333333, 0.0, 0.6666666666666666, 0.0, 0.3333333333333333, 0.3333333333333333, 0.6666666666666666, 0.0, 0.3333333333333333, 0.3333333333333333]\n",
      "\n",
      "changer\n",
      "[0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.0, 0.3333333333333333, 0.6666666666666666, 0.3333333333333333]\n",
      "\n",
      "0.25\n",
      "agir\n",
      "[0.0, 0.5, 0.5, 0.5, 0.0, 0.5, 0.0, 0.0, 0.0, 0.5]\n",
      "\n",
      "prononcer\n",
      "[0.0, 0.5, 0.0, 0.0, 0.0, 0.0, 0.5, 0.0, 0.0, 0.0]\n",
      "\n",
      "changer\n",
      "[0.0, 0.5, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "\n",
      "Accuracies moyennes obtenues avec 10 classifications\n",
      "    agir  prononcer   changer  data_sizes\n",
      "0  0.680        0.7  0.700000        1.00\n",
      "1  0.525        0.5  0.425000        0.75\n",
      "2  0.500        0.3  0.333333        0.50\n",
      "3  0.250        0.1  0.050000        0.25\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'agir': [0.6799999999999999, 0.525, 0.4999999999999999, 0.25],\n",
       " 'prononcer': [0.7, 0.5, 0.3, 0.1],\n",
       " 'changer': [0.7, 0.425, 0.3333333333333333, 0.05],\n",
       " 'data_sizes': [1.0, 0.75, 0.5, 0.25]}"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "instances = random.choices(list(Clf.w2examples.keys()),k=n_rand_instances)\n",
    "Clf.test_classifications(instances,step,n_repeat,affichage=True)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification semi-supervisée"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "class K_Means():\n",
    "    ''' \n",
    "    classifieur K-means pour un mot particulier\n",
    "    '''\n",
    "\n",
    "    def __init__(self, examples):\n",
    "        '''\n",
    "        Instancie les différentes variables utiles pour l'algorithme du K-means\n",
    "\n",
    "        examples : liste d'examples dont le mot à désambiguiser est le même pour \n",
    "                   chaque example\n",
    "        example : couple d'un mot avec son contexte de fenêtre 4 (sous forme \n",
    "                  d'embedding) et du numéro de sens attendu du mot à désambiguiser \n",
    "                  (gold class sous forme d'integer)\n",
    "                    si example = ([1.9, 2.3, 0.6], 1),\n",
    "                    - le contexte avec le mot à désambiguiser et son lemme est \n",
    "                      l'embedding [1.9, 2.3, 0.6]\n",
    "                    - le numéro de sens est 1\n",
    "        '''\n",
    "\n",
    "        # transforme l'ensemble des examples en une liste pour pouvoir garder le \n",
    "        # même indice pour chaque example par la suite\n",
    "        self.examples = list(examples)\n",
    "        # transforme les embeddings en tensors\n",
    "        self.tensors_examples = [example[0] for example in self.examples]\n",
    "        # détermine le nombre de sens possibles k (donc le nombre de clusters) \n",
    "        # à l'aide des données\n",
    "        self.k = self.nb_senses()\n",
    "        # initialisation de centroids : pour chaque sens, un example est pris au hasard\n",
    "        self.tensors_centroids = [random.choice(example) \n",
    "                                  for example in self.examples_of_same_sense().values()]\n",
    "        # initialisation de clusters : tous les examples sont associés au cluster 0\n",
    "        self.clusters = np.zeros(len(examples))\n",
    "\n",
    "    def nb_senses(self):\n",
    "        '''\n",
    "        Renvoie le nombre de sens existants dans un ensemble d'examples\n",
    "        '''\n",
    "\n",
    "        known_senses = []\n",
    "        # pour chaque exemple\n",
    "        for example in self.examples:\n",
    "            # si le sens attendu (gold class) n'a pas encore été rencontré\n",
    "            if example[1] not in known_senses:\n",
    "                # l'ajoute à la liste des sens possibles\n",
    "                known_senses.append(example[1])\n",
    "        # renvoie le nombre de sens\n",
    "        return len(known_senses)\n",
    "    \n",
    "    def examples_of_same_sense(self):\n",
    "        '''\n",
    "        Regroupe les contextes des examples dans un dictionnaire triés selon le \n",
    "        sens du mot à désambiguiser\n",
    "        '''\n",
    "\n",
    "        # clé : numéro du sens\n",
    "        # valeur : liste de contextes avec ce sens en gold class\n",
    "        sense2examples = {}\n",
    "        # pour chaque example\n",
    "        for example in self.examples:\n",
    "            # si sa gold class n'a pas été déjà rencontrée\n",
    "            if example[1] not in sense2examples:\n",
    "                # ajoute une clé pour cette gold class\n",
    "                sense2examples[example[1]] = []\n",
    "            # ajoute le contexte au dictionnaire correspondant au sens utilisé\n",
    "            sense2examples[example[1]].append(example[0])\n",
    "\n",
    "        return sense2examples\n",
    "    \n",
    "    def learn_clusters(self):\n",
    "        '''\n",
    "        Algorithme de K-Means\n",
    "        Retourne les coordonnées de chaque centroide ainsi que le cluster auquel \n",
    "        appartient chaque example\n",
    "        '''\n",
    "\n",
    "        # différence initialisée à Vrai\n",
    "        diff = True\n",
    "        \n",
    "        # tant qu'il y a une différence entre l'ancienne liste et la nouvelle \n",
    "        # liste de centroides\n",
    "        while diff:\n",
    "\n",
    "            # CALCUL DES DISTANCES ENTRE CHAQUE EXAMPLE ET CHAQUE CENTROIDE\n",
    "\n",
    "            # pour chaque couple (indice, coordonnées) dans les examples\n",
    "            for i, tensor_example in enumerate(self.tensors_examples):\n",
    "                # initialisation de la distance minimum à l'infini\n",
    "                min_dist = float('inf')\n",
    "                # pour chaque couple (indice, coordonnées) dans les centroides\n",
    "                for j, tensor_centroid in enumerate(self.tensors_centroids):\n",
    "                    # calcul de la distance entre cet example et ce centroide\n",
    "                    d = 0\n",
    "                    for k in range(len(tensor_example)):\n",
    "                        d += (tensor_centroid[k].item() - tensor_example[k].item())**2\n",
    "                    d = np.sqrt(d)\n",
    "                    # si une distance plus faible est trouvée\n",
    "                    if min_dist > d:\n",
    "                        # la distance ainsi que le centroide sont stockés\n",
    "                        min_dist = d\n",
    "                        self.clusters[i] = j\n",
    "            \n",
    "            # CALCUL DES NOUVEAUX CENTROIDES\n",
    "\n",
    "            # calcul des nouveaux centroides en utilisant le point au milieu de tous les\n",
    "            # autres points du même cluster\n",
    "            new_centroids = pd.DataFrame(self.tensors_examples).groupby(by = self.clusters).mean()\n",
    "            # transforme ces nouveaux centroides en tensors\n",
    "            tensors_new_centroids = []\n",
    "            for i in range(len(new_centroids.index)):\n",
    "                colums = []\n",
    "                for j in range(len(new_centroids.columns)):\n",
    "                    colums.append(int(new_centroids.iat[i,j]))\n",
    "                tensors_new_centroids.append(torch.tensor(colums))\n",
    "\n",
    "            # MISE A JOUR DES CENTROIDES\n",
    "\n",
    "            count_diff = 0\n",
    "            # pour chaque centroide\n",
    "            for i in range(len(self.tensors_centroids)):\n",
    "                # si l'ancien centroide et le nouveau ne sont pas les mêmes\n",
    "                if not(torch.equal(self.tensors_centroids[i], tensors_new_centroids[i])):\n",
    "                    count_diff += 1\n",
    "                    # met à jour le centroide\n",
    "                    self.tensors_centroids = tensors_new_centroids\n",
    "            # s'il n'y a eu aucune différence entre les anciens et les nouveaux centroides, \n",
    "            # la boucle while se termine\n",
    "            if count_diff == 0:\n",
    "                diff = False\n",
    "            \n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### on écrit encore des trucs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
