{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import pandas as pd\n",
    "import copy\n",
    "\n",
    "from collections import Counter, defaultdict\n",
    "import xml.etree.ElementTree as ET\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# World Sense Disambiguation (WSD)\n",
    "\n",
    "Ce notebook permet d'effectuer une comparaison des performances de deux algorithmes, un d'apprentissage supervisé et un d'apprentissage semi-supervisé, pour la tâche de Word Sense Disambiguation (WSD). \n",
    "\n",
    "Les deux méthodes sont les suivants :\n",
    "- pour la classification supervisée, utilisation d'un MLP\n",
    "- pour la classification semi-supervisée, utilisation d'un algorithme de constrained K-Means\n",
    "\n",
    "Plusieurs tests sont effectués en considérant plusieurs mots à désambiguiser pour lesquels les performances de ces deux méthodes sont évaluées. L'objectif final est de comparer ces performances pour déterminer à partir de combien de données annotées la première méthode est préférable à la deuxième et vice versa.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Extraction des données\n",
    "\n",
    "La classe Extractor permet d'accéder aux données et de les stocker dans des dictionnaires puis des embeddings. Elle permet de figer les données sur lesquelles les tests de classification seront ensuite faits. Elle comporte les méthodes suivantes :\n",
    "\n",
    "- `extract_examples()` : pour extraire les données d'entraînement et de test provenant de fichiers XML FSE\n",
    "\n",
    "- `extract_embeddings()` : pour extraire les embeddings à partir d'un fichier créé en amont, qui ne regroupe que les embeddings nécéssaires à notre jeu de données. Cette méthode est surtout utile pour drastiquement réduire le temps de chargement des embeddings\n",
    "\n",
    "- `look_up()` : pour effectuer l'étape de look-up avant la classifcation\n",
    "\n",
    "- `select_examples()` : pour sélectionner des données représentatives lorsqu'on ne considère pas toutes les données annotées. Pour qu'un ensemble de données soit représentatif, il faut que chaque étiquette présente dans les données totales soit présente au moins une fois dans le set d'entraînement sélectionné\n",
    "\n",
    "- `define_instance()` : pour choisir les données qui seront classifiées, c'est-à-dire quelle proportion des données seront utilisées (75%, 50%, 25%...)\n",
    "\n",
    "- `classifier_display_at_instance_time()` : pour afficher les données relatives au classifieur\n",
    "\n",
    "- `k-means_display_at_instance_time()` : pour afficher les données relatives au constrained k-means\n",
    "\n",
    "- `get_most_frequent_sense()` : pour obtenir le sens le plus fréquent et son occurence pour un lemme donné"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Extractor :\n",
    "    \n",
    "    def __init__(self, data_path, gold_path, embeddings_path, context_size):\n",
    "        '''\n",
    "        A partir des données, extrait les examples qui seront utilisés lors de l'apprentissage.\n",
    "\n",
    "        INPUT\n",
    "        data_path (str) : chemin pour accéder aux données d'entraînement, au format XML\n",
    "        gold_path (str) : chemin pour accéder aux numéros de sens correspondant aux données\n",
    "                          d'entraînement\n",
    "        embeddings_path (str) : chemin pour accéder aux embeddings, déjà extraits et \n",
    "                                présélectionnés pour ces données\n",
    "        context_size (int) : taille de la fenêtre du contexte du mot à désambiguiser\n",
    "\n",
    "        ARGUMENTS DE CLASSE\n",
    "        self.w2examples (dict) : associe chaque lemme à une liste d'examples correspondant à son \n",
    "                                 utilisation dans une phrase du corpus. \n",
    "                                 examples (list) : liste de tous les couples \n",
    "                                  ([mots du contexte], numéro de sens) pour un lemme donné\n",
    "        self.w2senses (dict) : associe chaque lemme à son ensemble de sens possible\n",
    "        self.w2emb (dict) : associe chaque mot à son embedding\n",
    "        self.selected_examples (liste) : liste d'examples qui contient au moins un example de \n",
    "                                         chaque sens du lemme choisi\n",
    "        self.selected_examples_embs (liste) : même liste d'examples, mais avec les contextes \n",
    "                                              sous forme d'embedding\n",
    "        self.X_train (list) : corpus d'apprentissage\n",
    "        self.X_test (list) : numéros des sens correspondant au corpus d'apprentissage\n",
    "        self.y_train (list) : corpus de test\n",
    "        self.y_test (list) : numéros des sens correspondant au corpus d'apprentissage\n",
    "        self.annotated_examples (list) : liste des données considérées comme annotées \n",
    "        self.unannotated_examples (list) : liste des données considérées comme non annotées \n",
    "        '''\n",
    "        \n",
    "        #récupération des données XML d'apprentissage fournies en argument\n",
    "        tree = ET.parse(data_path)\n",
    "        data_file = tree.getroot()\n",
    "\n",
    "        #récupération des données txt correspondant aux gold class\n",
    "        gold_file = open(gold_path, \"r\",encoding=\"utf-8\")\n",
    "        \n",
    "        # self.w2examples (dict) : associe chaque lemme à une liste d'examples correspondant à son \n",
    "        #                          utilisation dans une phrase du corpus.\n",
    "        # clé (str) : lemme du mot à désambiguiser\n",
    "        # valeur (list) : liste de tous les couples ([mots du contexte], numéro de sens) pour ce \n",
    "        #                 lemme\n",
    "        #\n",
    "        # self.w2senses (dict) : associe chaque lemme à son ensemble de sens possible\n",
    "        # clé (str) : lemme du mot à désambiguiser\n",
    "        # valeur (set) : ensemble des sens possible pour ce lemme\n",
    "        self.w2examples, self.w2senses = self.extract_examples_and_senses(data_file, gold_file, context_size)\n",
    "\n",
    "        # self.w2emb (dict) : associe chaque mot à l'embedding représentant son contexte sommé\n",
    "        # clé (str) : mot à désambiguiser\n",
    "        # valeur (list) : embedding\n",
    "        self.w2emb = self.extract_embeddings(embeddings_path)\n",
    "\n",
    "        # liste d'examples qui contient au moins un example de chaque sens du lemme choisi\n",
    "        # cette liste sera définie lorsque l'instance du mot à désambiguiser sera choisi\n",
    "        self.selected_examples = []\n",
    "        # même liste d'examples, mais avec les contextes sous forme d'embedding\n",
    "        # cette liste sera définie lorsque l'instance du mot à désambiguiser sera choisi\n",
    "        self.selected_examples_embs = []\n",
    "        # liste des examples non selectionnés, dont les contextes sont sous forme d'embedding\n",
    "        self.unannotated_set = []\n",
    "\n",
    "        # les corpus seront définis lorsque l'instance du mot à désambiguiser sera choisi\n",
    "        self.X_train = []\n",
    "        self.X_test = []\n",
    "        self.y_train = []\n",
    "        self.y_test = []\n",
    "\n",
    "        # liste des données considérées comme annotées \n",
    "        self.annotated_examples = []\n",
    "        # liste des données considérées comme non annotées \n",
    "        self.unannotated_examples = []\n",
    "    \n",
    "    def extract_examples_and_senses(self, data_file, gold_file, context_size):\n",
    "        '''\n",
    "        Extrait les données à partir des fichiers de corpus d'apprentissage et de gold classes.\n",
    "\n",
    "        INPUT\n",
    "        data_file (Element): représentation des phrases du corpus d'apprentissage\n",
    "        gold_file (TextIOWrapper): fichier contenant les numéros de sens (gold class) pour chaque\n",
    "                                   mot à désambiguiser\n",
    "        '''\n",
    "    \n",
    "        # clé (str) : lemme du mot à désambiguiser\n",
    "        # valeur (list) : liste de tous les couples ([mots du contexte], numéro de sens) pour ce \n",
    "        #                 lemme\n",
    "        w2examples = {}\n",
    "        # clé (str) : lemme du mot à désambiguiser\n",
    "        # valeur (set) : ensemble des sens possible pour ce lemme\n",
    "        w2senses = defaultdict(set)\n",
    "\n",
    "        # lecture du fichier gold\n",
    "        gold_file = gold_file.readlines()\n",
    "        \n",
    "        # index de parcours dans le fichier gold\n",
    "        i_gold = 0\n",
    "\n",
    "        # pour chaque phrase du corpus\n",
    "        for text_id in data_file:\n",
    "            for sentence in text_id:\n",
    "\n",
    "                # recherche de(s) l'indice(s) de(s) l'instance(s) pour savoir où se trouve la fenêtre\n",
    "                i_instances = []\n",
    "                for j in range(len(sentence)):\n",
    "                    if sentence[j].tag == \"instance\":\n",
    "                        i_instances.append(j)\n",
    "                \n",
    "                # tant qu'il y a des instances à repérer dans la phrase\n",
    "                while len(i_instances) > 0:\n",
    "\n",
    "                    # enregistrement du lemme de l'instance\n",
    "                    instance = sentence[i_instances[0]].attrib[\"lemma\"].lower()\n",
    "                    \n",
    "                    # si l'instance n'a pas encore de contexte\n",
    "                    if instance not in w2examples : \n",
    "                        # le crée\n",
    "                        w2examples[instance] = []\n",
    "\n",
    "                    context = []\n",
    "                    # pour chaque mot de la fenêtre\n",
    "                    for k in range(-context_size, context_size + 1):\n",
    "                        # si le mot est l'instance, enregistrement de son lemme\n",
    "                        if k == 0:\n",
    "                            context.append(instance)\n",
    "                        # sinon enregistrement du mot du contexte\n",
    "                        elif len(sentence) > i_instances[0] + k and i_instances[0] + k >= 0:\n",
    "                            context.append(sentence[i_instances[0] + k].text.lower())\n",
    "                    \n",
    "                    # récupération des différents sens possibles dans le fichier gold \n",
    "                    gold_class = gold_file[i_gold].split(\"__\")[1].split(\"_\")[1]\n",
    "\n",
    "                    # le fichiers gold et data ayant les données dans le même ordre, les instances\n",
    "                    # et les sens peuvent être enregistrés en même temps dans leur dictionnaire\n",
    "                    # respectif\n",
    "                    w2senses[instance].add(gold_class)\n",
    "                    w2examples[instance].append((context, gold_class))\n",
    "                    \n",
    "                    # l'instance lue est enlevée de la to-do list et l'index de parcours du fichier \n",
    "                    # gold est incrémenté pour passer à l'instance suivante\n",
    "                    i_instances.pop(0)\n",
    "                    i_gold += 1\n",
    "\n",
    "        return w2examples, w2senses\n",
    "    \n",
    "    def extract_embeddings(self,path_embeddings) :\n",
    "        '''\n",
    "        Récupère les embeddings dans le fichier généré et associe à chaque mot son\n",
    "        embedding.\n",
    "\n",
    "        INPUT\n",
    "        path_embeddings (str) : chemin pour accéder aux embeddings, déjà extraits et \n",
    "                                présélectionnés pour ces données\n",
    "\n",
    "        OUTPUT\n",
    "        w2emb (dict) : associe chaque mot à son embedding\n",
    "        '''\n",
    "\n",
    "        # lecture du fichier\n",
    "        file_embeddings = open(path_embeddings , \"r\", encoding=\"UTF-8\")\n",
    "\n",
    "        # clé (str) : mot à désambiguiser\n",
    "        # valeur (list) : embedding du mot\n",
    "        w2emb = {}\n",
    "\n",
    "        # pour chaque mot du fichier\n",
    "        for line in file_embeddings.readlines():\n",
    "\n",
    "            # séparation du mot et de l'embedding\n",
    "            splitted_line = line.split(\" \")\n",
    "            word = splitted_line[0]\n",
    "            embedding = list(map(float,splitted_line[1:]))\n",
    "            # insertion du mot et de son embedding dans le dictionnaire\n",
    "            w2emb[word] = embedding\n",
    "\n",
    "        return w2emb\n",
    "\n",
    "    def look_up(self, context) :\n",
    "        '''\n",
    "        Remplace dans les mots du vecteur de contexte par leur embedding et en fait la\n",
    "        somme.\n",
    "\n",
    "        INPUT\n",
    "        context (list) : liste de taille (size_window*2)+1\n",
    "\n",
    "        OUTPUT\n",
    "        context_emb (list) : liste de taille size_embedding (300 ici)\n",
    "        '''\n",
    "\n",
    "        # taille d'un embedding : 300\n",
    "        emb_size = len(list(self.w2emb.values())[0]) \n",
    "        # initialisation du contexte sous forme d'embedding\n",
    "        context_emb = np.zeros(emb_size)\n",
    "\n",
    "        # pour chaque mot du contexte\n",
    "        for word in context :\n",
    "            # s'il est présent dans le dictionnaire d'embeddings\n",
    "            if word in self.w2emb :\n",
    "                # il est ajouté à l'embedding représentant le contexte\n",
    "                context_emb = np.add(context_emb, np.array(self.w2emb[word])) \n",
    "\n",
    "        return context_emb\n",
    "    \n",
    "    def select_examples(self, examples, senses, sample_size):\n",
    "        '''\n",
    "        Choisit des examples représentatifs du corpus selon un nombre imposé de \n",
    "        données à choisir.\n",
    "\n",
    "        INPUT\n",
    "        examples (list) : liste d'examples pour le mot à désambiguiser\n",
    "        n_senses (int) : nombre de sens associés à ce mot\n",
    "        sample_size (float) : quantité des données considérés\n",
    "\n",
    "        OUTPUT\n",
    "        selected_examples (list) : liste d'examples qui contient au moins un example \n",
    "                                   de chaque sens\n",
    "        '''\n",
    "\n",
    "        selected_examples = []\n",
    "        \n",
    "        # pour chaque sens, on ajoute un example associé à ce sens, au hasard\n",
    "        for sense in senses :\n",
    "            selected_examples.append(random.choice(list(filter((lambda example:example[1]==sense),\n",
    "                                                               examples))))\n",
    "        \n",
    "        # ajoute le nombre de données manquantes (non-présentes dans la liste) selectionnées au hasard\n",
    "        random.shuffle(examples)\n",
    "        for example in examples:\n",
    "            if example not in selected_examples and len(selected_examples) < sample_size*len(examples):\n",
    "                selected_examples.append(example)\n",
    "\n",
    "        return selected_examples\n",
    "    \n",
    "    def select_train_test(self, x, y, senses, data_size, display, train_size = 0.8):\n",
    "        '''\n",
    "        Sépare en un train set et test set les examples représentatifs du corpus en mettant \n",
    "        au moins une étiquette de chaque sens dans le train set (et le test set si possible)\n",
    "\n",
    "        INPUT\n",
    "        x (list) : liste d'examples pour le mot à désambiguiser\n",
    "        y (list) : liste d'étiquette pour chaque example de x\n",
    "        senses (list) : numéros des sens associés à ce mot\n",
    "        train_size (float) : quantité des données d'entraînement considérés\n",
    "        '''\n",
    "\n",
    "        # SELECTION DES DONNEES REPRESENTATIVES DU TRAIN\n",
    "\n",
    "        # sélection au hasard d'un contexte et de son étiquette pour chaque sens\n",
    "        selected_train = [random.choice(list(filter((lambda example: example[1] == sense),\n",
    "                                                    zip(x,y)))) for sense in senses]\n",
    "            \n",
    "        # SELECTION DES DONNEES REPRESENTATIVES DU TEST\n",
    "\n",
    "        # fait de même pour le corpus de test, lorsque possible, en ne considérant pas\n",
    "        # ceux déjà sélectionnés pour le train\n",
    "        selected_test = []\n",
    "        for sense in senses:\n",
    "            added = False\n",
    "            for example in zip(x,y):\n",
    "                for train_ex in selected_train:\n",
    "                    # vérifie que l'example n'a pas déjà été sélectionné dans le train et\n",
    "                    # le test pour ne pas faire de doublon\n",
    "                    if example[1] == sense and example[1] == train_ex[1] and not(np.array_equal(example[0], train_ex[0])):\n",
    "                        selected_test.append(example)\n",
    "                        added = True\n",
    "                        break\n",
    "                if added == True:\n",
    "                    break\n",
    "\n",
    "        # SELECTION DES DONNEES RESTANTES DU TRAIN ET DU TEST\n",
    "\n",
    "        # effectue un split sur le reste d'examples disponibles\n",
    "        remaining_X = []\n",
    "        remaining_y = []\n",
    "        selected_train_copy = copy.deepcopy(selected_train)\n",
    "        selected_train_copy.extend(selected_test)\n",
    "        for contexte, sens in zip(x,y):\n",
    "            to_add = True\n",
    "            for ex in selected_train_copy:\n",
    "                # vérifie que l'example n'a pas déjà été sélectionné dans le train et le\n",
    "                # test pour ne pas faire de doublon\n",
    "                if np.array_equal(contexte, ex[0]) and sens == ex[1]:\n",
    "                    to_add = False\n",
    "                    break\n",
    "            # ajoute les examples qui doivent être ajoutés\n",
    "            if to_add:\n",
    "                remaining_X.append(contexte)\n",
    "                remaining_y.append(sens)\n",
    "\n",
    "        try:\n",
    "            self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(remaining_X, remaining_y,train_size = train_size)\n",
    "    \n",
    "            # création des sets d'entraînement et de test\n",
    "            selected_X_train, selected_y_train = zip(*selected_train)\n",
    "            selected_X_test, selected_y_test = zip(*selected_test)\n",
    "            # ajout des données représentatives dans les sets correspondant\n",
    "            self.X_train.extend(selected_X_train)\n",
    "            self.X_test.extend(selected_X_test)\n",
    "            self.y_train.extend(selected_y_train)\n",
    "            self.y_test.extend(selected_y_test)\n",
    "            \n",
    "        except:\n",
    "            if display:\n",
    "                print(f\"/!\\ ERREUR /!\\ La taille des données est trop faible. L'opération train_test_split() est impossible.\")                                                                     \n",
    "            self.X_train, self.X_test, self.y_train, self.y_test = set(), set(), set(), set()\n",
    "                     \n",
    "    def define_instance(self, instance, data_size, display):\n",
    "        '''\n",
    "        Permet de définir l'instance du mot à désambiguiser et les examples à utiliser. \n",
    "        Fixe les derniers arguments de classe selon l'instance choisie.\n",
    "        Contraint le choix de classification selon le nombre de données considéré.\n",
    "\n",
    "        INPUT\n",
    "        instance (str) : mot à désambiguiser\n",
    "        data_size (float): quantité de données à considérer\n",
    "        display (bool, optional): affiche une trace des options choisies\n",
    "        '''\n",
    "\n",
    "        # SET DE DONNEES ANNOTEES\n",
    "\n",
    "        # choisit des examples d'entraînement représentatifs du corpus selon le nombre\n",
    "        # imposé de données\n",
    "        self.annotated_examples = self.select_examples(self.w2examples[instance],\n",
    "                                                       self.w2senses[instance],\n",
    "                                                       data_size)\n",
    "        # liste de tous les contextes sous forme d'embedding\n",
    "        X_annotated = [self.look_up(context) for context, gold in self.annotated_examples]\n",
    "        # liste de tous les numéros de sens\n",
    "        y_annotated = [gold for context, gold in self.annotated_examples]\n",
    "        # le set des données annotées est une liste des examples représentatifs sous forme d'embeddings\n",
    "        self.selected_examples_embs = list(zip(X_annotated,y_annotated))\n",
    "\n",
    "        # SET DE DONNEES NON ANNOTEES\n",
    "\n",
    "        # garde en mémoire les examples considérés comme non-annotés\n",
    "        self.unannotated_examples = [example for example in self.w2examples[instance] \n",
    "                                     if example not in self.annotated_examples]        \n",
    "        # liste de tous les contextes sous forme d'embedding\n",
    "        X_unannotated = [self.look_up(context) for context,gold in self.unannotated_examples]\n",
    "        # liste de tous les numéros de sens\n",
    "        y_unannotated = [gold for context,gold in self.unannotated_examples]\n",
    "        # le set des données non-annotées est une liste des examples sous forme d'embeddings\n",
    "        self.unannotated_set = list(zip(X_unannotated,y_unannotated))\n",
    "\n",
    "        # SET DE DONNEES A CLASSIFIER PAR MLPCLASSIFIER_WSD\n",
    "        \n",
    "        # création des corpus d'entrainement et de test\n",
    "        self.select_train_test(X_annotated, y_annotated, self.w2senses[instance],display,data_size)\n",
    "            \n",
    "        # affichage des informations relatives à l'instance choisie pour MLPClassifier_WSD\n",
    "        if display :\n",
    "            self.classifier_display_at_instance_time(instance, data_size)\n",
    "            \n",
    "    \n",
    "    def classifier_display_at_instance_time(self, instance, data_size):\n",
    "        '''\n",
    "        Affiche les informations relatives à l'instance choisie pour MLPClassifier_WSD\n",
    "\n",
    "        INPUT\n",
    "        instance (str) : mot à désambiguiser\n",
    "        data_size (float) : quantité de données à considérer\n",
    "        '''\n",
    "        \n",
    "        print(\"--> Instance :\", instance)\n",
    "        print(f'{data_size*100}% des données annotées considérées')\n",
    "        print(\"Nombre de données d'entraînement : \", len(self.X_train))\n",
    "        print(\"Etiquettes possibles pour cette instance : \", self.w2senses[instance])\n",
    "        if self.y_train:\n",
    "            print(\"Etiquettes présentes dans les données d'entraînement :\", Counter(self.y_train))\n",
    "            \n",
    "\n",
    "    def kmeans_display_at_instance_time(self, instance, size):\n",
    "        ''' \n",
    "        Affiche des informations relatives à l'instance choisie pour K_Means\n",
    "\n",
    "        INPUT\n",
    "        instance (str) : mot à désambiguiser\n",
    "        num_correct (int) : nombre de prédictions correctes\n",
    "        num_examples (int) : nombre d'examples total\n",
    "        size (float) : quantité de données à considérer \n",
    "        '''\n",
    "        print(\"--> Instance :\",instance)\n",
    "        print(f\"Proportion de données annotées considérées sur le corpus: {size*100} %\")\n",
    "        y, most_frequent_sense, occurrence_of_most_frequent_sense = self.get_most_frequent_sense()\n",
    "        print(f\"Répartition des sens: {Counter(y)}\")\n",
    "        print(f\"Le sens le plus fréquent pour '{instance}' est le sens {most_frequent_sense} avec une proportion de {round(occurrence_of_most_frequent_sense*100,2)} %\")\n",
    "        print()\n",
    "\n",
    "    def get_most_frequent_sense(self):\n",
    "        '''\n",
    "        Retourne le numéro de sens le plus fréquent et son nombre d'occurrences,\n",
    "        ainsi que l'ensemble de tous les sens possibles\n",
    "        '''\n",
    "        y = [gold for tensor,gold in self.selected_examples_embs]\n",
    "        most_frequent_sense = max(y,key=y.count)\n",
    "        occurrence_of_most_frequent_sense = y.count(most_frequent_sense)/len(y)\n",
    "        return y, most_frequent_sense, occurrence_of_most_frequent_sense\n",
    "\n",
    "    def get_sets(self):\n",
    "        return self.X_train, self.X_test, self.y_train, self.y_test\n",
    "    \n",
    "    def get_annotated_and_unannotated_sets(self):\n",
    "        return self.selected_examples_embs, self.unannotated_set\n",
    "        \n",
    "    def get_annotated_examples(self):\n",
    "        return self.annotated_examples\n",
    "    \n",
    "    def get_unannotated_examples(self):\n",
    "        return self.unannotated_examples\n",
    "    \n",
    "    def get_embs(self):\n",
    "        return self.selected_examples_embs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chemin du corpus annoté\n",
    "data_path = \"../donnees/FSE-1.1-191210/FSE-1.1.data.xml\"\n",
    "# chemin pour récupérer les gold class du corpus annoté\n",
    "gold_path = \"../donnees/FSE-1.1-191210/FSE-1.1.gold.key.txt\"\n",
    "# choix de la fenêtre du contexte\n",
    "context_size = 4\n",
    "# chemin pour récupérer les embeddings afin de faire l'opération look-up\n",
    "# Les embeddings sont extraits de fastText\n",
    "embeddings_path = \"../donnees/embeddings.txt\"\n",
    "# choix de l'instance à tester pour la classification\n",
    "instance = \"aboutir\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--> Instance : aboutir\n",
      "80.0% des données annotées considérées\n",
      "Nombre de données d'entraînement :  31\n",
      "Etiquettes possibles pour cette instance :  {'2', '3', '4', '1'}\n",
      "Etiquettes présentes dans les données d'entraînement : Counter({'3': 25, '4': 4, '2': 1, '1': 1})\n",
      "\n",
      "exemple d'example avec contexte et gold class : (['les', 'produits', 'ainsi', 'formés', 'aboutir', 'dans', 'des', 'vésicules', 'destinées'], '2')\n",
      "\n",
      "au format embedding :  (array([ 8.6700e-02, -8.6500e-02,  1.1530e-01, -1.9800e-02, -5.4330e-01,\n",
      "       -1.1660e-01,  4.0650e-01, -3.2600e-01,  1.4230e-01, -9.7700e-02,\n",
      "        1.2140e-01, -3.3560e-01,  1.1430e-01,  1.2610e-01,  4.3000e-02,\n",
      "        6.0600e-02,  8.3600e-02, -4.5000e-02,  2.9500e-02,  9.6500e-02,\n",
      "       -3.4000e-03, -1.3260e-01, -7.7800e-02, -2.4500e-02, -7.0000e-04,\n",
      "        1.6780e-01, -8.2870e-01, -1.3090e-01,  5.3910e-01, -1.6000e-03,\n",
      "       -1.1190e-01,  9.0000e-04, -3.9980e-01,  3.1190e-01,  1.2870e-01,\n",
      "        1.8070e-01,  5.4570e-01, -4.8000e-03, -1.1460e-01, -6.2570e-01,\n",
      "       -9.1700e-02, -3.6400e-02, -1.1790e-01,  6.8100e-02, -5.2180e-01,\n",
      "        2.5060e-01,  3.2300e-02,  7.1900e-02,  3.4100e-02,  5.7700e-02,\n",
      "        1.5660e-01,  2.6100e-02,  3.5500e-01, -1.9800e-02,  4.3200e-02,\n",
      "        9.4440e-01,  6.0000e-02,  3.8800e-02, -2.5610e-01,  4.4500e-02,\n",
      "        8.5100e-02,  4.0910e-01, -2.1250e-01, -2.5570e-01, -4.4900e-02,\n",
      "        7.8200e-02,  1.7300e-02,  2.4000e-02, -1.1400e-02, -5.8100e-02,\n",
      "        4.9900e-02,  1.2920e-01,  3.4530e-01,  1.1110e-01, -7.6800e-02,\n",
      "       -9.6700e-02, -1.1820e-01, -7.6100e-02, -6.0880e-01,  8.1700e-02,\n",
      "        1.0140e-01,  1.6280e-01, -6.4690e-01, -2.0665e+00, -4.7060e-01,\n",
      "       -5.0400e-02,  2.8100e-02,  1.5660e-01, -2.4190e-01, -4.3200e-02,\n",
      "       -7.9100e-02,  4.1100e-02,  1.4300e-01, -4.0000e-02,  2.9770e-01,\n",
      "        3.0980e-01,  1.5410e-01, -7.4040e-01, -4.9920e-01,  1.4160e+00,\n",
      "       -1.1720e-01, -1.8300e-02, -2.3410e-01,  5.0900e-02,  1.4910e-01,\n",
      "       -1.8610e-01,  1.9800e-01,  1.8150e-01, -1.7410e-01,  6.7140e-01,\n",
      "        2.0820e-01, -3.2000e-03,  9.3300e-02, -6.2600e-02, -3.5400e-02,\n",
      "        4.5200e-02,  8.2300e-02, -2.2910e-01,  1.1010e-01, -1.2350e-01,\n",
      "       -4.7640e-01,  1.6540e-01,  1.9400e-02, -1.1210e-01, -3.3970e-01,\n",
      "       -6.2200e-02, -1.8210e-01,  2.8200e-02,  4.1310e-01, -7.2600e-02,\n",
      "        1.3180e-01,  1.1850e-01,  4.6800e-02,  1.7500e-02, -1.8360e-01,\n",
      "        2.6000e-03, -5.5130e-01, -1.2840e-01,  4.6400e-02,  1.0450e-01,\n",
      "       -6.6400e-02,  6.4000e-03,  7.9200e-02, -1.4630e-01,  5.3600e-02,\n",
      "        4.9200e-02, -8.2200e-02,  4.8000e-03, -1.4180e-01,  2.0440e-01,\n",
      "        8.2340e-01, -3.0830e-01,  1.3960e-01, -4.5070e-01, -1.2460e-01,\n",
      "       -1.9430e-01, -1.3820e-01, -2.5510e-01, -3.4400e-02,  8.0000e-04,\n",
      "       -3.2600e-02,  1.6930e-01,  1.0930e-01, -3.3450e-01, -1.6410e-01,\n",
      "       -1.5100e-02,  1.1830e-01,  5.3560e-01, -2.0700e-01,  2.4900e-02,\n",
      "        8.2040e-01, -1.1410e-01,  1.9470e-01,  1.2396e+00, -6.7300e-02,\n",
      "        9.8700e-02,  1.4600e-02, -3.4400e-02, -7.6800e-02, -1.4425e+00,\n",
      "        2.4790e-01,  3.6500e-01,  2.9450e-01,  1.1030e-01,  2.0320e-01,\n",
      "       -7.2400e-02,  5.3000e-01, -1.3700e-02,  1.2510e-01,  7.5900e-02,\n",
      "       -3.2200e-02, -1.8920e-01, -4.5400e-02,  7.8030e-01,  1.0300e-01,\n",
      "        1.4790e-01,  8.8230e-01, -2.3130e-01,  4.1900e-02,  1.6720e-01,\n",
      "       -1.3200e-02, -8.3860e-01, -8.4900e-02, -1.1100e-01,  1.7140e-01,\n",
      "        5.2600e-02,  5.5650e-01, -2.1800e-01, -4.3030e-01,  9.5000e-02,\n",
      "       -8.9700e-01, -7.9960e-01,  8.5760e-01, -3.3900e-02, -1.4510e-01,\n",
      "        6.9750e-01, -5.7510e-01, -2.2200e-02, -3.0560e-01, -8.5000e-02,\n",
      "       -4.8200e-02,  6.3700e-02,  1.8600e-01, -1.9110e-01,  2.2520e-01,\n",
      "       -2.1010e-01,  4.5700e-02,  2.7540e-01, -6.9600e-02, -6.1110e-01,\n",
      "       -3.2300e-02,  2.8430e-01,  1.1390e-01, -2.9100e-01, -1.9240e-01,\n",
      "       -2.0000e-02, -2.2490e-01,  3.3800e-02,  1.7740e-01, -1.9270e-01,\n",
      "        1.7130e-01,  2.1540e-01, -2.5350e-01, -4.0950e-01, -5.8540e-01,\n",
      "        3.1100e-01, -3.6370e-01,  5.1000e-02, -2.1550e-01, -1.2450e-01,\n",
      "       -4.8300e-02, -1.9210e-01, -7.1000e-03,  4.1000e-02,  2.8770e-01,\n",
      "        3.5640e-01, -3.4820e-01, -7.6500e-02,  4.5600e-02, -1.1630e-01,\n",
      "        1.6100e-01, -9.0600e-02, -1.4730e-01, -9.0100e-02, -1.4120e-01,\n",
      "       -1.4540e-01,  2.7990e-01,  1.1850e-01, -8.1300e-02,  1.0410e-01,\n",
      "       -8.9370e-01,  2.0600e-01,  2.1060e-01, -2.1140e-01, -9.4500e-02,\n",
      "       -2.6400e-01, -8.7200e-02, -3.5100e-02,  2.5500e-02,  1.5080e-01,\n",
      "       -5.2330e-01,  1.2450e-01,  2.8180e-01, -1.9500e-02, -6.1500e-02,\n",
      "        3.4600e-02,  1.6700e-02, -1.5800e-02,  1.6020e-01, -1.8800e-02,\n",
      "        3.7190e-01, -1.8600e-02,  7.7900e-02, -4.7900e-02, -1.1420e-01,\n",
      "        6.1850e-01,  9.5300e-02,  9.9080e-01, -2.0400e-02,  2.0410e-01]), '2')\n"
     ]
    }
   ],
   "source": [
    "# exemple d'utilisation d'Extractor avec le verbe \"aboutir\" et 100% des données utilisées\n",
    "ext = Extractor(data_path, gold_path, embeddings_path, context_size)\n",
    "ext.define_instance(instance, 1, display=True)\n",
    "print(\"\\nexemple d'example avec contexte et gold class :\",ext.get_annotated_examples()[0])\n",
    "print(\"\\nau format embedding : \",ext.get_embs()[0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Apprentissage supervisé\n",
    "\n",
    "L'utilisation d'un Classifieur MLP permet de prédire le sens des verbes de façon supervisée. Il s'agit de la première méthode proposée pour la tâche de WSD.\n",
    "\n",
    "Les données utilisées sont les données annotées extraites du fichier FSE grâce à l'Extractor pour un lemme donné. Un MLPClassifier_WSD doit donc être créé pour chaque verbe dont on veut la prédiction.\n",
    "\n",
    "MLPClassifier_WSD comporte les méthodes suivantes :\n",
    "- `classify()` : pour prédire le sens du lemme associé au classifieur et calculer l'accuracy de cette prédiction\n",
    "- `get_accuracy_baseline()` : pour récupérer le sens le plus fréquent et son nombre d'occurences dans les données d'entraînement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPClassifier_WSD :\n",
    "    \n",
    "    def __init__(self, X_train, X_test, y_train, y_test) :\n",
    "        '''\n",
    "        A partir des données, prédit le sens d'un lemme et évalue la prédiction\n",
    "\n",
    "        ARGUMENTS DE CLASSE\n",
    "        self.X_train (list) : liste des contextes d'entraînement\n",
    "        self.y_train (list) : liste des gold class d'entraînement\n",
    "        self.X_test (list) : liste des contextes de test\n",
    "        self.y_test (list) : liste des gold class de test\n",
    "        self.accuracy (float) : accuracy du classifieur\n",
    "        self.accuracy_baseline (float) : accuracy  du classifieur selon la baseline\n",
    "\n",
    "        '''\n",
    "        # ensembles d'entraînement et de test provenant de l'Extractor pour un lemme donné\n",
    "        self.X_train = X_train\n",
    "        self.X_test = X_test\n",
    "        self.y_train = y_train\n",
    "        self.y_test = y_test \n",
    "\n",
    "        # prédiction du modèle\n",
    "        self.y_pred = []\n",
    "        # accuracy de la prédiction \n",
    "        self.accuracy = -1\n",
    "        # accuracy de la baseline : most frequent sense\n",
    "        self.accuracy_baseline = -1\n",
    "        # most frequent sens\n",
    "        self.mfs = -1\n",
    "        \n",
    "            \n",
    "    def classify(self, display=False) :\n",
    "        ''' \n",
    "        Permet de prédire le sens du verbe.\n",
    "\n",
    "        INPUT\n",
    "        display (bool, optional) : affiche une trace des options choisies\n",
    "        '''\n",
    "        try:\n",
    "            clf = MLPClassifier(random_state=1, hidden_layer_sizes=(100,)) \n",
    "            # entraînement\n",
    "            clf.fit(self.X_train, self.y_train)\n",
    "            # prédiction\n",
    "            self.y_pred = clf.predict(self.X_test)\n",
    "\n",
    "            # calcul de l'accuracy\n",
    "            self.accuracy = accuracy_score(self.y_pred, self.y_test)\n",
    "            \n",
    "            # calcul de l'accuracy de la baseline et récupération du most frequent sense\n",
    "            self.accuracy_baseline, self.mfs = self.get_accuracy_baseline()\n",
    "        \n",
    "            # si une trace est souhaitée\n",
    "            if display :\n",
    "                print(\"prediction :\", self.y_pred)\n",
    "                print(\"gold :\", self.y_test)\n",
    "                print(\"accuracy score : \", round(self.accuracy,2))\n",
    "                print(\"accuracy score de la baseline :\",self.accuracy_baseline)\n",
    "                \n",
    "        except:\n",
    "             print(\"/!\\ ERREUR /!\\: La quantité de données fournies est insuffisante: formation du test set impossible\")\n",
    "        \n",
    "    def get_accuracy_baseline(self):\n",
    "        ''' \n",
    "        Retourne le nombre d'étiquettes correspondantes au sens le plus fréquent et le sens le plus fréquent.\n",
    "\n",
    "        OUTPOUT\n",
    "        accuracy_baseline (float) : l'accuracy correspondante à la baseline\n",
    "        mfs (int) : sens le plus fréquent\n",
    "        '''\n",
    "        \n",
    "        # si la quantité de donées sélectionnées est suffisante\n",
    "        if self.y_train :\n",
    "            count_gold = Counter(self.y_train)\n",
    "            # accuracy de la baseline : on divise le nombre d'étiquettes \n",
    "            # dont le gold correspond au sens le plus fréquent par le nombre d'étiquettes prédites\n",
    "            accuracy_baseline = round(max(count_gold.items(),\n",
    "                                          key = lambda item:item[1])[1]/len(self.y_train),2)\n",
    "            mfs = max(count_gold.items(),key = lambda item:item[1])[0]\n",
    "        else :\n",
    "            mfs = -1\n",
    "            accuracy_baseline = -1.0\n",
    "        return accuracy_baseline, mfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/!\\ ERREUR /!\\ La taille des données est trop faible. L'opération train_test_split() est impossible.\n",
      "--> Instance : demeurer\n",
      "10.0% des données annotées considérées\n",
      "Nombre de données d'entraînement :  0\n",
      "Etiquettes possibles pour cette instance :  {'2', '3', '4', '6'}\n",
      "/!\\ ERREUR /!\\: La quantité de données fournies est insuffisante: formation du test set impossible\n"
     ]
    }
   ],
   "source": [
    "# exemple d'utilisation de MLPClassifieur_WSD avec le verbe \"demeurer\" et 100% des données utilisées\n",
    "ext = Extractor(data_path, gold_path, embeddings_path, context_size)\n",
    "ext.define_instance(\"demeurer\", 1, display=True)\n",
    "X_train, X_test, y_train, y_test = ext.get_sets()\n",
    "\n",
    "Clf = MLPClassifier_WSD(X_train, X_test, y_train, y_test)\n",
    "Clf.classify(display=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour pouvoir comparer les performances de ce Classifieur MLP avec celles de l'apprentissage semi-supervisé, nous devons créer un classifieur par verbe à désambiguiser et choisir un pas de descente pour la quantité de données annotées considérées.\n",
    "\n",
    "Pour chaque classifieur et chaque quantitée de données considérées, on effectue *n_repeat* classifications pour obtenir une accuracy moyenne ainsi qu'un nombre d'étiquette correctement prédit moyen dans un souci de représentativité.\n",
    "\n",
    "Par conséquent, pour :\n",
    "- n_repeat = 5\n",
    "- step = 0.25\n",
    "\n",
    "nous obtiendrons pour chaque classifieur une liste d'accuracies correspondant à :\n",
    "- la moyenne des accuracies de 5 prédictions \n",
    "- la moyenne du nombre d'étiquettes correctement prédites de 5 prédictions \n",
    "- pour 100%, 75%, 50% et 25% des données pour le MLP et 75%, 50%, 25% et 0% pour le K-Means (0% signifie en réalité qu'un seul example est considéré comme annoté).\n",
    "\n",
    "S'ajoute à cela le calcul la macro-average de l'accuracy qui s'effectue grâce aux listes obtenues ainsi que celui de la micro-average accuracy.\n",
    "\n",
    "Pour avoir une base de comparaison autonome pour chaque méthode, nous effectuons les mêmes évaluations en considérant des prédications selon la baseline du most frequent sense."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mean_accuracies(instance, data_size, n_repeat, display=True):\n",
    "    '''\n",
    "    Retourne une moyenne d'accuracies pour un nombre de classifications donné\n",
    "    ainsi qu'une moyenne du nombre d'étiquette correctement prédites ainsi que le nombre\n",
    "    d'étiquettes prédites, nécéssaires au calcul de la micro-average.\n",
    "\n",
    "    INPUT\n",
    "    n_repeat (int): nombre de classifications à effectuer\n",
    "    display (bool, optional): affiche une trace des options choisies\n",
    "\n",
    "    OUTPUT\n",
    "    mean_acc (float): moyenne des accuracies calculées\n",
    "    mean_acc_baseline (float) : moyenne des accuracies de la baseline\n",
    "    mean_corr_pred (int) : nombre d'étiquettes correctement prédites selon le classifieur\n",
    "    mean_corr_pred_baseline (int) : nombre d'étiquettes correctement prédites selon la baseline\n",
    "    n_pred (int) : nombre d'étiquettes prédites\n",
    "    '''\n",
    "\n",
    "    # liste de l'accuracy à chaque répétition\n",
    "    accuracies = []\n",
    "    \n",
    "    # liste de l'accuracy de la baseline à chaque répétition\n",
    "    accuracies_baseline = []\n",
    "    \n",
    "    # liste du nombre d'étiquettes correctement prédites\n",
    "    n_corr_pred = []\n",
    "    \n",
    "    # liste du nombre d'étiquettes correctement prédites selon la baseline\n",
    "    n_corr_pred_baseline = []\n",
    "    \n",
    "    # nombre d'étiquettes prédites\n",
    "    n_pred = 0\n",
    "    \n",
    "    for _ in range(n_repeat) :\n",
    "            \n",
    "        # pour chaque itération, un nouveau classifieur est créé, qui s'appuie toujours sur \n",
    "        # la même quantité de données mais avec un autre tirage des données\n",
    "        # par exemple, pour 75% des données, des accuracies différentes seront obtenues en\n",
    "        # fonction des tirages de ces données\n",
    "        ext.define_instance(instance, data_size, False)\n",
    "        X_train, X_test, y_train, y_test = ext.get_sets()\n",
    "        \n",
    "        # si les sets ne sont pas vides, i.e que la quantité de données sélectionnées est suffisante\n",
    "        if y_train :\n",
    "            \n",
    "            # les données utiles à l'évaluation sont récupérées du classifieur\n",
    "            Clf = MLPClassifier_WSD(X_train, X_test, y_train, y_test)\n",
    "            Clf.classify()\n",
    "            accuracies.append(Clf.accuracy)\n",
    "            accuracies_baseline.append(Clf.accuracy_baseline)\n",
    "            n_pred = len(y_test)\n",
    "            n_corr_pred.append(sum([1 for (gold,pred) in zip(y_test,Clf.y_pred) if gold==pred]))\n",
    "            n_corr_pred_baseline.append(sum([1 for gold in y_test if Clf.mfs==gold]))\n",
    "            \n",
    "        # lorsque la quantité de données sélectionnées est trop faible\n",
    "        else :\n",
    "            accuracies.append(-1.0)\n",
    "            accuracies_baseline.append(-1.0)\n",
    "            n_corr_pred.append(-1)\n",
    "            n_corr_pred_baseline.append(-1)\n",
    "    \n",
    "    # calcul des moyennes \n",
    "    mean_acc = sum(accuracies)/len(accuracies)\n",
    "    mean_acc_baseline = sum(accuracies_baseline)/len(accuracies_baseline)\n",
    "    mean_corr_pred = round(sum(n_corr_pred)/len(n_corr_pred))\n",
    "    mean_corr_pred_baseline = round(sum(n_corr_pred_baseline)/len(n_corr_pred_baseline))\n",
    "            \n",
    "    # si la trace est souhaitée\n",
    "    if display :\n",
    "        print(f'{data_size*100}% des données annotées considérées')\n",
    "        print(\"instance :\", instance)\n",
    "        print(\"accuracies :\", accuracies)\n",
    "        print(\"accuracy moyenne :\", mean_acc)\n",
    "        print(\"accuracies de la baseline :\",accuracies_baseline)\n",
    "        print(\"accuracy moyenne de la baseline :\", mean_acc_baseline,\"\\n\")\n",
    "\n",
    "    return mean_acc, mean_acc_baseline, mean_corr_pred, mean_corr_pred_baseline, n_pred \n",
    "\n",
    "def get_accuracies(instances, step, n_repeat, display=True):\n",
    "    '''\n",
    "    - Permet d'obtenir des accuracies moyennes par lemme pour une certaine quantité \n",
    "      de données considérée.\n",
    "    - Produit des fichiers csv.\n",
    "\n",
    "    INPUT\n",
    "    instances (list): liste des mots à désambiguiser\n",
    "    step (float): pas de descente dans la quantité de données à considérer\n",
    "    n_repeat (int): nombre de classifications tests à effectuer\n",
    "\n",
    "    OUTPUT\n",
    "    instance2acc (dict) : associe à chaque instance sa liste d'accuracies moyennes + macro_average\n",
    "    instance2acc_base (dict) : associe à chaque instance sa liste de baselines d'accuracies + macro_average\n",
    "    '''\n",
    "\n",
    "    # clé : mot à désambiguiser\n",
    "    # valeur : liste des accuracies moyennes à chaque pas de descente\n",
    "    instance2acc = {instance : [] for instance in instances}\n",
    "    instance2acc_base = {instance : [] for instance in instances}\n",
    "    \n",
    "    # listes des métriques d'évaluation calculées pour chaque quantité de données\n",
    "    macro_average_acc = []\n",
    "    macro_average_acc_base = []\n",
    "    micro_average = []\n",
    "    micro_average_baseline = []\n",
    "    \n",
    "    # compteurs pour le nombre d'étiquettes correctement prédites selon le classifieur et selon la baseline\n",
    "    n_corr_pred = 0\n",
    "    n_corr_pred_baseline = 0\n",
    "    \n",
    "    # nombre d'étiquettes prédites pour la quantité de données entrée\n",
    "    n_pred_tot = 0\n",
    "    \n",
    "    # liste qui permettra d'afficher la quantité de données considérées dans le .csv\n",
    "    data_sizes =[]\n",
    "            \n",
    "    # pour chaque quantité de données observée\n",
    "    for i in range(round(1.0/step)): \n",
    "                \n",
    "        # calcul de la taille des données avec le pas de descente (100%, 75%, 50%, 25%)\n",
    "        data_size = 1.0 - (step*float(i))\n",
    "        data_sizes.append(data_size)\n",
    "        \n",
    "        # pour chaque mot à désambiguiser\n",
    "        for instance in instances :\n",
    "            # calcul de ses accuracies moyennes, selon le classifieur et selon la baseline\n",
    "            # comptage des étiquettes correctement prédites et du nombre d'étiquettes prédites\n",
    "            mean_acc, mean_acc_baseline, mean_corr_pred, mean_corr_pred_baseline, n_pred = get_mean_accuracies(instance, data_size, n_repeat, display)\n",
    "            \n",
    "            instance2acc[instance].append(mean_acc)\n",
    "            instance2acc_base[instance].append(mean_acc_baseline)\n",
    "            n_corr_pred += mean_corr_pred\n",
    "            n_corr_pred_baseline += mean_corr_pred_baseline\n",
    "            n_pred_tot += n_pred\n",
    "        \n",
    "        # calcule les macro-averages et les micro-averages des valeurs obtenues, \n",
    "        # selon le classifieur et selon la baseline\n",
    "        accuracies = [accuracies[i] for accuracies in instance2acc.values() if accuracies[i] != -1.0]\n",
    "        macro_average_acc.append(sum(accuracies)/len(accuracies))\n",
    "        \n",
    "        accuracies_base = [accuracies_baseline[i] for accuracies_baseline in instance2acc_base.values() if accuracies_baseline[i] != -1.0]\n",
    "        macro_average_acc_base.append(sum(accuracies_base)/len(accuracies_base))\n",
    "        \n",
    "        micro_average.append(n_corr_pred/n_pred_tot)\n",
    "        micro_average_baseline.append(n_corr_pred_baseline/n_pred_tot)\n",
    "  \n",
    "    # ajout d'une clé macro_average pour avoir les moyennes de toutes les accuracies moyennes pour chaque instance\n",
    "    # pour chaque pas\n",
    "    instance2acc[\"macro_average\"] = macro_average_acc\n",
    "    instance2acc_base[\"macro_average\"] = macro_average_acc_base\n",
    "    \n",
    "    # ajout d'une clé micro_average pour avoir les micro_averages pour chaque instance\n",
    "    # pour chaque pas\n",
    "    instance2acc[\"micro_average\"] = micro_average\n",
    "    instance2acc_base[\"micro_average\"] = micro_average_baseline\n",
    "            \n",
    "    # ajout d'une clé pour stocker les tailles des données à chaque pas\n",
    "    instance2acc[\"data_sizes\"] = data_sizes\n",
    "    instance2acc_base[\"data_sizes\"] = data_sizes \n",
    "\n",
    "    # export en csv des résultats\n",
    "    df1 = pd.DataFrame(instance2acc)\n",
    "    df1.set_index(\"data_sizes\")\n",
    "    df1.to_csv(f\"../results/classifieur_accuracies_par_lemme_{n_repeat}_repet.csv\")\n",
    "    \n",
    "    df2 = pd.DataFrame(instance2acc_base)\n",
    "    df2.set_index(\"data_sizes\")\n",
    "    df2.to_csv(f\"../results/classifieur_accuracies_baseline_par_lemme_{n_repeat}_repet.csv\")\n",
    "    \n",
    "    \n",
    "    return instance2acc,instance2acc_base\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pas de descente dans la quantité de données considérées\n",
    "step = 0.25\n",
    "# nombre de classifications pour un classifieur pour obtenir une precision moyenne\n",
    "n_repeat = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\carol\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\carol\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\carol\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\carol\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\carol\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\carol\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\carol\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\carol\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\carol\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\carol\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\carol\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\carol\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\carol\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\carol\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\carol\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\carol\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\carol\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\carol\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\carol\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\carol\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\carol\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\carol\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\carol\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\carol\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\carol\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\carol\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\carol\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\carol\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\carol\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\carol\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\carol\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\carol\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\carol\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\carol\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\carol\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\carol\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\carol\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\carol\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\carol\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\carol\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\carol\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\carol\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\carol\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\carol\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\carol\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\carol\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\carol\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\carol\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\carol\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\carol\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\carol\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\carol\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\carol\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\carol\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\carol\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\carol\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\carol\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\carol\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\carol\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\carol\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\carol\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\carol\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\carol\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\carol\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\carol\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\carol\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\carol\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\carol\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\carol\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\carol\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\carol\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\carol\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\carol\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\carol\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\carol\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\carol\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\carol\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\carol\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\carol\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\carol\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\carol\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\carol\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\carol\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\carol\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\carol\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\carol\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\carol\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\carol\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\carol\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\carol\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\carol\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\carol\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\carol\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\carol\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\carol\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\carol\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\carol\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\carol\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\carol\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\carol\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\carol\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\carol\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\carol\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\carol\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\carol\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\carol\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\carol\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\carol\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\carol\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\carol\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\carol\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\carol\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\carol\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\carol\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\carol\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\carol\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\carol\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\carol\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\carol\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\carol\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\carol\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\carol\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\carol\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\carol\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\carol\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\carol\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\carol\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\carol\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\carol\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\carol\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\carol\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\carol\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\carol\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\carol\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\carol\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\carol\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\carol\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\carol\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\carol\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\carol\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\carol\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\carol\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\carol\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\carol\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\carol\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\carol\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\carol\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\carol\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\carol\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\carol\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\carol\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\carol\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\carol\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\carol\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\carol\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\carol\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\carol\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\carol\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\carol\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\carol\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\carol\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\carol\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\carol\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\carol\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\carol\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\carol\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\carol\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\carol\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\carol\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\carol\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\carol\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\carol\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\carol\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\carol\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\carol\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\carol\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\carol\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\carol\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\carol\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\carol\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\carol\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\carol\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\carol\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\carol\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\carol\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\carol\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\carol\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\carol\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\carol\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\carol\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\carol\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\carol\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\carol\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\carol\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\carol\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\carol\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\carol\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\carol\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\carol\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\carol\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\carol\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\carol\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\carol\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\carol\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\carol\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\carol\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\carol\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\carol\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\carol\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\carol\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\carol\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\carol\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\carol\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\carol\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\carol\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\carol\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\carol\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\carol\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\carol\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\carol\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\carol\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\carol\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\carol\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\carol\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\carol\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\carol\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\carol\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\carol\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\carol\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\carol\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\carol\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\carol\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\carol\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\carol\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\carol\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\carol\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\carol\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\carol\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\carol\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\carol\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\carol\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\carol\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\carol\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\carol\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/!\\ ERREUR /!\\ La taille des données est trop faible. L'opération train_test_split() est impossible.\n",
      "/!\\ ERREUR /!\\ La taille des données est trop faible. L'opération train_test_split() est impossible.\n",
      "/!\\ ERREUR /!\\ La taille des données est trop faible. L'opération train_test_split() est impossible.\n",
      "/!\\ ERREUR /!\\ La taille des données est trop faible. L'opération train_test_split() est impossible.\n",
      "/!\\ ERREUR /!\\ La taille des données est trop faible. L'opération train_test_split() est impossible.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'aboutir': [0.8181818181818181,\n",
       "   0.7777777777777777,\n",
       "   0.7333333333333334,\n",
       "   0.65],\n",
       "  'investir': [0.6, 0.62, 0.6523809523809524, 0.53],\n",
       "  'traduire': [0.8, 0.68, 0.6, 0.64],\n",
       "  'témoigner': [0.8333333333333333,\n",
       "   0.7555555555555555,\n",
       "   0.8523809523809524,\n",
       "   0.75],\n",
       "  'juger': [0.66, 0.65, 0.5333333333333333, 0.6666666666666666],\n",
       "  'justifier': [0.8181818181818181,\n",
       "   0.7555555555555555,\n",
       "   0.7666666666666666,\n",
       "   0.5666666666666667],\n",
       "  'viser': [0.9833333333333332, 0.9777777777777779, 0.8857142857142858, 0.75],\n",
       "  'prononcer': [0.5384615384615384, 0.4727272727272728, 0.35, 0.29],\n",
       "  'accomplir': [0.6307692307692307,\n",
       "   0.6509090909090909,\n",
       "   0.6690476190476191,\n",
       "   0.73],\n",
       "  'convenir': [0.6153846153846153, 0.5454545454545454, 0.375, 0.58],\n",
       "  'acquérir': [0.557142857142857, 0.530909090909091, 0.5027777777777779, 0.55],\n",
       "  'achever': [0.7454545454545454, 0.8222222222222222, 0.7666666666666667, 0.6],\n",
       "  'observer': [0.5076923076923078, 0.48, 0.5678571428571428, 0.6],\n",
       "  'adapter': [0.6153846153846153,\n",
       "   0.650909090909091,\n",
       "   0.5821428571428571,\n",
       "   0.12000000000000002],\n",
       "  'admettre': [0.65, 0.6222222222222222, 0.5666666666666667, 0.5],\n",
       "  'entraîner': [0.7166666666666666, 0.72, 0.7047619047619047, 0.6],\n",
       "  'payer': [0.38461538461538464,\n",
       "   0.52,\n",
       "   0.5035714285714286,\n",
       "   0.31666666666666665],\n",
       "  'respecter': [0.7454545454545454,\n",
       "   0.6222222222222221,\n",
       "   0.7714285714285715,\n",
       "   0.7],\n",
       "  'affecter': [0.6166666666666667,\n",
       "   0.5711111111111111,\n",
       "   0.5238095238095238,\n",
       "   0.6166666666666667],\n",
       "  'demeurer': [0.7090909090909092,\n",
       "   0.6444444444444445,\n",
       "   0.6285714285714286,\n",
       "   0.6],\n",
       "  'aggraver': [0.75, 0.7555555555555554, 0.6285714285714286, 0.7],\n",
       "  'agir': [0.676923076923077, 0.6599999999999999, 0.5321428571428571, 0.52],\n",
       "  'ajouter': [0.5076923076923077, 0.54, 0.5107142857142858, 0.38],\n",
       "  'alimenter': [0.6181818181818182,\n",
       "   0.6222222222222222,\n",
       "   0.5666666666666667,\n",
       "   0.6],\n",
       "  'coûter': [0.4666666666666667, 0.54, 0.45, 0.42000000000000004],\n",
       "  'relancer': [0.43636363636363634, 0.5333333333333334, 0.5, 0.45],\n",
       "  'préférer': [0.5818181818181818,\n",
       "   0.7111111111111111,\n",
       "   0.5333333333333333,\n",
       "   0.7],\n",
       "  'appliquer': [0.6166666666666666,\n",
       "   0.42000000000000004,\n",
       "   0.6285714285714286,\n",
       "   0.38],\n",
       "  'apporter': [0.43076923076923074,\n",
       "   0.3818181818181818,\n",
       "   0.3464285714285714,\n",
       "   0.27999999999999997],\n",
       "  'fonder': [0.6, 0.5599999999999999, 0.6523809523809524, 0.35],\n",
       "  'appuyer': [0.7090909090909091, 0.8222222222222222, 0.8, 0.6],\n",
       "  'changer': [0.4333333333333334,\n",
       "   0.42000000000000004,\n",
       "   0.3142857142857142,\n",
       "   0.30999999999999994],\n",
       "  'chuter': [0.8222222222222222, 0.8, 0.68, 0.7333333333333332],\n",
       "  'soutenir': [0.6, 0.58, 0.5428571428571429, 0.36666666666666664],\n",
       "  'concevoir': [0.8909090909090909, 0.888888888888889, 0.9, 0.75],\n",
       "  'interroger': [0.6833333333333333,\n",
       "   0.5800000000000001,\n",
       "   0.5904761904761905,\n",
       "   0.42000000000000004],\n",
       "  'confirmer': [0.46153846153846156, 0.36, 0.375, 0.36],\n",
       "  'transformer': [1.0, 1.0, 1.0, 1.0],\n",
       "  'manifester': [0.55, 0.5399999999999999, 0.45714285714285713, 0.53],\n",
       "  'interpeller': [0.9166666666666666,\n",
       "   0.9555555555555555,\n",
       "   0.9428571428571428,\n",
       "   1.0],\n",
       "  'signer': [0.8045454545454547,\n",
       "   0.6888888888888889,\n",
       "   0.7080952380952381,\n",
       "   0.5666666666666667],\n",
       "  'rester': [0.5692307692307692,\n",
       "   0.6202020202020202,\n",
       "   0.4428571428571429,\n",
       "   0.46333333333333326],\n",
       "  'tuer': [0.65, 0.5777777777777777, 0.5428571428571429, 0.7],\n",
       "  'indiquer': [0.6666666666666667,\n",
       "   0.7533333333333333,\n",
       "   0.661904761904762,\n",
       "   0.75],\n",
       "  'conduire': [0.2857142857142857,\n",
       "   0.38333333333333336,\n",
       "   0.3333333333333333,\n",
       "   0.2866666666666667],\n",
       "  'situer': [0.909090909090909, 0.8444444444444443, 0.8857142857142858, 0.8],\n",
       "  'aider': [0.45, 0.38, 0.325, 0.43],\n",
       "  'poursuivre': [0.5692307692307692, 0.64, 0.6785714285714286, 0.45],\n",
       "  'profiter': [0.909090909090909, 0.9111111111111111, 0.9, 0.7833333333333333],\n",
       "  'détenir': [0.6833333333333333, 0.6222222222222221, 0.8571428571428571, 0.6],\n",
       "  'lire': [0.6461538461538461, 0.6290909090909091, 0.6083333333333333, 0.55],\n",
       "  'contenir': [0.5, 0.4955555555555556, 0.5285714285714285, 0.34],\n",
       "  'dominer': [0.8, 0.7054545454545454, 0.6464285714285715, 0.64],\n",
       "  'noter': [1.0, 1.0, 0.9, -1.0],\n",
       "  'dater': [0.8709090909090909, 0.9333333333333333, 0.9428571428571428, 0.8],\n",
       "  'adopter': [0.5666666666666667, 0.52, 0.5821428571428571, 0.38],\n",
       "  'enregistrer': [0.75, 0.6555555555555556, 0.6809523809523809, 0.8],\n",
       "  'intervenir': [0.55, 0.5599999999999999, 0.5285714285714286, 0.43],\n",
       "  'conclure': [0.7666666666666667,\n",
       "   0.6666666666666667,\n",
       "   0.6095238095238095,\n",
       "   0.82],\n",
       "  'disputer': [0.9166666666666666,\n",
       "   0.9111111111111111,\n",
       "   0.9428571428571428,\n",
       "   1.0],\n",
       "  'estimer': [0.95, 0.8222222222222222, 0.8285714285714286, 0.75],\n",
       "  'appartenir': [0.5, 0.3, 0.5142857142857142, 0.4],\n",
       "  'arriver': [0.4769230769230769,\n",
       "   0.5272727272727272,\n",
       "   0.425,\n",
       "   0.4666666666666666],\n",
       "  'chercher': [0.5333333333333334,\n",
       "   0.8000000000000002,\n",
       "   0.6857142857142857,\n",
       "   0.62],\n",
       "  'composer': [1.0, 1.0, 0.9666666666666666, 0.9],\n",
       "  'confier': [0.7818181818181819, 0.7555555555555554, 0.7714285714285714, 1.0],\n",
       "  'macro_average': [0.6727883396065213,\n",
       "   0.658236914600551,\n",
       "   0.636135161135161,\n",
       "   0.5835897435897436],\n",
       "  'micro_average': [0.6606217616580311,\n",
       "   0.6544540229885057,\n",
       "   0.6422764227642277,\n",
       "   0.6313298627543776],\n",
       "  'data_sizes': [1.0, 0.75, 0.5, 0.25]},\n",
       " {'aboutir': [0.82, 0.8, 0.768, 0.6479999999999999],\n",
       "  'investir': [0.6839999999999999, 0.6900000000000001, 0.648, 0.546],\n",
       "  'traduire': [0.554, 0.514, 0.588, 0.548],\n",
       "  'témoigner': [0.914,\n",
       "   0.9179999999999999,\n",
       "   0.9359999999999999,\n",
       "   0.8479999999999999],\n",
       "  'juger': [0.7939999999999999, 0.76, 0.6940000000000001, 0.5519999999999999],\n",
       "  'justifier': [0.8699999999999999, 0.884, 0.842, 0.682],\n",
       "  'viser': [0.5599999999999999,\n",
       "   0.5519999999999999,\n",
       "   0.5999999999999999,\n",
       "   0.6260000000000001],\n",
       "  'prononcer': [0.344, 0.34, 0.37399999999999994, 0.384],\n",
       "  'accomplir': [0.8539999999999999,\n",
       "   0.8220000000000001,\n",
       "   0.7959999999999999,\n",
       "   0.644],\n",
       "  'convenir': [0.37399999999999994,\n",
       "   0.34800000000000003,\n",
       "   0.422,\n",
       "   0.33799999999999997],\n",
       "  'acquérir': [0.718, 0.718, 0.648, 0.488],\n",
       "  'achever': [0.616, 0.608, 0.608, 0.648],\n",
       "  'observer': [0.712, 0.7220000000000001, 0.6539999999999999, 0.548],\n",
       "  'adapter': [0.41200000000000003, 0.41200000000000003, 0.438, 0.392],\n",
       "  'admettre': [0.596, 0.614, 0.6180000000000001, 0.524],\n",
       "  'entraîner': [0.8360000000000001, 0.774, 0.7700000000000001, 0.596],\n",
       "  'payer': [0.5900000000000001, 0.504, 0.502, 0.388],\n",
       "  'respecter': [0.8480000000000001, 0.906, 0.852, 0.8240000000000001],\n",
       "  'affecter': [0.596, 0.574, 0.402, 0.268],\n",
       "  'demeurer': [0.758, 0.77, 0.674, 0.5720000000000001],\n",
       "  'aggraver': [0.8379999999999999, 0.842, 0.8, 0.89],\n",
       "  'agir': [0.41200000000000003, 0.404, 0.4720000000000001, 0.418],\n",
       "  'ajouter': [0.43, 0.4800000000000001, 0.488, 0.44000000000000006],\n",
       "  'alimenter': [0.616, 0.6340000000000001, 0.612, 0.536],\n",
       "  'coûter': [0.34, 0.364, 0.36599999999999994, 0.41400000000000003],\n",
       "  'relancer': [0.602, 0.6, 0.61, 0.534],\n",
       "  'préférer': [0.682, 0.6699999999999999, 0.694, 0.6900000000000002],\n",
       "  'appliquer': [0.5519999999999999, 0.578, 0.558, 0.616],\n",
       "  'apporter': [0.434, 0.47400000000000003, 0.446, 0.43000000000000005],\n",
       "  'fonder': [0.6119999999999999,\n",
       "   0.5940000000000001,\n",
       "   0.5519999999999999,\n",
       "   0.358],\n",
       "  'appuyer': [0.6980000000000001,\n",
       "   0.6980000000000001,\n",
       "   0.5899999999999999,\n",
       "   0.58],\n",
       "  'changer': [0.37, 0.4, 0.434, 0.41],\n",
       "  'chuter': [0.698, 0.72, 0.754, 0.734],\n",
       "  'soutenir': [0.6900000000000001, 0.684, 0.5999999999999999, 0.418],\n",
       "  'concevoir': [0.9259999999999999, 0.906, 0.89, 0.7840000000000001],\n",
       "  'interroger': [0.726, 0.764, 0.736, 0.608],\n",
       "  'confirmer': [0.39199999999999996, 0.42000000000000004, 0.446, 0.426],\n",
       "  'transformer': [1.0, 1.0, 1.0, 1.0],\n",
       "  'manifester': [0.55, 0.542, 0.6119999999999999, 0.548],\n",
       "  'interpeller': [0.97, 0.97, 0.9460000000000001, 0.9],\n",
       "  'signer': [0.7459999999999999, 0.71, 0.666, 0.51],\n",
       "  'rester': [0.5519999999999999, 0.488, 0.462, 0.31999999999999995],\n",
       "  'tuer': [0.726, 0.664, 0.6900000000000001, 0.714],\n",
       "  'indiquer': [0.874, 0.852, 0.8480000000000001, 0.766],\n",
       "  'conduire': [0.332, 0.316, 0.312, 0.34400000000000003],\n",
       "  'situer': [0.95, 0.97, 0.932, 0.874],\n",
       "  'aider': [0.362, 0.364, 0.328, 0.40800000000000003],\n",
       "  'poursuivre': [0.576, 0.5919999999999999, 0.5, 0.396],\n",
       "  'profiter': [0.884, 0.8619999999999999, 0.86, 0.788],\n",
       "  'détenir': [0.542, 0.546, 0.55, 0.626],\n",
       "  'lire': [0.734, 0.72, 0.656, 0.536],\n",
       "  'contenir': [0.44399999999999995, 0.466, 0.49399999999999994, 0.372],\n",
       "  'dominer': [0.8, 0.764, 0.75, 0.602],\n",
       "  'noter': [0.86, 0.82, 0.71, -1.0],\n",
       "  'dater': [0.874, 0.85, 0.82, 0.86],\n",
       "  'adopter': [0.672, 0.644, 0.648, 0.45],\n",
       "  'enregistrer': [0.784, 0.8099999999999999, 0.778, 0.64],\n",
       "  'intervenir': [0.5479999999999999, 0.6, 0.538, 0.524],\n",
       "  'conclure': [0.484, 0.5199999999999999, 0.488, 0.524],\n",
       "  'disputer': [0.95, 0.932, 0.8960000000000001, 0.8],\n",
       "  'estimer': [0.78, 0.8, 0.8320000000000001, 0.7140000000000001],\n",
       "  'appartenir': [0.56, 0.564, 0.488, 0.488],\n",
       "  'arriver': [0.6140000000000001,\n",
       "   0.614,\n",
       "   0.5700000000000001,\n",
       "   0.5199999999999999],\n",
       "  'chercher': [0.63, 0.62, 0.568, 0.504],\n",
       "  'composer': [0.874,\n",
       "   0.8400000000000001,\n",
       "   0.8099999999999999,\n",
       "   0.6599999999999999],\n",
       "  'confier': [0.5280000000000001, 0.546, 0.59, 0.6260000000000001],\n",
       "  'macro_average': [0.6616363636363637,\n",
       "   0.6583030303030304,\n",
       "   0.639757575757576,\n",
       "   0.574830769230769],\n",
       "  'micro_average': [0.5854922279792746,\n",
       "   0.5783045977011494,\n",
       "   0.5718157181571816,\n",
       "   0.5669663984855655],\n",
       "  'data_sizes': [1.0, 0.75, 0.5, 0.25]})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# récupération de tous les verbes du corpus à désambiguiser\n",
    "instances = list(ext.w2examples.keys())\n",
    "# calcul des precisions\n",
    "get_accuracies(instances, step, n_repeat, False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apprentissage semi-supervisé\n",
    "\n",
    "Le constrained k-means est la deuxième méthode proposée pour la tâche WSD, utilisant le clustering. Les données utilisées sont les mêmes que celles utilisées le Classifieur MLP.\n",
    "\n",
    "Constrained_K_Means comporte les méthodes suivantes :\n",
    "- `make_centroids()`: pour calculer les coordonnées des centroïdes à chaque example classifié\n",
    "- `learn_clusters()`: pour mettre à jour les coordonnées de chaque centroïdes après la classification d'un example\n",
    "- `accuracy()`: pour calculer l'accuracy (nombre de sens prédit correctement/nombre de sens à prédire)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Constrained_K_Means():\n",
    "    ''' \n",
    "    Classifieur K-means pour un mot particulier\n",
    "    '''\n",
    "\n",
    "    def __init__(self, annotated_examples, not_annotated_examples):\n",
    "        '''\n",
    "        Instancie les différentes variables utiles pour l'algorithme du K-means\n",
    "\n",
    "        INPUT\n",
    "        annotated_examples (list) : liste des exemples qui seront considérés\n",
    "                                     comme annotés pour la construction des premiers\n",
    "                                     centroïdes\n",
    "        non_annotated_examples (list) : liste des exemples à classifier \n",
    "        N.B.: un exemple est un tuple (tenseur, gold class)\n",
    "\n",
    "        ARGUMENTS DE CLASSE\n",
    "        self.annotated_examples\n",
    "        self.not_annotated_examples\n",
    "        self.k (int) : nombre de clusters pour ce lemme\n",
    "        self.centroids (list) : liste des centroïdes sous forme d'embeddings\n",
    "        self.cluster2sense (list) : associe chaque cluster (indice de la liste)\n",
    "                                    à un sens\n",
    "        '''\n",
    "\n",
    "        self.annotated_examples = annotated_examples\n",
    "\n",
    "        # les gold class ne seront utilisées que pour calculer l'accuracy\n",
    "        self.not_annotated_examples = not_annotated_examples\n",
    "\n",
    "        # initialisation de clusters : tous les examples non annotés sont associés \n",
    "        # au cluster 0\n",
    "        self.clusters = np.zeros(len(not_annotated_examples))\n",
    "\n",
    "        # détermine les sens possibles k (donc le nombre de clusters) \n",
    "        # N.B.: dans le cas du constrained Kmeans, cela \n",
    "        # peut se faire à l'aide des données annotées, qui représentent tous les sens possibles\n",
    "        self.k = len(set([example[1] for example in self.annotated_examples]))\n",
    "\n",
    "        # initialisation des centroïdes : pour chaque sens, le centroïde \n",
    "        # correspond à la moyenne des embeddings des exemples annotés\n",
    "        # Ainsi, chaque centroïde représente un sens\n",
    "        self.centroids, self.cluster2sense = self.make_centroids(self.annotated_examples)\n",
    "\n",
    "\n",
    "    def make_centroids(self, data):\n",
    "        '''\n",
    "        Calcule les coordonnées des centroïdes\n",
    "\n",
    "        INPUT\n",
    "        data (list) : liste des données ayant une étiquette\n",
    "\n",
    "        OUTPUT\n",
    "        centroids (list) : liste des coordonnées des centroïdes dans l'ordre\n",
    "                           des clusters\n",
    "        cluster2sense (list) : à chaque indice correpond au numéro d'un sens\n",
    "        '''\n",
    "\n",
    "        centroids = []\n",
    "        # clé : numéro du cluster (ie indice de la liste)\n",
    "        # valeur : numéro du sens associé\n",
    "        cluster2sense = []\n",
    "        # regroupe les sens présents dans le corpus\n",
    "        senses = set([example[1] for example in data])\n",
    "        # pour chaque sens\n",
    "        for sense in senses:\n",
    "            # récupère les examples correspondant à ce sens\n",
    "            examples_sense = [example[0] for example in data if example[1] == sense]\n",
    "            # le centroide correspond à la moyenne de tous ces examples\n",
    "            centroids.append(np.mean(examples_sense, axis=0))\n",
    "            # ajoute le numéro du sens\n",
    "            cluster2sense.append(sense)\n",
    "\n",
    "        return centroids, cluster2sense\n",
    "\n",
    "\n",
    "    def learn_clusters(self):\n",
    "        '''\n",
    "        Algorithme d'apprentissage de K-Means : met à jour les coordonnées\n",
    "        des centroïdes après chaque annotation d'exemple\n",
    "        '''\n",
    "\n",
    "        # CALCUL DES DISTANCES ENTRE CHAQUE EXAMPLE ET CHAQUE CENTROIDE\n",
    "         \n",
    "        # pour chaque couple (indice, coordonnées) dans les examples\n",
    "        for i, example in enumerate(self.not_annotated_examples):\n",
    "            # initialisation de la distance minimum à l'infini\n",
    "            min_dist = float('inf')\n",
    "            # pour chaque couple (indice, coordonnées) dans les centroides\n",
    "            for j, centroid in enumerate(self.centroids):\n",
    "                # calcul de la distance entre cet example et ce centroide\n",
    "                d = np.sqrt(np.sum(np.square(centroid - example[0])))\n",
    "                # si une distance plus faible est trouvée\n",
    "                if min_dist > d:\n",
    "                    # la distance ainsi que le centroide sont stockés\n",
    "                    min_dist = d\n",
    "                    self.clusters[i] = j\n",
    "                \n",
    "            # CALCUL ET MISE A JOUR DES NOUVEAUX CENTROIDES\n",
    "            \n",
    "            # donne l'étiquette prédite à cet exemple\n",
    "            predicted_example = (self.not_annotated_examples[i][0], self.cluster2sense[int(self.clusters[i])])\n",
    "            # fusionne les données annotées avec cette donnée prédite\n",
    "            data = self.annotated_examples\n",
    "            data.append(predicted_example)\n",
    "            # pour mettre à jour les centroides\n",
    "            self.make_centroids(data)\n",
    "\n",
    "    def accuracy(self): \n",
    "        '''\n",
    "        Calcule l'accuracy sur l'ensemble des données à annoter\n",
    "\n",
    "        OUTPUT\n",
    "        - correct (int) : nombre de fois où le sens prédit est le bon\n",
    "        - len(self.not_annotated_examples) (int): nombre total d'examples non annotés\n",
    "        '''\n",
    "        correct = 0\n",
    "        # pour chaque couple (indice, coordonnées) dans les examples\n",
    "        for i, example in enumerate(self.not_annotated_examples):\n",
    "            # si l'étiquette prédite est la bonne\n",
    "            if example[1] == self.cluster2sense[int(self.clusters[i])]:\n",
    "                # on incrémente correct\n",
    "                correct += 1\n",
    "        \n",
    "        return correct, len(self.not_annotated_examples)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_annotated_and_unannotated_sets(instance, data_size):\n",
    "    '''\n",
    "    Dernière étape de la préparation des données pour le clustering.\n",
    "    \n",
    "    INPUT\n",
    "    instance (str): mot à désambiguiser\n",
    "    data_size (float): quantité de données à considérer\n",
    "\n",
    "    OUTPUT\n",
    "    annotated_set (list): liste des données annotées contenant des tuples\n",
    "                          (vecteur numpy, sens)\n",
    "    unannotated_set (list): liste des données (que l'on utilisera comme) \n",
    "                            non annotées contenant des tuples(vecteur numpy, sens)\n",
    "    '''\n",
    "\n",
    "    # définit l'instance à désambiguiser\n",
    "    ext.define_instance(instance, data_size, False)\n",
    "    # récupère les données annotées et non annotées\n",
    "    annotated_set, unannotated_set = ext.get_annotated_and_unannotated_sets()\n",
    "    annotated_set = [(np.array(embedding),sense) for embedding, sense in annotated_set]\n",
    "    unannotated_set = [(np.array(embedding),gold) for embedding, gold in unannotated_set]\n",
    "    \n",
    "    return annotated_set, unannotated_set\n",
    "\n",
    "\n",
    "def make_csv_per_instance(instance, n_repeat, data_size, accuracy, averages2score, n_repeat_most_frequent_senses): \n",
    "    '''\n",
    "    Création d'un fichier csv pour chaque instance contenant les moyennes obtenues sur les répétitions\n",
    "    \n",
    "    INPUT\n",
    "    instance (str): mot à désambiguiser\n",
    "    n_repeat (int): nombre de répétitions\n",
    "    data_size (float): quantité de données à considérer\n",
    "    macro_average (float): moyenne des macro-averages obtenues sur les répétitions\n",
    "    micro_average (float): moyenne des micro-averages obtenues sur les répétitions\n",
    "    averages2score (dict): dictionnaire qui associe à chaque moyenne le score correspondant\n",
    "    n_repeat_most_frequent_senses (int): nombre de fois où le sens le plus fréquent a été prédit\n",
    "\n",
    "    OUTPUT\n",
    "    averages2score (dict): dictionnaire qui associe à chaque moyenne le score correspondant\n",
    "    '''\n",
    "\n",
    "    # on ouvre le fichier csv pour ajouter une ligne avec les moyennes obtenues\n",
    "    df = pd.read_csv(f\"../results/kmeans_accuracies_{instance}_for_{n_repeat}_repetitions.csv\")\n",
    "    df.loc[len(df)] = [data_size, accuracy, n_repeat_most_frequent_senses]\n",
    "    df.to_csv(f\"../results/kmeans_accuracies_{instance}_for_{n_repeat}_repetitions.csv\", index=False)\n",
    "\n",
    "    # on stocke les moyennes obtenues pour chaque instance\n",
    "    averages2score[\"accuracy\"].append(accuracy)\n",
    "    averages2score[\"most_frequent_sense\"].append(n_repeat_most_frequent_senses)\n",
    "\n",
    "    return averages2score\n",
    "\n",
    "\n",
    "def get_macro_and_micro_average(averages2score, micro_average, macro_average, correct_classification_for_all_instances, classified_examples_for_all_instances, data_size, display): \n",
    "    '''\n",
    "    Calcul des moyennes des macro-averages et des micro-averages obtenues sur les répétitions\n",
    "    \n",
    "    INPUT\n",
    "    n_repeat_macro_averages (list): liste des macro-averages obtenues sur les répétitions\n",
    "    n_repeat_micro_averages (list): liste des micro-averages obtenues sur les répétitions\n",
    "                                    display (bool): si True, affiche les moyennes obtenues\n",
    "\n",
    "    OUTPUT\n",
    "    mean_macro_average_score (float): moyenne des macro-averages obtenues sur les répétitions\n",
    "    mean_micro_averages (float): moyenne des micro-averages obtenues sur les répétitions\n",
    "    '''\n",
    "    micro_average.append(round(correct_classification_for_all_instances/classified_examples_for_all_instances,2))\n",
    "    macro_average.append(round(sum(averages2score[\"accuracy\"])/len(averages2score[\"accuracy\"]),2))\n",
    "\n",
    "    if display:\n",
    "        print(f\"Macro et micro average pour {round(data_size*100,2)}% des données annotées\")\n",
    "        print(\"Macro-average :\", round(correct_classification_for_all_instances/classified_examples_for_all_instances,2))\n",
    "        print(\"Micro-average :\", round(sum(averages2score[\"accuracy\"])/len(averages2score[\"accuracy\"]),2))\n",
    "        print(\"\\n--------------------------------------------------\\n\")\n",
    "    return micro_average, macro_average\n",
    "\n",
    "\n",
    "def get_accuracy(n_repeat_accuracies, display):\n",
    "\n",
    "    if display: \n",
    "        print(f\"Accuracy : {round(sum(n_repeat_accuracies)/len(n_repeat_accuracies),2)}\")\n",
    "        print()\n",
    "\n",
    "    return round(sum(n_repeat_accuracies)/len(n_repeat_accuracies),2)\n",
    "\n",
    "\n",
    "def create_kmeans_mean_accuracies_csv(mean_averages2score, macro_average, micro_average, data_sizes, n_repeat):\n",
    "    '''\n",
    "    Création d'un fichier csv contenant les moyennes des macro-averages et des micro-averages \n",
    "    pour toutes les instances\n",
    "    \n",
    "    INPUT\n",
    "    mean_averages2score (dict): dictionnaire qui associe à chaque moyenne le score correspondant\n",
    "    mean_macro_averages_for_kmeans (list): liste des moyennes des macro-averages obtenues pour\n",
    "                                           toutes les instances à chaque pas\n",
    "    mean_micro_averages_for_kmeans (list): liste des moyennes des micro-averages obtenues pour \n",
    "                                           toutes les instances à chaque pas\n",
    "    data_sizes (list): liste des tailles des données à chaque pas\n",
    "    n_repeat (int): nombre de répétitions\n",
    "    '''\n",
    "\n",
    "    mean_averages2score[\"macro_average\"] = macro_average\n",
    "    mean_averages2score[\"micro_average\"] = micro_average \n",
    "    mean_averages2score[\"data_sizes\"] = data_sizes\n",
    "    # export en csv des résultats\n",
    "    df = pd.DataFrame(mean_averages2score)\n",
    "    df.set_index([\"data_sizes\"], inplace=True)\n",
    "    df.to_csv(f\"../results/kmeans_mean_accuracies_for_{n_repeat}_repetitions.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pas de descente dans la quantité de données considérées\n",
    "step = 0.25\n",
    "# nombre de classifications pour un classifieur pour obtenir une accuracy moyenne\n",
    "n_repeat = 5\n",
    "# nombre d'itérations maximal\n",
    "max_iter = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--> Instance : aboutir\n",
      "Proportion de données annotées considérées sur le corpus: 75.0 %\n",
      "Répartition des sens: Counter({'3': 30, '4': 6, '2': 1, '1': 1})\n",
      "Le sens le plus fréquent pour 'aboutir' est le sens 3 avec une proportion de 78.95 %\n",
      "\n",
      "Accuracy : 0.82\n",
      "\n",
      "--> Instance : investir\n",
      "Proportion de données annotées considérées sur le corpus: 75.0 %\n",
      "Répartition des sens: Counter({'4': 23, '3': 10, '1': 4, '2': 1})\n",
      "Le sens le plus fréquent pour 'investir' est le sens 4 avec une proportion de 60.53 %\n",
      "\n",
      "Accuracy : 0.47\n",
      "\n",
      "--> Instance : traduire\n",
      "Proportion de données annotées considérées sur le corpus: 75.0 %\n",
      "Répartition des sens: Counter({'1': 17, '5': 15, '4': 6})\n",
      "Le sens le plus fréquent pour 'traduire' est le sens 1 avec une proportion de 44.74 %\n",
      "\n",
      "Accuracy : 0.53\n",
      "\n",
      "--> Instance : témoigner\n",
      "Proportion de données annotées considérées sur le corpus: 75.0 %\n",
      "Répartition des sens: Counter({'2': 33, '1': 5})\n",
      "Le sens le plus fréquent pour 'témoigner' est le sens 2 avec une proportion de 86.84 %\n",
      "\n",
      "Accuracy : 0.8\n",
      "\n",
      "--> Instance : juger\n",
      "Proportion de données annotées considérées sur le corpus: 75.0 %\n",
      "Répartition des sens: Counter({'7': 23, '5': 3, '1': 2, '6': 1})\n",
      "Le sens le plus fréquent pour 'juger' est le sens 7 avec une proportion de 79.31 %\n",
      "\n",
      "Accuracy : 0.51\n",
      "\n",
      "--> Instance : justifier\n",
      "Proportion de données annotées considérées sur le corpus: 75.0 %\n",
      "Répartition des sens: Counter({'2': 34, '3': 2, '4': 1, '6': 1})\n",
      "Le sens le plus fréquent pour 'justifier' est le sens 2 avec une proportion de 89.47 %\n",
      "\n",
      "Accuracy : 0.62\n",
      "\n",
      "--> Instance : viser\n",
      "Proportion de données annotées considérées sur le corpus: 75.0 %\n",
      "Répartition des sens: Counter({'4': 22, '3': 16})\n",
      "Le sens le plus fréquent pour 'viser' est le sens 4 avec une proportion de 57.89 %\n",
      "\n",
      "Accuracy : 0.97\n",
      "\n",
      "--> Instance : prononcer\n",
      "Proportion de données annotées considérées sur le corpus: 75.0 %\n",
      "Répartition des sens: Counter({'2': 11, '7': 10, '3': 8, '1': 6, '4': 3})\n",
      "Le sens le plus fréquent pour 'prononcer' est le sens 2 avec une proportion de 28.95 %\n",
      "\n",
      "Accuracy : 0.37\n",
      "\n",
      "--> Instance : accomplir\n",
      "Proportion de données annotées considérées sur le corpus: 75.0 %\n",
      "Répartition des sens: Counter({'2': 32, '1': 4, '4': 2, '3': 1})\n",
      "Le sens le plus fréquent pour 'accomplir' est le sens 2 avec une proportion de 82.05 %\n",
      "\n",
      "Accuracy : 0.62\n",
      "\n",
      "--> Instance : convenir\n",
      "Proportion de données annotées considérées sur le corpus: 75.0 %\n",
      "Répartition des sens: Counter({'1': 15, '3': 10, '6': 6, '2': 4, '5': 3})\n",
      "Le sens le plus fréquent pour 'convenir' est le sens 1 avec une proportion de 39.47 %\n",
      "\n",
      "Accuracy : 0.37\n",
      "\n",
      "--> Instance : acquérir\n",
      "Proportion de données annotées considérées sur le corpus: 75.0 %\n",
      "Répartition des sens: Counter({'1': 24, '4': 6, '5': 4, '2': 3, '6': 2})\n",
      "Le sens le plus fréquent pour 'acquérir' est le sens 1 avec une proportion de 61.54 %\n",
      "\n",
      "Accuracy : 0.5\n",
      "\n",
      "--> Instance : achever\n",
      "Proportion de données annotées considérées sur le corpus: 75.0 %\n",
      "Répartition des sens: Counter({'1': 26, '5': 11, '3': 1})\n",
      "Le sens le plus fréquent pour 'achever' est le sens 1 avec une proportion de 68.42 %\n",
      "\n",
      "Accuracy : 0.7\n",
      "\n",
      "--> Instance : observer\n",
      "Proportion de données annotées considérées sur le corpus: 75.0 %\n",
      "Répartition des sens: Counter({'4': 28, '1': 4, '2': 3, '3': 3})\n",
      "Le sens le plus fréquent pour 'observer' est le sens 4 avec une proportion de 73.68 %\n",
      "\n",
      "Accuracy : 0.52\n",
      "\n",
      "--> Instance : adapter\n",
      "Proportion de données annotées considérées sur le corpus: 75.0 %\n",
      "Répartition des sens: Counter({'3': 20, '7': 9, '5': 6, '4': 2, '2': 1})\n",
      "Le sens le plus fréquent pour 'adapter' est le sens 3 avec une proportion de 52.63 %\n",
      "\n",
      "Accuracy : 0.55\n",
      "\n",
      "--> Instance : admettre\n",
      "Proportion de données annotées considérées sur le corpus: 75.0 %\n",
      "Répartition des sens: Counter({'2': 21, '3': 13, '4': 1, '1': 1})\n",
      "Le sens le plus fréquent pour 'admettre' est le sens 2 avec une proportion de 58.33 %\n",
      "\n",
      "Accuracy : 0.55\n",
      "\n",
      "--> Instance : entraîner\n",
      "Proportion de données annotées considérées sur le corpus: 75.0 %\n",
      "Répartition des sens: Counter({'4': 31, '5': 4, '3': 2, '2': 1})\n",
      "Le sens le plus fréquent pour 'entraîner' est le sens 4 avec une proportion de 81.58 %\n",
      "\n",
      "Accuracy : 0.72\n",
      "\n",
      "--> Instance : payer\n",
      "Proportion de données annotées considérées sur le corpus: 75.0 %\n",
      "Répartition des sens: Counter({'1': 19, '2': 9, '3': 7, '10': 2, '7': 1, '11': 1})\n",
      "Le sens le plus fréquent pour 'payer' est le sens 1 avec une proportion de 48.72 %\n",
      "\n",
      "Accuracy : 0.35\n",
      "\n",
      "--> Instance : respecter\n",
      "Proportion de données annotées considérées sur le corpus: 75.0 %\n",
      "Répartition des sens: Counter({'2': 29, '1': 8})\n",
      "Le sens le plus fréquent pour 'respecter' est le sens 2 avec une proportion de 78.38 %\n",
      "\n",
      "Accuracy : 0.65\n",
      "\n",
      "--> Instance : affecter\n",
      "Proportion de données annotées considérées sur le corpus: 75.0 %\n",
      "Répartition des sens: Counter({'8': 22, '1': 7, '6': 3, '7': 2, '5': 1, '10': 1, '3': 1, '4': 1})\n",
      "Le sens le plus fréquent pour 'affecter' est le sens 8 avec une proportion de 57.89 %\n",
      "\n",
      "Accuracy : 0.52\n",
      "\n",
      "--> Instance : demeurer\n",
      "Proportion de données annotées considérées sur le corpus: 75.0 %\n",
      "Répartition des sens: Counter({'4': 24, '2': 5, '3': 5, '6': 1})\n",
      "Le sens le plus fréquent pour 'demeurer' est le sens 4 avec une proportion de 68.57 %\n",
      "\n",
      "Accuracy : 0.82\n",
      "\n",
      "--> Instance : aggraver\n",
      "Proportion de données annotées considérées sur le corpus: 75.0 %\n",
      "Répartition des sens: Counter({'1': 30, '2': 8})\n",
      "Le sens le plus fréquent pour 'aggraver' est le sens 1 avec une proportion de 78.95 %\n",
      "\n",
      "Accuracy : 0.72\n",
      "\n",
      "--> Instance : agir\n",
      "Proportion de données annotées considérées sur le corpus: 75.0 %\n",
      "Répartition des sens: Counter({'7': 19, '3': 10, '1': 7, '6': 1, '2': 1})\n",
      "Le sens le plus fréquent pour 'agir' est le sens 7 avec une proportion de 50.0 %\n",
      "\n",
      "Accuracy : 0.53\n",
      "\n",
      "--> Instance : ajouter\n",
      "Proportion de données annotées considérées sur le corpus: 75.0 %\n",
      "Répartition des sens: Counter({'2': 18, '1': 13, '5': 4, '3': 3})\n",
      "Le sens le plus fréquent pour 'ajouter' est le sens 2 avec une proportion de 47.37 %\n",
      "\n",
      "Accuracy : 0.52\n",
      "\n",
      "--> Instance : alimenter\n",
      "Proportion de données annotées considérées sur le corpus: 75.0 %\n",
      "Répartition des sens: Counter({'2': 21, '3': 16, '1': 1})\n",
      "Le sens le plus fréquent pour 'alimenter' est le sens 2 avec une proportion de 55.26 %\n",
      "\n",
      "Accuracy : 0.58\n",
      "\n",
      "--> Instance : coûter\n",
      "Proportion de données annotées considérées sur le corpus: 75.0 %\n",
      "Répartition des sens: Counter({'1': 12, '3': 11, '2': 10, '4': 3})\n",
      "Le sens le plus fréquent pour 'coûter' est le sens 1 avec une proportion de 33.33 %\n",
      "\n",
      "Accuracy : 0.51\n",
      "\n",
      "--> Instance : relancer\n",
      "Proportion de données annotées considérées sur le corpus: 75.0 %\n",
      "Répartition des sens: Counter({'1': 23, '6': 14, '2': 1})\n",
      "Le sens le plus fréquent pour 'relancer' est le sens 1 avec une proportion de 60.53 %\n",
      "\n",
      "Accuracy : 0.56\n",
      "\n",
      "--> Instance : préférer\n",
      "Proportion de données annotées considérées sur le corpus: 75.0 %\n",
      "Répartition des sens: Counter({'1': 27, '3': 10, '2': 1})\n",
      "Le sens le plus fréquent pour 'préférer' est le sens 1 avec une proportion de 71.05 %\n",
      "\n",
      "Accuracy : 0.48\n",
      "\n",
      "--> Instance : appliquer\n",
      "Proportion de données annotées considérées sur le corpus: 75.0 %\n",
      "Répartition des sens: Counter({'3': 20, '2': 14, '8': 4})\n",
      "Le sens le plus fréquent pour 'appliquer' est le sens 3 avec une proportion de 52.63 %\n",
      "\n",
      "Accuracy : 0.47\n",
      "\n",
      "--> Instance : apporter\n",
      "Proportion de données annotées considérées sur le corpus: 75.0 %\n",
      "Répartition des sens: Counter({'1': 17, '2': 11, '4': 5, '3': 3, '5': 2})\n",
      "Le sens le plus fréquent pour 'apporter' est le sens 1 avec une proportion de 44.74 %\n",
      "\n",
      "Accuracy : 0.38\n",
      "\n",
      "--> Instance : fonder\n",
      "Proportion de données annotées considérées sur le corpus: 75.0 %\n",
      "Répartition des sens: Counter({'4': 22, '6': 8, '5': 5, '7': 2, '3': 1, '1': 1})\n",
      "Le sens le plus fréquent pour 'fonder' est le sens 4 avec une proportion de 56.41 %\n",
      "\n",
      "Accuracy : 0.52\n",
      "\n",
      "--> Instance : appuyer\n",
      "Proportion de données annotées considérées sur le corpus: 75.0 %\n",
      "Répartition des sens: Counter({'2': 24, '10': 11, '5': 1, '6': 1})\n",
      "Le sens le plus fréquent pour 'appuyer' est le sens 2 avec une proportion de 64.86 %\n",
      "\n",
      "Accuracy : 0.69\n",
      "\n",
      "--> Instance : changer\n",
      "Proportion de données annotées considérées sur le corpus: 75.0 %\n",
      "Répartition des sens: Counter({'4': 13, '1': 11, '5': 7, '9': 4, '6': 1})\n",
      "Le sens le plus fréquent pour 'changer' est le sens 4 avec une proportion de 36.11 %\n",
      "\n",
      "Accuracy : 0.35\n",
      "\n",
      "--> Instance : chuter\n",
      "Proportion de données annotées considérées sur le corpus: 75.0 %\n",
      "Répartition des sens: Counter({'4': 19, '1': 8})\n",
      "Le sens le plus fréquent pour 'chuter' est le sens 4 avec une proportion de 70.37 %\n",
      "\n",
      "Accuracy : 0.72\n",
      "\n",
      "--> Instance : soutenir\n",
      "Proportion de données annotées considérées sur le corpus: 75.0 %\n",
      "Répartition des sens: Counter({'2': 26, '4': 6, '1': 3, '5': 1, '6': 1, '3': 1})\n",
      "Le sens le plus fréquent pour 'soutenir' est le sens 2 avec une proportion de 68.42 %\n",
      "\n",
      "Accuracy : 0.58\n",
      "\n",
      "--> Instance : concevoir\n",
      "Proportion de données annotées considérées sur le corpus: 75.0 %\n",
      "Répartition des sens: Counter({'2': 36, '4': 1, '1': 1})\n",
      "Le sens le plus fréquent pour 'concevoir' est le sens 2 avec une proportion de 94.74 %\n",
      "\n",
      "Accuracy : 0.68\n",
      "\n",
      "--> Instance : interroger\n",
      "Proportion de données annotées considérées sur le corpus: 75.0 %\n",
      "Répartition des sens: Counter({'1': 25, '3': 10, '2': 3})\n",
      "Le sens le plus fréquent pour 'interroger' est le sens 1 avec une proportion de 65.79 %\n",
      "\n",
      "Accuracy : 0.65\n",
      "\n",
      "--> Instance : confirmer\n",
      "Proportion de données annotées considérées sur le corpus: 75.0 %\n",
      "Répartition des sens: Counter({'2': 15, '5': 12, '3': 6, '4': 5})\n",
      "Le sens le plus fréquent pour 'confirmer' est le sens 2 avec une proportion de 39.47 %\n",
      "\n",
      "Accuracy : 0.43\n",
      "\n",
      "--> Instance : transformer\n",
      "Proportion de données annotées considérées sur le corpus: 75.0 %\n",
      "Répartition des sens: Counter({'1': 12})\n",
      "Le sens le plus fréquent pour 'transformer' est le sens 1 avec une proportion de 100.0 %\n",
      "\n",
      "Accuracy : 1.0\n",
      "\n",
      "--> Instance : manifester\n",
      "Proportion de données annotées considérées sur le corpus: 75.0 %\n",
      "Répartition des sens: Counter({'1': 20, '4': 9, '3': 8})\n",
      "Le sens le plus fréquent pour 'manifester' est le sens 1 avec une proportion de 54.05 %\n",
      "\n",
      "Accuracy : 0.55\n",
      "\n",
      "--> Instance : interpeller\n",
      "Proportion de données annotées considérées sur le corpus: 75.0 %\n",
      "Répartition des sens: Counter({'5': 36, '1': 2})\n",
      "Le sens le plus fréquent pour 'interpeller' est le sens 5 avec une proportion de 94.74 %\n",
      "\n",
      "Accuracy : 0.87\n",
      "\n",
      "--> Instance : signer\n",
      "Proportion de données annotées considérées sur le corpus: 75.0 %\n",
      "Répartition des sens: Counter({'1': 30, '2': 4, '7': 2, '5': 1, '4': 1})\n",
      "Le sens le plus fréquent pour 'signer' est le sens 1 avec une proportion de 78.95 %\n",
      "\n",
      "Accuracy : 0.7\n",
      "\n",
      "--> Instance : rester\n",
      "Proportion de données annotées considérées sur le corpus: 75.0 %\n",
      "Répartition des sens: Counter({'1': 18, '3': 10, '4': 4, '6': 2, '7': 2, '5': 1, '2': 1})\n",
      "Le sens le plus fréquent pour 'rester' est le sens 1 avec une proportion de 47.37 %\n",
      "\n",
      "Accuracy : 0.43\n",
      "\n",
      "--> Instance : tuer\n",
      "Proportion de données annotées considérées sur le corpus: 75.0 %\n",
      "Répartition des sens: Counter({'1': 29, '2': 9})\n",
      "Le sens le plus fréquent pour 'tuer' est le sens 1 avec une proportion de 76.32 %\n",
      "\n",
      "Accuracy : 0.43\n",
      "\n",
      "--> Instance : indiquer\n",
      "Proportion de données annotées considérées sur le corpus: 75.0 %\n",
      "Répartition des sens: Counter({'2': 33, '4': 4, '1': 1})\n",
      "Le sens le plus fréquent pour 'indiquer' est le sens 2 avec une proportion de 86.84 %\n",
      "\n",
      "Accuracy : 0.6\n",
      "\n",
      "--> Instance : conduire\n",
      "Proportion de données annotées considérées sur le corpus: 75.0 %\n",
      "Répartition des sens: Counter({'2': 11, '1': 8, '10': 6, '7': 6, '8': 4, '9': 3})\n",
      "Le sens le plus fréquent pour 'conduire' est le sens 2 avec une proportion de 28.95 %\n",
      "\n",
      "Accuracy : 0.2\n",
      "\n",
      "--> Instance : situer\n",
      "Proportion de données annotées considérées sur le corpus: 75.0 %\n",
      "Répartition des sens: Counter({'1': 36, '2': 2})\n",
      "Le sens le plus fréquent pour 'situer' est le sens 1 avec une proportion de 94.74 %\n",
      "\n",
      "Accuracy : 0.67\n",
      "\n",
      "--> Instance : aider\n",
      "Proportion de données annotées considérées sur le corpus: 75.0 %\n",
      "Répartition des sens: Counter({'3': 12, '2': 12, '6': 8, '1': 5, '4': 1})\n",
      "Le sens le plus fréquent pour 'aider' est le sens 3 avec une proportion de 31.58 %\n",
      "\n",
      "Accuracy : 0.29\n",
      "\n",
      "--> Instance : poursuivre\n",
      "Proportion de données annotées considérées sur le corpus: 75.0 %\n",
      "Répartition des sens: Counter({'4': 21, '6': 9, '5': 5, '3': 2, '1': 1})\n",
      "Le sens le plus fréquent pour 'poursuivre' est le sens 4 avec une proportion de 55.26 %\n",
      "\n",
      "Accuracy : 0.58\n",
      "\n",
      "--> Instance : profiter\n",
      "Proportion de données annotées considérées sur le corpus: 75.0 %\n",
      "Répartition des sens: Counter({'2': 34, '7': 3, '4': 1})\n",
      "Le sens le plus fréquent pour 'profiter' est le sens 2 avec une proportion de 89.47 %\n",
      "\n",
      "Accuracy : 0.91\n",
      "\n",
      "--> Instance : détenir\n",
      "Proportion de données annotées considérées sur le corpus: 75.0 %\n",
      "Répartition des sens: Counter({'1': 20, '2': 19})\n",
      "Le sens le plus fréquent pour 'détenir' est le sens 1 avec une proportion de 51.28 %\n",
      "\n",
      "Accuracy : 0.68\n",
      "\n",
      "--> Instance : lire\n",
      "Proportion de données annotées considérées sur le corpus: 75.0 %\n",
      "Répartition des sens: Counter({'1': 26, '6': 4, '7': 4, '3': 2, '2': 2})\n",
      "Le sens le plus fréquent pour 'lire' est le sens 1 avec une proportion de 68.42 %\n",
      "\n",
      "Accuracy : 0.6\n",
      "\n",
      "--> Instance : contenir\n",
      "Proportion de données annotées considérées sur le corpus: 75.0 %\n",
      "Répartition des sens: Counter({'3': 17, '2': 13, '5': 5, '4': 1, '1': 1})\n",
      "Le sens le plus fréquent pour 'contenir' est le sens 3 avec une proportion de 45.95 %\n",
      "\n",
      "Accuracy : 0.35\n",
      "\n",
      "--> Instance : dominer\n",
      "Proportion de données annotées considérées sur le corpus: 75.0 %\n",
      "Répartition des sens: Counter({'6': 31, '4': 5, '3': 2, '5': 1})\n",
      "Le sens le plus fréquent pour 'dominer' est le sens 6 avec une proportion de 79.49 %\n",
      "\n",
      "Accuracy : 0.7\n",
      "\n",
      "--> Instance : noter\n",
      "Proportion de données annotées considérées sur le corpus: 75.0 %\n",
      "Répartition des sens: Counter({'3': 12, '2': 1, '5': 1})\n",
      "Le sens le plus fréquent pour 'noter' est le sens 3 avec une proportion de 85.71 %\n",
      "\n",
      "Accuracy : 1.0\n",
      "\n",
      "--> Instance : dater\n",
      "Proportion de données annotées considérées sur le corpus: 75.0 %\n",
      "Répartition des sens: Counter({'1': 30, '2': 7})\n",
      "Le sens le plus fréquent pour 'dater' est le sens 1 avec une proportion de 81.08 %\n",
      "\n",
      "Accuracy : 0.86\n",
      "\n",
      "--> Instance : adopter\n",
      "Proportion de données annotées considérées sur le corpus: 75.0 %\n",
      "Répartition des sens: Counter({'4': 23, '5': 8, '3': 3, '1': 3, '2': 1})\n",
      "Le sens le plus fréquent pour 'adopter' est le sens 4 avec une proportion de 60.53 %\n",
      "\n",
      "Accuracy : 0.31\n",
      "\n",
      "--> Instance : enregistrer\n",
      "Proportion de données annotées considérées sur le corpus: 75.0 %\n",
      "Répartition des sens: Counter({'3': 27, '6': 4, '1': 3, '2': 1})\n",
      "Le sens le plus fréquent pour 'enregistrer' est le sens 3 avec une proportion de 77.14 %\n",
      "\n",
      "Accuracy : 0.71\n",
      "\n",
      "--> Instance : intervenir\n",
      "Proportion de données annotées considérées sur le corpus: 75.0 %\n",
      "Répartition des sens: Counter({'4': 21, '1': 15, '3': 2})\n",
      "Le sens le plus fréquent pour 'intervenir' est le sens 4 avec une proportion de 55.26 %\n",
      "\n",
      "Accuracy : 0.68\n",
      "\n",
      "--> Instance : conclure\n",
      "Proportion de données annotées considérées sur le corpus: 75.0 %\n",
      "Répartition des sens: Counter({'1b': 16, '1a': 16, '2b': 4, '3a': 1})\n",
      "Le sens le plus fréquent pour 'conclure' est le sens 1b avec une proportion de 43.24 %\n",
      "\n",
      "Accuracy : 0.72\n",
      "\n",
      "--> Instance : disputer\n",
      "Proportion de données annotées considérées sur le corpus: 75.0 %\n",
      "Répartition des sens: Counter({'5': 36, '3': 2, '2': 1})\n",
      "Le sens le plus fréquent pour 'disputer' est le sens 5 avec une proportion de 92.31 %\n",
      "\n",
      "Accuracy : 0.73\n",
      "\n",
      "--> Instance : estimer\n",
      "Proportion de données annotées considérées sur le corpus: 75.0 %\n",
      "Répartition des sens: Counter({'3': 29, '1': 10})\n",
      "Le sens le plus fréquent pour 'estimer' est le sens 3 avec une proportion de 74.36 %\n",
      "\n",
      "Accuracy : 0.78\n",
      "\n",
      "--> Instance : appartenir\n",
      "Proportion de données annotées considérées sur le corpus: 75.0 %\n",
      "Répartition des sens: Counter({'6': 19, '1': 16, '3': 2, '4': 1})\n",
      "Le sens le plus fréquent pour 'appartenir' est le sens 6 avec une proportion de 50.0 %\n",
      "\n",
      "Accuracy : 0.38\n",
      "\n",
      "--> Instance : arriver\n",
      "Proportion de données annotées considérées sur le corpus: 75.0 %\n",
      "Répartition des sens: Counter({'1': 29, '2': 7, '3': 2, '4': 2, '5': 1, '6': 1})\n",
      "Le sens le plus fréquent pour 'arriver' est le sens 1 avec une proportion de 69.05 %\n",
      "\n",
      "Accuracy : 0.38\n",
      "\n",
      "--> Instance : chercher\n",
      "Proportion de données annotées considérées sur le corpus: 75.0 %\n",
      "Répartition des sens: Counter({'4': 24, '1': 9, '6': 4, '7': 1})\n",
      "Le sens le plus fréquent pour 'chercher' est le sens 4 avec une proportion de 63.16 %\n",
      "\n",
      "Accuracy : 0.72\n",
      "\n",
      "--> Instance : composer\n",
      "Proportion de données annotées considérées sur le corpus: 75.0 %\n",
      "Répartition des sens: Counter({'1': 33, '6': 4, '9': 1, '8': 1})\n",
      "Le sens le plus fréquent pour 'composer' est le sens 1 avec une proportion de 84.62 %\n",
      "\n",
      "Accuracy : 0.95\n",
      "\n",
      "--> Instance : confier\n",
      "Proportion de données annotées considérées sur le corpus: 75.0 %\n",
      "Répartition des sens: Counter({'2': 21, '1': 17})\n",
      "Le sens le plus fréquent pour 'confier' est le sens 2 avec une proportion de 55.26 %\n",
      "\n",
      "Accuracy : 0.82\n",
      "\n",
      "Macro et micro average pour 75.0% des données annotées\n",
      "Macro-average : 0.82\n",
      "Micro-average : 0.61\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "--> Instance : aboutir\n",
      "Proportion de données annotées considérées sur le corpus: 50.0 %\n",
      "Répartition des sens: Counter({'3': 20, '4': 3, '2': 1, '1': 1})\n",
      "Le sens le plus fréquent pour 'aboutir' est le sens 3 avec une proportion de 80.0 %\n",
      "\n",
      "Accuracy : 0.8\n",
      "\n",
      "--> Instance : investir\n",
      "Proportion de données annotées considérées sur le corpus: 50.0 %\n",
      "Répartition des sens: Counter({'4': 13, '3': 8, '1': 3, '2': 1})\n",
      "Le sens le plus fréquent pour 'investir' est le sens 4 avec une proportion de 52.0 %\n",
      "\n",
      "Accuracy : 0.55\n",
      "\n",
      "--> Instance : traduire\n",
      "Proportion de données annotées considérées sur le corpus: 50.0 %\n",
      "Répartition des sens: Counter({'5': 10, '1': 10, '4': 5})\n",
      "Le sens le plus fréquent pour 'traduire' est le sens 5 avec une proportion de 40.0 %\n",
      "\n",
      "Accuracy : 0.66\n",
      "\n",
      "--> Instance : témoigner\n",
      "Proportion de données annotées considérées sur le corpus: 50.0 %\n",
      "Répartition des sens: Counter({'2': 24, '1': 1})\n",
      "Le sens le plus fréquent pour 'témoigner' est le sens 2 avec une proportion de 96.0 %\n",
      "\n",
      "Accuracy : 0.82\n",
      "\n",
      "--> Instance : juger\n",
      "Proportion de données annotées considérées sur le corpus: 50.0 %\n",
      "Répartition des sens: Counter({'7': 14, '5': 2, '1': 2, '6': 1})\n",
      "Le sens le plus fréquent pour 'juger' est le sens 7 avec une proportion de 73.68 %\n",
      "\n",
      "Accuracy : 0.56\n",
      "\n",
      "--> Instance : justifier\n",
      "Proportion de données annotées considérées sur le corpus: 50.0 %\n",
      "Répartition des sens: Counter({'2': 20, '3': 3, '4': 1, '6': 1})\n",
      "Le sens le plus fréquent pour 'justifier' est le sens 2 avec une proportion de 80.0 %\n",
      "\n",
      "Accuracy : 0.66\n",
      "\n",
      "--> Instance : viser\n",
      "Proportion de données annotées considérées sur le corpus: 50.0 %\n",
      "Répartition des sens: Counter({'4': 16, '3': 9})\n",
      "Le sens le plus fréquent pour 'viser' est le sens 4 avec une proportion de 64.0 %\n",
      "\n",
      "Accuracy : 0.82\n",
      "\n",
      "--> Instance : prononcer\n",
      "Proportion de données annotées considérées sur le corpus: 50.0 %\n",
      "Répartition des sens: Counter({'7': 8, '3': 7, '2': 7, '1': 2, '4': 1})\n",
      "Le sens le plus fréquent pour 'prononcer' est le sens 7 avec une proportion de 32.0 %\n",
      "\n",
      "Accuracy : 0.38\n",
      "\n",
      "--> Instance : accomplir\n",
      "Proportion de données annotées considérées sur le corpus: 50.0 %\n",
      "Répartition des sens: Counter({'2': 19, '1': 3, '3': 2, '4': 2})\n",
      "Le sens le plus fréquent pour 'accomplir' est le sens 2 avec une proportion de 73.08 %\n",
      "\n",
      "Accuracy : 0.5\n",
      "\n",
      "--> Instance : convenir\n",
      "Proportion de données annotées considérées sur le corpus: 50.0 %\n",
      "Répartition des sens: Counter({'1': 8, '3': 7, '6': 4, '2': 4, '5': 2})\n",
      "Le sens le plus fréquent pour 'convenir' est le sens 1 avec une proportion de 32.0 %\n",
      "\n",
      "Accuracy : 0.38\n",
      "\n",
      "--> Instance : acquérir\n",
      "Proportion de données annotées considérées sur le corpus: 50.0 %\n",
      "Répartition des sens: Counter({'1': 17, '5': 3, '2': 3, '4': 2, '6': 1})\n",
      "Le sens le plus fréquent pour 'acquérir' est le sens 1 avec une proportion de 65.38 %\n",
      "\n",
      "Accuracy : 0.5\n",
      "\n",
      "--> Instance : achever\n",
      "Proportion de données annotées considérées sur le corpus: 50.0 %\n",
      "Répartition des sens: Counter({'1': 13, '5': 11, '3': 1})\n",
      "Le sens le plus fréquent pour 'achever' est le sens 1 avec une proportion de 52.0 %\n",
      "\n",
      "Accuracy : 0.7\n",
      "\n",
      "--> Instance : observer\n",
      "Proportion de données annotées considérées sur le corpus: 50.0 %\n",
      "Répartition des sens: Counter({'4': 15, '1': 6, '2': 2, '3': 2})\n",
      "Le sens le plus fréquent pour 'observer' est le sens 4 avec une proportion de 60.0 %\n",
      "\n",
      "Accuracy : 0.62\n",
      "\n",
      "--> Instance : adapter\n",
      "Proportion de données annotées considérées sur le corpus: 50.0 %\n",
      "Répartition des sens: Counter({'3': 9, '7': 7, '5': 4, '4': 3, '2': 2})\n",
      "Le sens le plus fréquent pour 'adapter' est le sens 3 avec une proportion de 36.0 %\n",
      "\n",
      "Accuracy : 0.46\n",
      "\n",
      "--> Instance : admettre\n",
      "Proportion de données annotées considérées sur le corpus: 50.0 %\n",
      "Répartition des sens: Counter({'2': 14, '3': 7, '1': 2, '4': 1})\n",
      "Le sens le plus fréquent pour 'admettre' est le sens 2 avec une proportion de 58.33 %\n",
      "\n",
      "Accuracy : 0.62\n",
      "\n",
      "--> Instance : entraîner\n",
      "Proportion de données annotées considérées sur le corpus: 50.0 %\n",
      "Répartition des sens: Counter({'4': 18, '5': 5, '3': 1, '2': 1})\n",
      "Le sens le plus fréquent pour 'entraîner' est le sens 4 avec une proportion de 72.0 %\n",
      "\n",
      "Accuracy : 0.5\n",
      "\n",
      "--> Instance : payer\n",
      "Proportion de données annotées considérées sur le corpus: 50.0 %\n",
      "Répartition des sens: Counter({'1': 13, '2': 6, '3': 3, '10': 2, '7': 1, '11': 1})\n",
      "Le sens le plus fréquent pour 'payer' est le sens 1 avec une proportion de 50.0 %\n",
      "\n",
      "Accuracy : 0.39\n",
      "\n",
      "--> Instance : respecter\n",
      "Proportion de données annotées considérées sur le corpus: 50.0 %\n",
      "Répartition des sens: Counter({'2': 20, '1': 5})\n",
      "Le sens le plus fréquent pour 'respecter' est le sens 2 avec une proportion de 80.0 %\n",
      "\n",
      "Accuracy : 0.68\n",
      "\n",
      "--> Instance : affecter\n",
      "Proportion de données annotées considérées sur le corpus: 50.0 %\n",
      "Répartition des sens: Counter({'8': 14, '1': 5, '5': 1, '6': 1, '10': 1, '3': 1, '4': 1, '7': 1})\n",
      "Le sens le plus fréquent pour 'affecter' est le sens 8 avec une proportion de 56.0 %\n",
      "\n",
      "Accuracy : 0.58\n",
      "\n",
      "--> Instance : demeurer\n",
      "Proportion de données annotées considérées sur le corpus: 50.0 %\n",
      "Répartition des sens: Counter({'4': 17, '3': 3, '2': 2, '6': 1})\n",
      "Le sens le plus fréquent pour 'demeurer' est le sens 4 avec une proportion de 73.91 %\n",
      "\n",
      "Accuracy : 0.7\n",
      "\n",
      "--> Instance : aggraver\n",
      "Proportion de données annotées considérées sur le corpus: 50.0 %\n",
      "Répartition des sens: Counter({'1': 20, '2': 5})\n",
      "Le sens le plus fréquent pour 'aggraver' est le sens 1 avec une proportion de 80.0 %\n",
      "\n",
      "Accuracy : 0.73\n",
      "\n",
      "--> Instance : agir\n",
      "Proportion de données annotées considérées sur le corpus: 50.0 %\n",
      "Répartition des sens: Counter({'7': 12, '3': 6, '1': 4, '6': 2, '2': 1})\n",
      "Le sens le plus fréquent pour 'agir' est le sens 7 avec une proportion de 48.0 %\n",
      "\n",
      "Accuracy : 0.62\n",
      "\n",
      "--> Instance : ajouter\n",
      "Proportion de données annotées considérées sur le corpus: 50.0 %\n",
      "Répartition des sens: Counter({'2': 13, '1': 7, '5': 3, '3': 2})\n",
      "Le sens le plus fréquent pour 'ajouter' est le sens 2 avec une proportion de 52.0 %\n",
      "\n",
      "Accuracy : 0.53\n",
      "\n",
      "--> Instance : alimenter\n",
      "Proportion de données annotées considérées sur le corpus: 50.0 %\n",
      "Répartition des sens: Counter({'2': 17, '3': 7, '1': 1})\n",
      "Le sens le plus fréquent pour 'alimenter' est le sens 2 avec une proportion de 68.0 %\n",
      "\n",
      "Accuracy : 0.57\n",
      "\n",
      "--> Instance : coûter\n",
      "Proportion de données annotées considérées sur le corpus: 50.0 %\n",
      "Répartition des sens: Counter({'1': 9, '2': 8, '3': 6, '4': 1})\n",
      "Le sens le plus fréquent pour 'coûter' est le sens 1 avec une proportion de 37.5 %\n",
      "\n",
      "Accuracy : 0.59\n",
      "\n",
      "--> Instance : relancer\n",
      "Proportion de données annotées considérées sur le corpus: 50.0 %\n",
      "Répartition des sens: Counter({'1': 17, '6': 7, '2': 1})\n",
      "Le sens le plus fréquent pour 'relancer' est le sens 1 avec une proportion de 68.0 %\n",
      "\n",
      "Accuracy : 0.57\n",
      "\n",
      "--> Instance : préférer\n",
      "Proportion de données annotées considérées sur le corpus: 50.0 %\n",
      "Répartition des sens: Counter({'1': 16, '3': 8, '2': 1})\n",
      "Le sens le plus fréquent pour 'préférer' est le sens 1 avec une proportion de 64.0 %\n",
      "\n",
      "Accuracy : 0.54\n",
      "\n",
      "--> Instance : appliquer\n",
      "Proportion de données annotées considérées sur le corpus: 50.0 %\n",
      "Répartition des sens: Counter({'3': 15, '2': 6, '8': 4})\n",
      "Le sens le plus fréquent pour 'appliquer' est le sens 3 avec une proportion de 60.0 %\n",
      "\n",
      "Accuracy : 0.38\n",
      "\n",
      "--> Instance : apporter\n",
      "Proportion de données annotées considérées sur le corpus: 50.0 %\n",
      "Répartition des sens: Counter({'1': 11, '2': 6, '3': 3, '4': 3, '5': 2})\n",
      "Le sens le plus fréquent pour 'apporter' est le sens 1 avec une proportion de 44.0 %\n",
      "\n",
      "Accuracy : 0.27\n",
      "\n",
      "--> Instance : fonder\n",
      "Proportion de données annotées considérées sur le corpus: 50.0 %\n",
      "Répartition des sens: Counter({'4': 12, '6': 8, '5': 3, '3': 1, '7': 1, '1': 1})\n",
      "Le sens le plus fréquent pour 'fonder' est le sens 4 avec une proportion de 46.15 %\n",
      "\n",
      "Accuracy : 0.48\n",
      "\n",
      "--> Instance : appuyer\n",
      "Proportion de données annotées considérées sur le corpus: 50.0 %\n",
      "Répartition des sens: Counter({'2': 16, '10': 7, '5': 1, '6': 1})\n",
      "Le sens le plus fréquent pour 'appuyer' est le sens 2 avec une proportion de 64.0 %\n",
      "\n",
      "Accuracy : 0.57\n",
      "\n",
      "--> Instance : changer\n",
      "Proportion de données annotées considérées sur le corpus: 50.0 %\n",
      "Répartition des sens: Counter({'1': 10, '4': 6, '5': 5, '9': 2, '6': 1})\n",
      "Le sens le plus fréquent pour 'changer' est le sens 1 avec une proportion de 41.67 %\n",
      "\n",
      "Accuracy : 0.26\n",
      "\n",
      "--> Instance : chuter\n",
      "Proportion de données annotées considérées sur le corpus: 50.0 %\n",
      "Répartition des sens: Counter({'4': 11, '1': 7})\n",
      "Le sens le plus fréquent pour 'chuter' est le sens 4 avec une proportion de 61.11 %\n",
      "\n",
      "Accuracy : 0.75\n",
      "\n",
      "--> Instance : soutenir\n",
      "Proportion de données annotées considérées sur le corpus: 50.0 %\n",
      "Répartition des sens: Counter({'2': 14, '1': 4, '4': 3, '3': 2, '5': 1, '6': 1})\n",
      "Le sens le plus fréquent pour 'soutenir' est le sens 2 avec une proportion de 56.0 %\n",
      "\n",
      "Accuracy : 0.46\n",
      "\n",
      "--> Instance : concevoir\n",
      "Proportion de données annotées considérées sur le corpus: 50.0 %\n",
      "Répartition des sens: Counter({'2': 23, '4': 1, '1': 1})\n",
      "Le sens le plus fréquent pour 'concevoir' est le sens 2 avec une proportion de 92.0 %\n",
      "\n",
      "Accuracy : 0.67\n",
      "\n",
      "--> Instance : interroger\n",
      "Proportion de données annotées considérées sur le corpus: 50.0 %\n",
      "Répartition des sens: Counter({'1': 16, '3': 8, '2': 1})\n",
      "Le sens le plus fréquent pour 'interroger' est le sens 1 avec une proportion de 64.0 %\n",
      "\n",
      "Accuracy : 0.62\n",
      "\n",
      "--> Instance : confirmer\n",
      "Proportion de données annotées considérées sur le corpus: 50.0 %\n",
      "Répartition des sens: Counter({'2': 10, '5': 9, '4': 3, '3': 3})\n",
      "Le sens le plus fréquent pour 'confirmer' est le sens 2 avec une proportion de 40.0 %\n",
      "\n",
      "Accuracy : 0.4\n",
      "\n",
      "--> Instance : transformer\n",
      "Proportion de données annotées considérées sur le corpus: 50.0 %\n",
      "Répartition des sens: Counter({'1': 8})\n",
      "Le sens le plus fréquent pour 'transformer' est le sens 1 avec une proportion de 100.0 %\n",
      "\n",
      "Accuracy : 1.0\n",
      "\n",
      "--> Instance : manifester\n",
      "Proportion de données annotées considérées sur le corpus: 50.0 %\n",
      "Répartition des sens: Counter({'1': 15, '4': 7, '3': 3})\n",
      "Le sens le plus fréquent pour 'manifester' est le sens 1 avec une proportion de 60.0 %\n",
      "\n",
      "Accuracy : 0.55\n",
      "\n",
      "--> Instance : interpeller\n",
      "Proportion de données annotées considérées sur le corpus: 50.0 %\n",
      "Répartition des sens: Counter({'5': 23, '1': 2})\n",
      "Le sens le plus fréquent pour 'interpeller' est le sens 5 avec une proportion de 92.0 %\n",
      "\n",
      "Accuracy : 0.79\n",
      "\n",
      "--> Instance : signer\n",
      "Proportion de données annotées considérées sur le corpus: 50.0 %\n",
      "Répartition des sens: Counter({'1': 19, '2': 3, '5': 1, '4': 1, '7': 1})\n",
      "Le sens le plus fréquent pour 'signer' est le sens 1 avec une proportion de 76.0 %\n",
      "\n",
      "Accuracy : 0.8\n",
      "\n",
      "--> Instance : rester\n",
      "Proportion de données annotées considérées sur le corpus: 50.0 %\n",
      "Répartition des sens: Counter({'1': 11, '3': 6, '6': 3, '7': 2, '5': 1, '4': 1, '2': 1})\n",
      "Le sens le plus fréquent pour 'rester' est le sens 1 avec une proportion de 44.0 %\n",
      "\n",
      "Accuracy : 0.49\n",
      "\n",
      "--> Instance : tuer\n",
      "Proportion de données annotées considérées sur le corpus: 50.0 %\n",
      "Répartition des sens: Counter({'1': 18, '2': 7})\n",
      "Le sens le plus fréquent pour 'tuer' est le sens 1 avec une proportion de 72.0 %\n",
      "\n",
      "Accuracy : 0.51\n",
      "\n",
      "--> Instance : indiquer\n",
      "Proportion de données annotées considérées sur le corpus: 50.0 %\n",
      "Répartition des sens: Counter({'2': 22, '1': 2, '4': 1})\n",
      "Le sens le plus fréquent pour 'indiquer' est le sens 2 avec une proportion de 88.0 %\n",
      "\n",
      "Accuracy : 0.7\n",
      "\n",
      "--> Instance : conduire\n",
      "Proportion de données annotées considérées sur le corpus: 50.0 %\n",
      "Répartition des sens: Counter({'2': 9, '1': 5, '10': 3, '8': 3, '7': 3, '9': 2})\n",
      "Le sens le plus fréquent pour 'conduire' est le sens 2 avec une proportion de 36.0 %\n",
      "\n",
      "Accuracy : 0.35\n",
      "\n",
      "--> Instance : situer\n",
      "Proportion de données annotées considérées sur le corpus: 50.0 %\n",
      "Répartition des sens: Counter({'1': 23, '2': 2})\n",
      "Le sens le plus fréquent pour 'situer' est le sens 1 avec une proportion de 92.0 %\n",
      "\n",
      "Accuracy : 0.83\n",
      "\n",
      "--> Instance : aider\n",
      "Proportion de données annotées considérées sur le corpus: 50.0 %\n",
      "Répartition des sens: Counter({'1': 8, '3': 6, '2': 6, '6': 4, '4': 1})\n",
      "Le sens le plus fréquent pour 'aider' est le sens 1 avec une proportion de 32.0 %\n",
      "\n",
      "Accuracy : 0.32\n",
      "\n",
      "--> Instance : poursuivre\n",
      "Proportion de données annotées considérées sur le corpus: 50.0 %\n",
      "Répartition des sens: Counter({'4': 12, '6': 6, '5': 4, '3': 2, '1': 1})\n",
      "Le sens le plus fréquent pour 'poursuivre' est le sens 4 avec une proportion de 48.0 %\n",
      "\n",
      "Accuracy : 0.6\n",
      "\n",
      "--> Instance : profiter\n",
      "Proportion de données annotées considérées sur le corpus: 50.0 %\n",
      "Répartition des sens: Counter({'2': 21, '7': 3, '4': 1})\n",
      "Le sens le plus fréquent pour 'profiter' est le sens 2 avec une proportion de 84.0 %\n",
      "\n",
      "Accuracy : 0.82\n",
      "\n",
      "--> Instance : détenir\n",
      "Proportion de données annotées considérées sur le corpus: 50.0 %\n",
      "Répartition des sens: Counter({'2': 14, '1': 12})\n",
      "Le sens le plus fréquent pour 'détenir' est le sens 2 avec une proportion de 53.85 %\n",
      "\n",
      "Accuracy : 0.64\n",
      "\n",
      "--> Instance : lire\n",
      "Proportion de données annotées considérées sur le corpus: 50.0 %\n",
      "Répartition des sens: Counter({'1': 15, '6': 3, '3': 3, '7': 3, '2': 1})\n",
      "Le sens le plus fréquent pour 'lire' est le sens 1 avec une proportion de 60.0 %\n",
      "\n",
      "Accuracy : 0.58\n",
      "\n",
      "--> Instance : contenir\n",
      "Proportion de données annotées considérées sur le corpus: 50.0 %\n",
      "Répartition des sens: Counter({'2': 10, '3': 8, '5': 4, '1': 2, '4': 1})\n",
      "Le sens le plus fréquent pour 'contenir' est le sens 2 avec une proportion de 40.0 %\n",
      "\n",
      "Accuracy : 0.4\n",
      "\n",
      "--> Instance : dominer\n",
      "Proportion de données annotées considérées sur le corpus: 50.0 %\n",
      "Répartition des sens: Counter({'6': 17, '4': 4, '3': 3, '5': 2})\n",
      "Le sens le plus fréquent pour 'dominer' est le sens 6 avec une proportion de 65.38 %\n",
      "\n",
      "Accuracy : 0.73\n",
      "\n",
      "--> Instance : noter\n",
      "Proportion de données annotées considérées sur le corpus: 50.0 %\n",
      "Répartition des sens: Counter({'3': 7, '2': 1, '5': 1})\n",
      "Le sens le plus fréquent pour 'noter' est le sens 3 avec une proportion de 77.78 %\n",
      "\n",
      "Accuracy : 0.73\n",
      "\n",
      "--> Instance : dater\n",
      "Proportion de données annotées considérées sur le corpus: 50.0 %\n",
      "Répartition des sens: Counter({'1': 22, '2': 3})\n",
      "Le sens le plus fréquent pour 'dater' est le sens 1 avec une proportion de 88.0 %\n",
      "\n",
      "Accuracy : 0.88\n",
      "\n",
      "--> Instance : adopter\n",
      "Proportion de données annotées considérées sur le corpus: 50.0 %\n",
      "Répartition des sens: Counter({'4': 17, '5': 3, '3': 2, '1': 2, '2': 1})\n",
      "Le sens le plus fréquent pour 'adopter' est le sens 4 avec une proportion de 68.0 %\n",
      "\n",
      "Accuracy : 0.41\n",
      "\n",
      "--> Instance : enregistrer\n",
      "Proportion de données annotées considérées sur le corpus: 50.0 %\n",
      "Répartition des sens: Counter({'3': 15, '6': 3, '1': 3, '2': 2})\n",
      "Le sens le plus fréquent pour 'enregistrer' est le sens 3 avec une proportion de 65.22 %\n",
      "\n",
      "Accuracy : 0.67\n",
      "\n",
      "--> Instance : intervenir\n",
      "Proportion de données annotées considérées sur le corpus: 50.0 %\n",
      "Répartition des sens: Counter({'4': 14, '1': 10, '3': 1})\n",
      "Le sens le plus fréquent pour 'intervenir' est le sens 4 avec une proportion de 56.0 %\n",
      "\n",
      "Accuracy : 0.63\n",
      "\n",
      "--> Instance : conclure\n",
      "Proportion de données annotées considérées sur le corpus: 50.0 %\n",
      "Répartition des sens: Counter({'1a': 13, '1b': 9, '2b': 2, '3a': 1})\n",
      "Le sens le plus fréquent pour 'conclure' est le sens 1a avec une proportion de 52.0 %\n",
      "\n",
      "Accuracy : 0.62\n",
      "\n",
      "--> Instance : disputer\n",
      "Proportion de données annotées considérées sur le corpus: 50.0 %\n",
      "Répartition des sens: Counter({'5': 24, '3': 1, '2': 1})\n",
      "Le sens le plus fréquent pour 'disputer' est le sens 5 avec une proportion de 92.31 %\n",
      "\n",
      "Accuracy : 0.77\n",
      "\n",
      "--> Instance : estimer\n",
      "Proportion de données annotées considérées sur le corpus: 50.0 %\n",
      "Répartition des sens: Counter({'3': 20, '1': 6})\n",
      "Le sens le plus fréquent pour 'estimer' est le sens 3 avec une proportion de 76.92 %\n",
      "\n",
      "Accuracy : 0.73\n",
      "\n",
      "--> Instance : appartenir\n",
      "Proportion de données annotées considérées sur le corpus: 50.0 %\n",
      "Répartition des sens: Counter({'6': 13, '1': 9, '3': 2, '4': 1})\n",
      "Le sens le plus fréquent pour 'appartenir' est le sens 6 avec une proportion de 52.0 %\n",
      "\n",
      "Accuracy : 0.34\n",
      "\n",
      "--> Instance : arriver\n",
      "Proportion de données annotées considérées sur le corpus: 50.0 %\n",
      "Répartition des sens: Counter({'1': 14, '2': 6, '4': 4, '3': 2, '5': 1, '6': 1})\n",
      "Le sens le plus fréquent pour 'arriver' est le sens 1 avec une proportion de 50.0 %\n",
      "\n",
      "Accuracy : 0.4\n",
      "\n",
      "--> Instance : chercher\n",
      "Proportion de données annotées considérées sur le corpus: 50.0 %\n",
      "Répartition des sens: Counter({'4': 15, '1': 6, '6': 3, '7': 1})\n",
      "Le sens le plus fréquent pour 'chercher' est le sens 4 avec une proportion de 60.0 %\n",
      "\n",
      "Accuracy : 0.62\n",
      "\n",
      "--> Instance : composer\n",
      "Proportion de données annotées considérées sur le corpus: 50.0 %\n",
      "Répartition des sens: Counter({'1': 23, '9': 1, '6': 1, '8': 1})\n",
      "Le sens le plus fréquent pour 'composer' est le sens 1 avec une proportion de 88.46 %\n",
      "\n",
      "Accuracy : 0.94\n",
      "\n",
      "--> Instance : confier\n",
      "Proportion de données annotées considérées sur le corpus: 50.0 %\n",
      "Répartition des sens: Counter({'1': 14, '2': 11})\n",
      "Le sens le plus fréquent pour 'confier' est le sens 1 avec une proportion de 56.0 %\n",
      "\n",
      "Accuracy : 0.8\n",
      "\n",
      "Macro et micro average pour 50.0% des données annotées\n",
      "Macro-average : 0.8\n",
      "Micro-average : 0.6\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "--> Instance : aboutir\n",
      "Proportion de données annotées considérées sur le corpus: 25.0 %\n",
      "Répartition des sens: Counter({'3': 8, '4': 3, '2': 1, '1': 1})\n",
      "Le sens le plus fréquent pour 'aboutir' est le sens 3 avec une proportion de 61.54 %\n",
      "\n",
      "Accuracy : 0.77\n",
      "\n",
      "--> Instance : investir\n",
      "Proportion de données annotées considérées sur le corpus: 25.0 %\n",
      "Répartition des sens: Counter({'4': 8, '3': 3, '2': 1, '1': 1})\n",
      "Le sens le plus fréquent pour 'investir' est le sens 4 avec une proportion de 61.54 %\n",
      "\n",
      "Accuracy : 0.53\n",
      "\n",
      "--> Instance : traduire\n",
      "Proportion de données annotées considérées sur le corpus: 25.0 %\n",
      "Répartition des sens: Counter({'5': 5, '1': 5, '4': 3})\n",
      "Le sens le plus fréquent pour 'traduire' est le sens 5 avec une proportion de 38.46 %\n",
      "\n",
      "Accuracy : 0.65\n",
      "\n",
      "--> Instance : témoigner\n",
      "Proportion de données annotées considérées sur le corpus: 25.0 %\n",
      "Répartition des sens: Counter({'2': 12, '1': 1})\n",
      "Le sens le plus fréquent pour 'témoigner' est le sens 2 avec une proportion de 92.31 %\n",
      "\n",
      "Accuracy : 0.84\n",
      "\n",
      "--> Instance : juger\n",
      "Proportion de données annotées considérées sur le corpus: 25.0 %\n",
      "Répartition des sens: Counter({'7': 6, '1': 2, '5': 1, '6': 1})\n",
      "Le sens le plus fréquent pour 'juger' est le sens 7 avec une proportion de 60.0 %\n",
      "\n",
      "Accuracy : 0.48\n",
      "\n",
      "--> Instance : justifier\n",
      "Proportion de données annotées considérées sur le corpus: 25.0 %\n",
      "Répartition des sens: Counter({'2': 8, '3': 3, '4': 1, '6': 1})\n",
      "Le sens le plus fréquent pour 'justifier' est le sens 2 avec une proportion de 61.54 %\n",
      "\n",
      "Accuracy : 0.62\n",
      "\n",
      "--> Instance : viser\n",
      "Proportion de données annotées considérées sur le corpus: 25.0 %\n",
      "Répartition des sens: Counter({'3': 7, '4': 6})\n",
      "Le sens le plus fréquent pour 'viser' est le sens 3 avec une proportion de 53.85 %\n",
      "\n",
      "Accuracy : 0.92\n",
      "\n",
      "--> Instance : prononcer\n",
      "Proportion de données annotées considérées sur le corpus: 25.0 %\n",
      "Répartition des sens: Counter({'2': 4, '3': 3, '7': 3, '1': 2, '4': 1})\n",
      "Le sens le plus fréquent pour 'prononcer' est le sens 2 avec une proportion de 30.77 %\n",
      "\n",
      "Accuracy : 0.36\n",
      "\n",
      "--> Instance : accomplir\n",
      "Proportion de données annotées considérées sur le corpus: 25.0 %\n",
      "Répartition des sens: Counter({'2': 7, '3': 2, '4': 2, '1': 2})\n",
      "Le sens le plus fréquent pour 'accomplir' est le sens 2 avec une proportion de 53.85 %\n",
      "\n",
      "Accuracy : 0.58\n",
      "\n",
      "--> Instance : convenir\n",
      "Proportion de données annotées considérées sur le corpus: 25.0 %\n",
      "Répartition des sens: Counter({'1': 5, '3': 4, '5': 2, '6': 1, '2': 1})\n",
      "Le sens le plus fréquent pour 'convenir' est le sens 1 avec une proportion de 38.46 %\n",
      "\n",
      "Accuracy : 0.38\n",
      "\n",
      "--> Instance : acquérir\n",
      "Proportion de données annotées considérées sur le corpus: 25.0 %\n",
      "Répartition des sens: Counter({'1': 8, '4': 2, '5': 1, '6': 1, '2': 1})\n",
      "Le sens le plus fréquent pour 'acquérir' est le sens 1 avec une proportion de 61.54 %\n",
      "\n",
      "Accuracy : 0.62\n",
      "\n",
      "--> Instance : achever\n",
      "Proportion de données annotées considérées sur le corpus: 25.0 %\n",
      "Répartition des sens: Counter({'1': 9, '5': 3, '3': 1})\n",
      "Le sens le plus fréquent pour 'achever' est le sens 1 avec une proportion de 69.23 %\n",
      "\n",
      "Accuracy : 0.63\n",
      "\n",
      "--> Instance : observer\n",
      "Proportion de données annotées considérées sur le corpus: 25.0 %\n",
      "Répartition des sens: Counter({'4': 10, '2': 1, '3': 1, '1': 1})\n",
      "Le sens le plus fréquent pour 'observer' est le sens 4 avec une proportion de 76.92 %\n",
      "\n",
      "Accuracy : 0.56\n",
      "\n",
      "--> Instance : adapter\n",
      "Proportion de données annotées considérées sur le corpus: 25.0 %\n",
      "Répartition des sens: Counter({'3': 5, '5': 3, '7': 3, '4': 1, '2': 1})\n",
      "Le sens le plus fréquent pour 'adapter' est le sens 3 avec une proportion de 38.46 %\n",
      "\n",
      "Accuracy : 0.4\n",
      "\n",
      "--> Instance : admettre\n",
      "Proportion de données annotées considérées sur le corpus: 25.0 %\n",
      "Répartition des sens: Counter({'2': 5, '3': 5, '4': 1, '1': 1})\n",
      "Le sens le plus fréquent pour 'admettre' est le sens 2 avec une proportion de 41.67 %\n",
      "\n",
      "Accuracy : 0.57\n",
      "\n",
      "--> Instance : entraîner\n",
      "Proportion de données annotées considérées sur le corpus: 25.0 %\n",
      "Répartition des sens: Counter({'4': 8, '5': 3, '3': 1, '2': 1})\n",
      "Le sens le plus fréquent pour 'entraîner' est le sens 4 avec une proportion de 61.54 %\n",
      "\n",
      "Accuracy : 0.5\n",
      "\n",
      "--> Instance : payer\n",
      "Proportion de données annotées considérées sur le corpus: 25.0 %\n",
      "Répartition des sens: Counter({'1': 5, '2': 3, '3': 2, '10': 1, '7': 1, '11': 1})\n",
      "Le sens le plus fréquent pour 'payer' est le sens 1 avec une proportion de 38.46 %\n",
      "\n",
      "Accuracy : 0.39\n",
      "\n",
      "--> Instance : respecter\n",
      "Proportion de données annotées considérées sur le corpus: 25.0 %\n",
      "Répartition des sens: Counter({'2': 9, '1': 4})\n",
      "Le sens le plus fréquent pour 'respecter' est le sens 2 avec une proportion de 69.23 %\n",
      "\n",
      "Accuracy : 0.76\n",
      "\n",
      "--> Instance : affecter\n",
      "Proportion de données annotées considérées sur le corpus: 25.0 %\n",
      "Répartition des sens: Counter({'8': 5, '1': 2, '5': 1, '6': 1, '10': 1, '3': 1, '4': 1, '7': 1})\n",
      "Le sens le plus fréquent pour 'affecter' est le sens 8 avec une proportion de 38.46 %\n",
      "\n",
      "Accuracy : 0.33\n",
      "\n",
      "--> Instance : demeurer\n",
      "Proportion de données annotées considérées sur le corpus: 25.0 %\n",
      "Répartition des sens: Counter({'4': 8, '3': 2, '2': 1, '6': 1})\n",
      "Le sens le plus fréquent pour 'demeurer' est le sens 4 avec une proportion de 66.67 %\n",
      "\n",
      "Accuracy : 0.7\n",
      "\n",
      "--> Instance : aggraver\n",
      "Proportion de données annotées considérées sur le corpus: 25.0 %\n",
      "Répartition des sens: Counter({'1': 10, '2': 3})\n",
      "Le sens le plus fréquent pour 'aggraver' est le sens 1 avec une proportion de 76.92 %\n",
      "\n",
      "Accuracy : 0.7\n",
      "\n",
      "--> Instance : agir\n",
      "Proportion de données annotées considérées sur le corpus: 25.0 %\n",
      "Répartition des sens: Counter({'3': 4, '7': 4, '1': 3, '6': 1, '2': 1})\n",
      "Le sens le plus fréquent pour 'agir' est le sens 3 avec une proportion de 30.77 %\n",
      "\n",
      "Accuracy : 0.54\n",
      "\n",
      "--> Instance : ajouter\n",
      "Proportion de données annotées considérées sur le corpus: 25.0 %\n",
      "Répartition des sens: Counter({'2': 6, '1': 3, '5': 2, '3': 2})\n",
      "Le sens le plus fréquent pour 'ajouter' est le sens 2 avec une proportion de 46.15 %\n",
      "\n",
      "Accuracy : 0.44\n",
      "\n",
      "--> Instance : alimenter\n",
      "Proportion de données annotées considérées sur le corpus: 25.0 %\n",
      "Répartition des sens: Counter({'2': 7, '3': 5, '1': 1})\n",
      "Le sens le plus fréquent pour 'alimenter' est le sens 2 avec une proportion de 53.85 %\n",
      "\n",
      "Accuracy : 0.5\n",
      "\n",
      "--> Instance : coûter\n",
      "Proportion de données annotées considérées sur le corpus: 25.0 %\n",
      "Répartition des sens: Counter({'2': 4, '3': 4, '4': 2, '1': 2})\n",
      "Le sens le plus fréquent pour 'coûter' est le sens 2 avec une proportion de 33.33 %\n",
      "\n",
      "Accuracy : 0.55\n",
      "\n",
      "--> Instance : relancer\n",
      "Proportion de données annotées considérées sur le corpus: 25.0 %\n",
      "Répartition des sens: Counter({'1': 7, '6': 5, '2': 1})\n",
      "Le sens le plus fréquent pour 'relancer' est le sens 1 avec une proportion de 53.85 %\n",
      "\n",
      "Accuracy : 0.55\n",
      "\n",
      "--> Instance : préférer\n",
      "Proportion de données annotées considérées sur le corpus: 25.0 %\n",
      "Répartition des sens: Counter({'1': 8, '3': 4, '2': 1})\n",
      "Le sens le plus fréquent pour 'préférer' est le sens 1 avec une proportion de 61.54 %\n",
      "\n",
      "Accuracy : 0.51\n",
      "\n",
      "--> Instance : appliquer\n",
      "Proportion de données annotées considérées sur le corpus: 25.0 %\n",
      "Répartition des sens: Counter({'2': 7, '3': 4, '8': 2})\n",
      "Le sens le plus fréquent pour 'appliquer' est le sens 2 avec une proportion de 53.85 %\n",
      "\n",
      "Accuracy : 0.42\n",
      "\n",
      "--> Instance : apporter\n",
      "Proportion de données annotées considérées sur le corpus: 25.0 %\n",
      "Répartition des sens: Counter({'4': 4, '1': 4, '3': 2, '2': 2, '5': 1})\n",
      "Le sens le plus fréquent pour 'apporter' est le sens 4 avec une proportion de 30.77 %\n",
      "\n",
      "Accuracy : 0.31\n",
      "\n",
      "--> Instance : fonder\n",
      "Proportion de données annotées considérées sur le corpus: 25.0 %\n",
      "Répartition des sens: Counter({'4': 7, '6': 2, '5': 1, '3': 1, '7': 1, '1': 1})\n",
      "Le sens le plus fréquent pour 'fonder' est le sens 4 avec une proportion de 53.85 %\n",
      "\n",
      "Accuracy : 0.48\n",
      "\n",
      "--> Instance : appuyer\n",
      "Proportion de données annotées considérées sur le corpus: 25.0 %\n",
      "Répartition des sens: Counter({'10': 6, '2': 5, '5': 1, '6': 1})\n",
      "Le sens le plus fréquent pour 'appuyer' est le sens 10 avec une proportion de 46.15 %\n",
      "\n",
      "Accuracy : 0.54\n",
      "\n",
      "--> Instance : changer\n",
      "Proportion de données annotées considérées sur le corpus: 25.0 %\n",
      "Répartition des sens: Counter({'1': 6, '5': 2, '9': 2, '6': 1, '4': 1})\n",
      "Le sens le plus fréquent pour 'changer' est le sens 1 avec une proportion de 50.0 %\n",
      "\n",
      "Accuracy : 0.25\n",
      "\n",
      "--> Instance : chuter\n",
      "Proportion de données annotées considérées sur le corpus: 25.0 %\n",
      "Répartition des sens: Counter({'4': 7, '1': 2})\n",
      "Le sens le plus fréquent pour 'chuter' est le sens 4 avec une proportion de 77.78 %\n",
      "\n",
      "Accuracy : 0.75\n",
      "\n",
      "--> Instance : soutenir\n",
      "Proportion de données annotées considérées sur le corpus: 25.0 %\n",
      "Répartition des sens: Counter({'2': 5, '1': 3, '3': 2, '5': 1, '6': 1, '4': 1})\n",
      "Le sens le plus fréquent pour 'soutenir' est le sens 2 avec une proportion de 38.46 %\n",
      "\n",
      "Accuracy : 0.38\n",
      "\n",
      "--> Instance : concevoir\n",
      "Proportion de données annotées considérées sur le corpus: 25.0 %\n",
      "Répartition des sens: Counter({'2': 10, '4': 2, '1': 1})\n",
      "Le sens le plus fréquent pour 'concevoir' est le sens 2 avec une proportion de 76.92 %\n",
      "\n",
      "Accuracy : 0.78\n",
      "\n",
      "--> Instance : interroger\n",
      "Proportion de données annotées considérées sur le corpus: 25.0 %\n",
      "Répartition des sens: Counter({'1': 9, '3': 3, '2': 1})\n",
      "Le sens le plus fréquent pour 'interroger' est le sens 1 avec une proportion de 69.23 %\n",
      "\n",
      "Accuracy : 0.56\n",
      "\n",
      "--> Instance : confirmer\n",
      "Proportion de données annotées considérées sur le corpus: 25.0 %\n",
      "Répartition des sens: Counter({'5': 6, '2': 4, '4': 2, '3': 1})\n",
      "Le sens le plus fréquent pour 'confirmer' est le sens 5 avec une proportion de 46.15 %\n",
      "\n",
      "Accuracy : 0.4\n",
      "\n",
      "--> Instance : transformer\n",
      "Proportion de données annotées considérées sur le corpus: 25.0 %\n",
      "Répartition des sens: Counter({'1': 4})\n",
      "Le sens le plus fréquent pour 'transformer' est le sens 1 avec une proportion de 100.0 %\n",
      "\n",
      "Accuracy : 1.0\n",
      "\n",
      "--> Instance : manifester\n",
      "Proportion de données annotées considérées sur le corpus: 25.0 %\n",
      "Répartition des sens: Counter({'1': 6, '4': 4, '3': 3})\n",
      "Le sens le plus fréquent pour 'manifester' est le sens 1 avec une proportion de 46.15 %\n",
      "\n",
      "Accuracy : 0.54\n",
      "\n",
      "--> Instance : interpeller\n",
      "Proportion de données annotées considérées sur le corpus: 25.0 %\n",
      "Répartition des sens: Counter({'5': 11, '1': 2})\n",
      "Le sens le plus fréquent pour 'interpeller' est le sens 5 avec une proportion de 84.62 %\n",
      "\n",
      "Accuracy : 0.81\n",
      "\n",
      "--> Instance : signer\n",
      "Proportion de données annotées considérées sur le corpus: 25.0 %\n",
      "Répartition des sens: Counter({'1': 7, '7': 2, '2': 2, '5': 1, '4': 1})\n",
      "Le sens le plus fréquent pour 'signer' est le sens 1 avec une proportion de 53.85 %\n",
      "\n",
      "Accuracy : 0.82\n",
      "\n",
      "--> Instance : rester\n",
      "Proportion de données annotées considérées sur le corpus: 25.0 %\n",
      "Répartition des sens: Counter({'1': 6, '4': 2, '5': 1, '6': 1, '3': 1, '7': 1, '2': 1})\n",
      "Le sens le plus fréquent pour 'rester' est le sens 1 avec une proportion de 46.15 %\n",
      "\n",
      "Accuracy : 0.35\n",
      "\n",
      "--> Instance : tuer\n",
      "Proportion de données annotées considérées sur le corpus: 25.0 %\n",
      "Répartition des sens: Counter({'1': 8, '2': 5})\n",
      "Le sens le plus fréquent pour 'tuer' est le sens 1 avec une proportion de 61.54 %\n",
      "\n",
      "Accuracy : 0.63\n",
      "\n",
      "--> Instance : indiquer\n",
      "Proportion de données annotées considérées sur le corpus: 25.0 %\n",
      "Répartition des sens: Counter({'2': 10, '4': 2, '1': 1})\n",
      "Le sens le plus fréquent pour 'indiquer' est le sens 2 avec une proportion de 76.92 %\n",
      "\n",
      "Accuracy : 0.68\n",
      "\n",
      "--> Instance : conduire\n",
      "Proportion de données annotées considérées sur le corpus: 25.0 %\n",
      "Répartition des sens: Counter({'2': 5, '1': 3, '10': 2, '9': 1, '8': 1, '7': 1})\n",
      "Le sens le plus fréquent pour 'conduire' est le sens 2 avec une proportion de 38.46 %\n",
      "\n",
      "Accuracy : 0.27\n",
      "\n",
      "--> Instance : situer\n",
      "Proportion de données annotées considérées sur le corpus: 25.0 %\n",
      "Répartition des sens: Counter({'1': 11, '2': 2})\n",
      "Le sens le plus fréquent pour 'situer' est le sens 1 avec une proportion de 84.62 %\n",
      "\n",
      "Accuracy : 0.76\n",
      "\n",
      "--> Instance : aider\n",
      "Proportion de données annotées considérées sur le corpus: 25.0 %\n",
      "Répartition des sens: Counter({'3': 4, '2': 4, '1': 3, '6': 1, '4': 1})\n",
      "Le sens le plus fréquent pour 'aider' est le sens 3 avec une proportion de 30.77 %\n",
      "\n",
      "Accuracy : 0.25\n",
      "\n",
      "--> Instance : poursuivre\n",
      "Proportion de données annotées considérées sur le corpus: 25.0 %\n",
      "Répartition des sens: Counter({'4': 6, '6': 3, '5': 2, '3': 1, '1': 1})\n",
      "Le sens le plus fréquent pour 'poursuivre' est le sens 4 avec une proportion de 46.15 %\n",
      "\n",
      "Accuracy : 0.48\n",
      "\n",
      "--> Instance : profiter\n",
      "Proportion de données annotées considérées sur le corpus: 25.0 %\n",
      "Répartition des sens: Counter({'2': 9, '7': 3, '4': 1})\n",
      "Le sens le plus fréquent pour 'profiter' est le sens 2 avec une proportion de 69.23 %\n",
      "\n",
      "Accuracy : 0.74\n",
      "\n",
      "--> Instance : détenir\n",
      "Proportion de données annotées considérées sur le corpus: 25.0 %\n",
      "Répartition des sens: Counter({'1': 9, '2': 4})\n",
      "Le sens le plus fréquent pour 'détenir' est le sens 1 avec une proportion de 69.23 %\n",
      "\n",
      "Accuracy : 0.63\n",
      "\n",
      "--> Instance : lire\n",
      "Proportion de données annotées considérées sur le corpus: 25.0 %\n",
      "Répartition des sens: Counter({'1': 8, '6': 2, '3': 1, '7': 1, '2': 1})\n",
      "Le sens le plus fréquent pour 'lire' est le sens 1 avec une proportion de 61.54 %\n",
      "\n",
      "Accuracy : 0.61\n",
      "\n",
      "--> Instance : contenir\n",
      "Proportion de données annotées considérées sur le corpus: 25.0 %\n",
      "Répartition des sens: Counter({'2': 6, '3': 3, '5': 2, '4': 1, '1': 1})\n",
      "Le sens le plus fréquent pour 'contenir' est le sens 2 avec une proportion de 46.15 %\n",
      "\n",
      "Accuracy : 0.38\n",
      "\n",
      "--> Instance : dominer\n",
      "Proportion de données annotées considérées sur le corpus: 25.0 %\n",
      "Répartition des sens: Counter({'6': 10, '3': 1, '4': 1, '5': 1})\n",
      "Le sens le plus fréquent pour 'dominer' est le sens 6 avec une proportion de 76.92 %\n",
      "\n",
      "Accuracy : 0.6\n",
      "\n",
      "/!\\ ERREUR /!\\ La taille des données est trop faible. L'opération train_test_split() est impossible.\n",
      "/!\\ ERREUR /!\\ La taille des données est trop faible. L'opération train_test_split() est impossible.\n",
      "/!\\ ERREUR /!\\ La taille des données est trop faible. L'opération train_test_split() est impossible.\n",
      "/!\\ ERREUR /!\\ La taille des données est trop faible. L'opération train_test_split() est impossible.\n",
      "/!\\ ERREUR /!\\ La taille des données est trop faible. L'opération train_test_split() est impossible.\n",
      "--> Instance : noter\n",
      "Proportion de données annotées considérées sur le corpus: 25.0 %\n",
      "Répartition des sens: Counter({'3': 3, '2': 1, '5': 1})\n",
      "Le sens le plus fréquent pour 'noter' est le sens 3 avec une proportion de 60.0 %\n",
      "\n",
      "Accuracy : 0.71\n",
      "\n",
      "--> Instance : dater\n",
      "Proportion de données annotées considérées sur le corpus: 25.0 %\n",
      "Répartition des sens: Counter({'1': 11, '2': 2})\n",
      "Le sens le plus fréquent pour 'dater' est le sens 1 avec une proportion de 84.62 %\n",
      "\n",
      "Accuracy : 0.9\n",
      "\n",
      "--> Instance : adopter\n",
      "Proportion de données annotées considérées sur le corpus: 25.0 %\n",
      "Répartition des sens: Counter({'4': 8, '5': 2, '3': 1, '2': 1, '1': 1})\n",
      "Le sens le plus fréquent pour 'adopter' est le sens 4 avec une proportion de 61.54 %\n",
      "\n",
      "Accuracy : 0.46\n",
      "\n",
      "--> Instance : enregistrer\n",
      "Proportion de données annotées considérées sur le corpus: 25.0 %\n",
      "Répartition des sens: Counter({'3': 6, '2': 3, '6': 2, '1': 1})\n",
      "Le sens le plus fréquent pour 'enregistrer' est le sens 3 avec une proportion de 50.0 %\n",
      "\n",
      "Accuracy : 0.72\n",
      "\n",
      "--> Instance : intervenir\n",
      "Proportion de données annotées considérées sur le corpus: 25.0 %\n",
      "Répartition des sens: Counter({'4': 8, '1': 3, '3': 2})\n",
      "Le sens le plus fréquent pour 'intervenir' est le sens 4 avec une proportion de 61.54 %\n",
      "\n",
      "Accuracy : 0.56\n",
      "\n",
      "--> Instance : conclure\n",
      "Proportion de données annotées considérées sur le corpus: 25.0 %\n",
      "Répartition des sens: Counter({'1a': 7, '1b': 4, '3a': 1, '2b': 1})\n",
      "Le sens le plus fréquent pour 'conclure' est le sens 1a avec une proportion de 53.85 %\n",
      "\n",
      "Accuracy : 0.6\n",
      "\n",
      "--> Instance : disputer\n",
      "Proportion de données annotées considérées sur le corpus: 25.0 %\n",
      "Répartition des sens: Counter({'5': 11, '3': 1, '2': 1})\n",
      "Le sens le plus fréquent pour 'disputer' est le sens 5 avec une proportion de 84.62 %\n",
      "\n",
      "Accuracy : 0.78\n",
      "\n",
      "--> Instance : estimer\n",
      "Proportion de données annotées considérées sur le corpus: 25.0 %\n",
      "Répartition des sens: Counter({'3': 10, '1': 3})\n",
      "Le sens le plus fréquent pour 'estimer' est le sens 3 avec une proportion de 76.92 %\n",
      "\n",
      "Accuracy : 0.66\n",
      "\n",
      "--> Instance : appartenir\n",
      "Proportion de données annotées considérées sur le corpus: 25.0 %\n",
      "Répartition des sens: Counter({'6': 7, '1': 4, '3': 1, '4': 1})\n",
      "Le sens le plus fréquent pour 'appartenir' est le sens 6 avec une proportion de 53.85 %\n",
      "\n",
      "Accuracy : 0.39\n",
      "\n",
      "--> Instance : arriver\n",
      "Proportion de données annotées considérées sur le corpus: 25.0 %\n",
      "Répartition des sens: Counter({'1': 6, '2': 3, '4': 2, '5': 1, '6': 1, '3': 1})\n",
      "Le sens le plus fréquent pour 'arriver' est le sens 1 avec une proportion de 42.86 %\n",
      "\n",
      "Accuracy : 0.46\n",
      "\n",
      "--> Instance : chercher\n",
      "Proportion de données annotées considérées sur le corpus: 25.0 %\n",
      "Répartition des sens: Counter({'4': 8, '6': 3, '7': 1, '1': 1})\n",
      "Le sens le plus fréquent pour 'chercher' est le sens 4 avec une proportion de 61.54 %\n",
      "\n",
      "Accuracy : 0.61\n",
      "\n",
      "--> Instance : composer\n",
      "Proportion de données annotées considérées sur le corpus: 25.0 %\n",
      "Répartition des sens: Counter({'1': 9, '6': 2, '9': 1, '8': 1})\n",
      "Le sens le plus fréquent pour 'composer' est le sens 1 avec une proportion de 69.23 %\n",
      "\n",
      "Accuracy : 0.93\n",
      "\n",
      "--> Instance : confier\n",
      "Proportion de données annotées considérées sur le corpus: 25.0 %\n",
      "Répartition des sens: Counter({'2': 8, '1': 5})\n",
      "Le sens le plus fréquent pour 'confier' est le sens 2 avec une proportion de 61.54 %\n",
      "\n",
      "Accuracy : 0.78\n",
      "\n",
      "Macro et micro average pour 25.0% des données annotées\n",
      "Macro-average : 0.77\n",
      "Micro-average : 0.6\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "--> Instance : aboutir\n",
      "Proportion de données annotées considérées sur le corpus: 0.0 %\n",
      "Répartition des sens: Counter({'2': 1, '3': 1, '4': 1, '1': 1})\n",
      "Le sens le plus fréquent pour 'aboutir' est le sens 2 avec une proportion de 25.0 %\n",
      "\n",
      "Accuracy : 0.5\n",
      "\n",
      "--> Instance : investir\n",
      "Proportion de données annotées considérées sur le corpus: 0.0 %\n",
      "Répartition des sens: Counter({'2': 1, '3': 1, '4': 1, '1': 1})\n",
      "Le sens le plus fréquent pour 'investir' est le sens 2 avec une proportion de 25.0 %\n",
      "\n",
      "Accuracy : 0.27\n",
      "\n",
      "--> Instance : traduire\n",
      "Proportion de données annotées considérées sur le corpus: 0.0 %\n",
      "Répartition des sens: Counter({'5': 1, '4': 1, '1': 1})\n",
      "Le sens le plus fréquent pour 'traduire' est le sens 5 avec une proportion de 33.33 %\n",
      "\n",
      "Accuracy : 0.37\n",
      "\n",
      "--> Instance : témoigner\n",
      "Proportion de données annotées considérées sur le corpus: 0.0 %\n",
      "Répartition des sens: Counter({'2': 1, '1': 1})\n",
      "Le sens le plus fréquent pour 'témoigner' est le sens 2 avec une proportion de 50.0 %\n",
      "\n",
      "Accuracy : 0.67\n",
      "\n",
      "--> Instance : juger\n",
      "Proportion de données annotées considérées sur le corpus: 0.0 %\n",
      "Répartition des sens: Counter({'7': 1, '5': 1, '6': 1, '1': 1})\n",
      "Le sens le plus fréquent pour 'juger' est le sens 7 avec une proportion de 25.0 %\n",
      "\n",
      "Accuracy : 0.36\n",
      "\n",
      "--> Instance : justifier\n",
      "Proportion de données annotées considérées sur le corpus: 0.0 %\n",
      "Répartition des sens: Counter({'2': 1, '3': 1, '4': 1, '6': 1})\n",
      "Le sens le plus fréquent pour 'justifier' est le sens 2 avec une proportion de 25.0 %\n",
      "\n",
      "Accuracy : 0.2\n",
      "\n",
      "--> Instance : viser\n",
      "Proportion de données annotées considérées sur le corpus: 0.0 %\n",
      "Répartition des sens: Counter({'3': 1, '4': 1})\n",
      "Le sens le plus fréquent pour 'viser' est le sens 3 avec une proportion de 50.0 %\n",
      "\n",
      "Accuracy : 0.69\n",
      "\n",
      "--> Instance : prononcer\n",
      "Proportion de données annotées considérées sur le corpus: 0.0 %\n",
      "Répartition des sens: Counter({'3': 1, '4': 1, '7': 1, '2': 1, '1': 1})\n",
      "Le sens le plus fréquent pour 'prononcer' est le sens 3 avec une proportion de 20.0 %\n",
      "\n",
      "Accuracy : 0.29\n",
      "\n",
      "--> Instance : accomplir\n",
      "Proportion de données annotées considérées sur le corpus: 0.0 %\n",
      "Répartition des sens: Counter({'2': 1, '3': 1, '4': 1, '1': 1})\n",
      "Le sens le plus fréquent pour 'accomplir' est le sens 2 avec une proportion de 25.0 %\n",
      "\n",
      "Accuracy : 0.29\n",
      "\n",
      "--> Instance : convenir\n",
      "Proportion de données annotées considérées sur le corpus: 0.0 %\n",
      "Répartition des sens: Counter({'5': 1, '6': 1, '3': 1, '2': 1, '1': 1})\n",
      "Le sens le plus fréquent pour 'convenir' est le sens 5 avec une proportion de 20.0 %\n",
      "\n",
      "Accuracy : 0.33\n",
      "\n",
      "--> Instance : acquérir\n",
      "Proportion de données annotées considérées sur le corpus: 0.0 %\n",
      "Répartition des sens: Counter({'5': 1, '6': 1, '4': 1, '2': 1, '1': 1})\n",
      "Le sens le plus fréquent pour 'acquérir' est le sens 5 avec une proportion de 20.0 %\n",
      "\n",
      "Accuracy : 0.25\n",
      "\n",
      "--> Instance : achever\n",
      "Proportion de données annotées considérées sur le corpus: 0.0 %\n",
      "Répartition des sens: Counter({'5': 1, '3': 1, '1': 1})\n",
      "Le sens le plus fréquent pour 'achever' est le sens 5 avec une proportion de 33.33 %\n",
      "\n",
      "Accuracy : 0.43\n",
      "\n",
      "--> Instance : observer\n",
      "Proportion de données annotées considérées sur le corpus: 0.0 %\n",
      "Répartition des sens: Counter({'2': 1, '3': 1, '4': 1, '1': 1})\n",
      "Le sens le plus fréquent pour 'observer' est le sens 2 avec une proportion de 25.0 %\n",
      "\n",
      "Accuracy : 0.31\n",
      "\n",
      "--> Instance : adapter\n",
      "Proportion de données annotées considérées sur le corpus: 0.0 %\n",
      "Répartition des sens: Counter({'5': 1, '3': 1, '4': 1, '7': 1, '2': 1})\n",
      "Le sens le plus fréquent pour 'adapter' est le sens 5 avec une proportion de 20.0 %\n",
      "\n",
      "Accuracy : 0.24\n",
      "\n",
      "--> Instance : admettre\n",
      "Proportion de données annotées considérées sur le corpus: 0.0 %\n",
      "Répartition des sens: Counter({'2': 1, '3': 1, '4': 1, '1': 1})\n",
      "Le sens le plus fréquent pour 'admettre' est le sens 2 avec une proportion de 25.0 %\n",
      "\n",
      "Accuracy : 0.38\n",
      "\n",
      "--> Instance : entraîner\n",
      "Proportion de données annotées considérées sur le corpus: 0.0 %\n",
      "Répartition des sens: Counter({'3': 1, '5': 1, '4': 1, '2': 1})\n",
      "Le sens le plus fréquent pour 'entraîner' est le sens 3 avec une proportion de 25.0 %\n",
      "\n",
      "Accuracy : 0.33\n",
      "\n",
      "--> Instance : payer\n",
      "Proportion de données annotées considérées sur le corpus: 0.0 %\n",
      "Répartition des sens: Counter({'10': 1, '3': 1, '7': 1, '2': 1, '11': 1, '1': 1})\n",
      "Le sens le plus fréquent pour 'payer' est le sens 10 avec une proportion de 16.67 %\n",
      "\n",
      "Accuracy : 0.14\n",
      "\n",
      "--> Instance : respecter\n",
      "Proportion de données annotées considérées sur le corpus: 0.0 %\n",
      "Répartition des sens: Counter({'2': 1, '1': 1})\n",
      "Le sens le plus fréquent pour 'respecter' est le sens 2 avec une proportion de 50.0 %\n",
      "\n",
      "Accuracy : 0.63\n",
      "\n",
      "--> Instance : affecter\n",
      "Proportion de données annotées considérées sur le corpus: 0.0 %\n",
      "Répartition des sens: Counter({'5': 1, '6': 1, '10': 1, '3': 1, '4': 1, '8': 1, '7': 1, '1': 1})\n",
      "Le sens le plus fréquent pour 'affecter' est le sens 5 avec une proportion de 12.5 %\n",
      "\n",
      "Accuracy : 0.14\n",
      "\n",
      "--> Instance : demeurer\n",
      "Proportion de données annotées considérées sur le corpus: 0.0 %\n",
      "Répartition des sens: Counter({'2': 1, '3': 1, '4': 1, '6': 1})\n",
      "Le sens le plus fréquent pour 'demeurer' est le sens 2 avec une proportion de 25.0 %\n",
      "\n",
      "Accuracy : 0.46\n",
      "\n",
      "--> Instance : aggraver\n",
      "Proportion de données annotées considérées sur le corpus: 0.0 %\n",
      "Répartition des sens: Counter({'2': 1, '1': 1})\n",
      "Le sens le plus fréquent pour 'aggraver' est le sens 2 avec une proportion de 50.0 %\n",
      "\n",
      "Accuracy : 0.42\n",
      "\n",
      "--> Instance : agir\n",
      "Proportion de données annotées considérées sur le corpus: 0.0 %\n",
      "Répartition des sens: Counter({'6': 1, '3': 1, '7': 1, '2': 1, '1': 1})\n",
      "Le sens le plus fréquent pour 'agir' est le sens 6 avec une proportion de 20.0 %\n",
      "\n",
      "Accuracy : 0.46\n",
      "\n",
      "--> Instance : ajouter\n",
      "Proportion de données annotées considérées sur le corpus: 0.0 %\n",
      "Répartition des sens: Counter({'5': 1, '2': 1, '3': 1, '1': 1})\n",
      "Le sens le plus fréquent pour 'ajouter' est le sens 5 avec une proportion de 25.0 %\n",
      "\n",
      "Accuracy : 0.29\n",
      "\n",
      "--> Instance : alimenter\n",
      "Proportion de données annotées considérées sur le corpus: 0.0 %\n",
      "Répartition des sens: Counter({'2': 1, '3': 1, '1': 1})\n",
      "Le sens le plus fréquent pour 'alimenter' est le sens 2 avec une proportion de 33.33 %\n",
      "\n",
      "Accuracy : 0.24\n",
      "\n",
      "--> Instance : coûter\n",
      "Proportion de données annotées considérées sur le corpus: 0.0 %\n",
      "Répartition des sens: Counter({'2': 1, '3': 1, '4': 1, '1': 1})\n",
      "Le sens le plus fréquent pour 'coûter' est le sens 2 avec une proportion de 25.0 %\n",
      "\n",
      "Accuracy : 0.37\n",
      "\n",
      "--> Instance : relancer\n",
      "Proportion de données annotées considérées sur le corpus: 0.0 %\n",
      "Répartition des sens: Counter({'2': 1, '6': 1, '1': 1})\n",
      "Le sens le plus fréquent pour 'relancer' est le sens 2 avec une proportion de 33.33 %\n",
      "\n",
      "Accuracy : 0.47\n",
      "\n",
      "--> Instance : préférer\n",
      "Proportion de données annotées considérées sur le corpus: 0.0 %\n",
      "Répartition des sens: Counter({'2': 1, '3': 1, '1': 1})\n",
      "Le sens le plus fréquent pour 'préférer' est le sens 2 avec une proportion de 33.33 %\n",
      "\n",
      "Accuracy : 0.35\n",
      "\n",
      "--> Instance : appliquer\n",
      "Proportion de données annotées considérées sur le corpus: 0.0 %\n",
      "Répartition des sens: Counter({'2': 1, '3': 1, '8': 1})\n",
      "Le sens le plus fréquent pour 'appliquer' est le sens 2 avec une proportion de 33.33 %\n",
      "\n",
      "Accuracy : 0.32\n",
      "\n",
      "--> Instance : apporter\n",
      "Proportion de données annotées considérées sur le corpus: 0.0 %\n",
      "Répartition des sens: Counter({'5': 1, '3': 1, '4': 1, '2': 1, '1': 1})\n",
      "Le sens le plus fréquent pour 'apporter' est le sens 5 avec une proportion de 20.0 %\n",
      "\n",
      "Accuracy : 0.23\n",
      "\n",
      "--> Instance : fonder\n",
      "Proportion de données annotées considérées sur le corpus: 0.0 %\n",
      "Répartition des sens: Counter({'5': 1, '6': 1, '3': 1, '4': 1, '7': 1, '1': 1})\n",
      "Le sens le plus fréquent pour 'fonder' est le sens 5 avec une proportion de 16.67 %\n",
      "\n",
      "Accuracy : 0.27\n",
      "\n",
      "--> Instance : appuyer\n",
      "Proportion de données annotées considérées sur le corpus: 0.0 %\n",
      "Répartition des sens: Counter({'10': 1, '2': 1, '5': 1, '6': 1})\n",
      "Le sens le plus fréquent pour 'appuyer' est le sens 10 avec une proportion de 25.0 %\n",
      "\n",
      "Accuracy : 0.38\n",
      "\n",
      "--> Instance : changer\n",
      "Proportion de données annotées considérées sur le corpus: 0.0 %\n",
      "Répartition des sens: Counter({'5': 1, '9': 1, '6': 1, '4': 1, '1': 1})\n",
      "Le sens le plus fréquent pour 'changer' est le sens 5 avec une proportion de 20.0 %\n",
      "\n",
      "Accuracy : 0.17\n",
      "\n",
      "--> Instance : chuter\n",
      "Proportion de données annotées considérées sur le corpus: 0.0 %\n",
      "Répartition des sens: Counter({'4': 1, '1': 1})\n",
      "Le sens le plus fréquent pour 'chuter' est le sens 4 avec une proportion de 50.0 %\n",
      "\n",
      "Accuracy : 0.74\n",
      "\n",
      "--> Instance : soutenir\n",
      "Proportion de données annotées considérées sur le corpus: 0.0 %\n",
      "Répartition des sens: Counter({'5': 1, '6': 1, '3': 1, '4': 1, '2': 1, '1': 1})\n",
      "Le sens le plus fréquent pour 'soutenir' est le sens 5 avec une proportion de 16.67 %\n",
      "\n",
      "Accuracy : 0.25\n",
      "\n",
      "--> Instance : concevoir\n",
      "Proportion de données annotées considérées sur le corpus: 0.0 %\n",
      "Répartition des sens: Counter({'2': 1, '4': 1, '1': 1})\n",
      "Le sens le plus fréquent pour 'concevoir' est le sens 2 avec une proportion de 33.33 %\n",
      "\n",
      "Accuracy : 0.21\n",
      "\n",
      "--> Instance : interroger\n",
      "Proportion de données annotées considérées sur le corpus: 0.0 %\n",
      "Répartition des sens: Counter({'2': 1, '3': 1, '1': 1})\n",
      "Le sens le plus fréquent pour 'interroger' est le sens 2 avec une proportion de 33.33 %\n",
      "\n",
      "Accuracy : 0.38\n",
      "\n",
      "--> Instance : confirmer\n",
      "Proportion de données annotées considérées sur le corpus: 0.0 %\n",
      "Répartition des sens: Counter({'4': 1, '2': 1, '5': 1, '3': 1})\n",
      "Le sens le plus fréquent pour 'confirmer' est le sens 4 avec une proportion de 25.0 %\n",
      "\n",
      "Accuracy : 0.38\n",
      "\n",
      "--> Instance : transformer\n",
      "Proportion de données annotées considérées sur le corpus: 0.0 %\n",
      "Répartition des sens: Counter({'1': 1})\n",
      "Le sens le plus fréquent pour 'transformer' est le sens 1 avec une proportion de 100.0 %\n",
      "\n",
      "Accuracy : 1.0\n",
      "\n",
      "--> Instance : manifester\n",
      "Proportion de données annotées considérées sur le corpus: 0.0 %\n",
      "Répartition des sens: Counter({'3': 1, '4': 1, '1': 1})\n",
      "Le sens le plus fréquent pour 'manifester' est le sens 3 avec une proportion de 33.33 %\n",
      "\n",
      "Accuracy : 0.4\n",
      "\n",
      "--> Instance : interpeller\n",
      "Proportion de données annotées considérées sur le corpus: 0.0 %\n",
      "Répartition des sens: Counter({'5': 1, '1': 1})\n",
      "Le sens le plus fréquent pour 'interpeller' est le sens 5 avec une proportion de 50.0 %\n",
      "\n",
      "Accuracy : 0.41\n",
      "\n",
      "--> Instance : signer\n",
      "Proportion de données annotées considérées sur le corpus: 0.0 %\n",
      "Répartition des sens: Counter({'5': 1, '4': 1, '7': 1, '2': 1, '1': 1})\n",
      "Le sens le plus fréquent pour 'signer' est le sens 5 avec une proportion de 20.0 %\n",
      "\n",
      "Accuracy : 0.75\n",
      "\n",
      "--> Instance : rester\n",
      "Proportion de données annotées considérées sur le corpus: 0.0 %\n",
      "Répartition des sens: Counter({'5': 1, '6': 1, '3': 1, '4': 1, '7': 1, '2': 1, '1': 1})\n",
      "Le sens le plus fréquent pour 'rester' est le sens 5 avec une proportion de 14.29 %\n",
      "\n",
      "Accuracy : 0.28\n",
      "\n",
      "--> Instance : tuer\n",
      "Proportion de données annotées considérées sur le corpus: 0.0 %\n",
      "Répartition des sens: Counter({'2': 1, '1': 1})\n",
      "Le sens le plus fréquent pour 'tuer' est le sens 2 avec une proportion de 50.0 %\n",
      "\n",
      "Accuracy : 0.52\n",
      "\n",
      "--> Instance : indiquer\n",
      "Proportion de données annotées considérées sur le corpus: 0.0 %\n",
      "Répartition des sens: Counter({'2': 1, '4': 1, '1': 1})\n",
      "Le sens le plus fréquent pour 'indiquer' est le sens 2 avec une proportion de 33.33 %\n",
      "\n",
      "Accuracy : 0.28\n",
      "\n",
      "--> Instance : conduire\n",
      "Proportion de données annotées considérées sur le corpus: 0.0 %\n",
      "Répartition des sens: Counter({'9': 1, '10': 1, '8': 1, '7': 1, '2': 1, '1': 1})\n",
      "Le sens le plus fréquent pour 'conduire' est le sens 9 avec une proportion de 16.67 %\n",
      "\n",
      "Accuracy : 0.26\n",
      "\n",
      "--> Instance : situer\n",
      "Proportion de données annotées considérées sur le corpus: 0.0 %\n",
      "Répartition des sens: Counter({'2': 1, '1': 1})\n",
      "Le sens le plus fréquent pour 'situer' est le sens 2 avec une proportion de 50.0 %\n",
      "\n",
      "Accuracy : 0.44\n",
      "\n",
      "--> Instance : aider\n",
      "Proportion de données annotées considérées sur le corpus: 0.0 %\n",
      "Répartition des sens: Counter({'6': 1, '3': 1, '4': 1, '2': 1, '1': 1})\n",
      "Le sens le plus fréquent pour 'aider' est le sens 6 avec une proportion de 20.0 %\n",
      "\n",
      "Accuracy : 0.29\n",
      "\n",
      "--> Instance : poursuivre\n",
      "Proportion de données annotées considérées sur le corpus: 0.0 %\n",
      "Répartition des sens: Counter({'5': 1, '6': 1, '3': 1, '4': 1, '1': 1})\n",
      "Le sens le plus fréquent pour 'poursuivre' est le sens 5 avec une proportion de 20.0 %\n",
      "\n",
      "Accuracy : 0.24\n",
      "\n",
      "--> Instance : profiter\n",
      "Proportion de données annotées considérées sur le corpus: 0.0 %\n",
      "Répartition des sens: Counter({'7': 1, '2': 1, '4': 1})\n",
      "Le sens le plus fréquent pour 'profiter' est le sens 7 avec une proportion de 33.33 %\n",
      "\n",
      "Accuracy : 0.2\n",
      "\n",
      "--> Instance : détenir\n",
      "Proportion de données annotées considérées sur le corpus: 0.0 %\n",
      "Répartition des sens: Counter({'2': 1, '1': 1})\n",
      "Le sens le plus fréquent pour 'détenir' est le sens 2 avec une proportion de 50.0 %\n",
      "\n",
      "Accuracy : 0.52\n",
      "\n",
      "--> Instance : lire\n",
      "Proportion de données annotées considérées sur le corpus: 0.0 %\n",
      "Répartition des sens: Counter({'6': 1, '3': 1, '7': 1, '2': 1, '1': 1})\n",
      "Le sens le plus fréquent pour 'lire' est le sens 6 avec une proportion de 20.0 %\n",
      "\n",
      "Accuracy : 0.32\n",
      "\n",
      "--> Instance : contenir\n",
      "Proportion de données annotées considérées sur le corpus: 0.0 %\n",
      "Répartition des sens: Counter({'5': 1, '3': 1, '4': 1, '2': 1, '1': 1})\n",
      "Le sens le plus fréquent pour 'contenir' est le sens 5 avec une proportion de 20.0 %\n",
      "\n",
      "Accuracy : 0.33\n",
      "\n",
      "--> Instance : dominer\n",
      "Proportion de données annotées considérées sur le corpus: 0.0 %\n",
      "Répartition des sens: Counter({'3': 1, '4': 1, '6': 1, '5': 1})\n",
      "Le sens le plus fréquent pour 'dominer' est le sens 3 avec une proportion de 25.0 %\n",
      "\n",
      "Accuracy : 0.23\n",
      "\n",
      "--> Instance : noter\n",
      "Proportion de données annotées considérées sur le corpus: 0.0 %\n",
      "Répartition des sens: Counter({'2': 1, '3': 1, '5': 1})\n",
      "Le sens le plus fréquent pour 'noter' est le sens 2 avec une proportion de 33.33 %\n",
      "\n",
      "Accuracy : 0.28\n",
      "\n",
      "--> Instance : dater\n",
      "Proportion de données annotées considérées sur le corpus: 0.0 %\n",
      "Répartition des sens: Counter({'2': 1, '1': 1})\n",
      "Le sens le plus fréquent pour 'dater' est le sens 2 avec une proportion de 50.0 %\n",
      "\n",
      "Accuracy : 0.86\n",
      "\n",
      "--> Instance : adopter\n",
      "Proportion de données annotées considérées sur le corpus: 0.0 %\n",
      "Répartition des sens: Counter({'5': 1, '3': 1, '4': 1, '2': 1, '1': 1})\n",
      "Le sens le plus fréquent pour 'adopter' est le sens 5 avec une proportion de 20.0 %\n",
      "\n",
      "Accuracy : 0.24\n",
      "\n",
      "--> Instance : enregistrer\n",
      "Proportion de données annotées considérées sur le corpus: 0.0 %\n",
      "Répartition des sens: Counter({'2': 1, '3': 1, '6': 1, '1': 1})\n",
      "Le sens le plus fréquent pour 'enregistrer' est le sens 2 avec une proportion de 25.0 %\n",
      "\n",
      "Accuracy : 0.54\n",
      "\n",
      "--> Instance : intervenir\n",
      "Proportion de données annotées considérées sur le corpus: 0.0 %\n",
      "Répartition des sens: Counter({'3': 1, '4': 1, '1': 1})\n",
      "Le sens le plus fréquent pour 'intervenir' est le sens 3 avec une proportion de 33.33 %\n",
      "\n",
      "Accuracy : 0.32\n",
      "\n",
      "--> Instance : conclure\n",
      "Proportion de données annotées considérées sur le corpus: 0.0 %\n",
      "Répartition des sens: Counter({'1b': 1, '1a': 1, '3a': 1, '2b': 1})\n",
      "Le sens le plus fréquent pour 'conclure' est le sens 1b avec une proportion de 25.0 %\n",
      "\n",
      "Accuracy : 0.45\n",
      "\n",
      "--> Instance : disputer\n",
      "Proportion de données annotées considérées sur le corpus: 0.0 %\n",
      "Répartition des sens: Counter({'3': 1, '5': 1, '2': 1})\n",
      "Le sens le plus fréquent pour 'disputer' est le sens 3 avec une proportion de 33.33 %\n",
      "\n",
      "Accuracy : 0.29\n",
      "\n",
      "--> Instance : estimer\n",
      "Proportion de données annotées considérées sur le corpus: 0.0 %\n",
      "Répartition des sens: Counter({'3': 1, '1': 1})\n",
      "Le sens le plus fréquent pour 'estimer' est le sens 3 avec une proportion de 50.0 %\n",
      "\n",
      "Accuracy : 0.46\n",
      "\n",
      "--> Instance : appartenir\n",
      "Proportion de données annotées considérées sur le corpus: 0.0 %\n",
      "Répartition des sens: Counter({'3': 1, '4': 1, '6': 1, '1': 1})\n",
      "Le sens le plus fréquent pour 'appartenir' est le sens 3 avec une proportion de 25.0 %\n",
      "\n",
      "Accuracy : 0.27\n",
      "\n",
      "--> Instance : arriver\n",
      "Proportion de données annotées considérées sur le corpus: 0.0 %\n",
      "Répartition des sens: Counter({'5': 1, '6': 1, '3': 1, '4': 1, '2': 1, '1': 1})\n",
      "Le sens le plus fréquent pour 'arriver' est le sens 5 avec une proportion de 16.67 %\n",
      "\n",
      "Accuracy : 0.21\n",
      "\n",
      "--> Instance : chercher\n",
      "Proportion de données annotées considérées sur le corpus: 0.0 %\n",
      "Répartition des sens: Counter({'7': 1, '4': 1, '6': 1, '1': 1})\n",
      "Le sens le plus fréquent pour 'chercher' est le sens 7 avec une proportion de 25.0 %\n",
      "\n",
      "Accuracy : 0.26\n",
      "\n",
      "--> Instance : composer\n",
      "Proportion de données annotées considérées sur le corpus: 0.0 %\n",
      "Répartition des sens: Counter({'9': 1, '6': 1, '1': 1, '8': 1})\n",
      "Le sens le plus fréquent pour 'composer' est le sens 9 avec une proportion de 25.0 %\n",
      "\n",
      "Accuracy : 0.58\n",
      "\n",
      "--> Instance : confier\n",
      "Proportion de données annotées considérées sur le corpus: 0.0 %\n",
      "Répartition des sens: Counter({'2': 1, '1': 1})\n",
      "Le sens le plus fréquent pour 'confier' est le sens 2 avec une proportion de 50.0 %\n",
      "\n",
      "Accuracy : 0.54\n",
      "\n",
      "Macro et micro average pour 0.0% des données annotées\n",
      "Macro-average : 0.55\n",
      "Micro-average : 0.54\n",
      "\n",
      "--------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#   MAIN LOOP\n",
    "\n",
    "# sélection de toutes ou plusieurs instances\n",
    "instances = list(ext.w2examples.keys())\n",
    "\n",
    "# instantiation des dictionnaire qui permettront de construire les dataframes \n",
    "# contenant les résultats\n",
    "averages2score = {\"accuracy\":[], \"most_frequent_sense\":[]}\n",
    "mean_averages2score = {\"macro_average\": 0, \"micro_average\":0}\n",
    "\n",
    "macro_average = []\n",
    "micro_average = []\n",
    "data_sizes =[]\n",
    "n_repeat_most_frequent_senses = []\n",
    "    \n",
    "# pour chaque quantité de données observée\n",
    "for i in range(round(1.0/step)): \n",
    "    # calcul de la taille des données avec le pas de descente (75%, 50%, 25%, 0%)\n",
    "    data_size = 0.75 - (step*float(i))\n",
    "    data_sizes.append(data_size)\n",
    "\n",
    "    for instance in instances: \n",
    "        \n",
    "        if i == 0:\n",
    "            # crée un dataframe pour chaque instance\n",
    "            df = pd.DataFrame(columns=[\"data_sizes\", \"accuracy\", \"most_frequent_sense\"])\n",
    "            df.to_csv(f\"../results/kmeans_accuracies_{instance}_for_{n_repeat}_repetitions.csv\", index=False)\n",
    "            \n",
    "        n_repeat_accuracies = []\n",
    "        n_repeat_correct = 0\n",
    "        classified_examples_for_all_instances = 0\n",
    "        correct_classification_for_all_instances = 0\n",
    "        # effectue le clustering d'une instance n_repeat fois pour obtenir un résultat \n",
    "        # aussi homogène que possible\n",
    "        for i in range(n_repeat):\n",
    "            # récupération des sets\n",
    "            annotated_set, unannotated_set = process_annotated_and_unannotated_sets(instance, data_size)\n",
    "\n",
    "            # clustering\n",
    "            k_Means = Constrained_K_Means(annotated_set, unannotated_set)\n",
    "            k_Means.learn_clusters()\n",
    "\n",
    "            # calcul des métriques pour chaque répétition\n",
    "            correct, num_examples = k_Means.accuracy()\n",
    "            if i == n_repeat-1:\n",
    "                ext.kmeans_display_at_instance_time(instance, data_size)\n",
    "            n_repeat_accuracies.append(correct/num_examples)\n",
    "            n_repeat_correct += correct\n",
    "\n",
    "        mean_correct = (n_repeat_correct/n_repeat)\n",
    "        correct_classification_for_all_instances += mean_correct\n",
    "        classified_examples_for_all_instances += num_examples\n",
    "                                       \n",
    "        # calcul des métriques pour chaque instance (on fait la moyenne des accuracy sur les répétitions)\n",
    "        accuracy = get_accuracy(n_repeat_accuracies, display=True)\n",
    "        n_repeat_most_frequent_senses = [ext.get_most_frequent_sense()[1], ext.get_most_frequent_sense()[2]]\n",
    "        averages2score = make_csv_per_instance(instance, n_repeat, data_size, accuracy, averages2score, n_repeat_most_frequent_senses)\n",
    "    \n",
    "    # calcul des micro et macro averages pour chaque pas et pour le kmeans\n",
    "    micro_average, macro_average = get_macro_and_micro_average(averages2score, micro_average, macro_average, correct_classification_for_all_instances, classified_examples_for_all_instances, data_size, display=True)\n",
    "\n",
    "create_kmeans_mean_accuracies_csv(mean_averages2score, macro_average, micro_average, data_sizes, n_repeat)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
